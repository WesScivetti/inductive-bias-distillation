
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 1 --language_list language_list_synchrony --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 5 --adam_epochs 1 --eval_suffix matched --return_last --top_p 1.0 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 10 --language_list language_list_synchrony --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 5 --adam_epochs 1 --eval_suffix for_paper --return_last --top_p 1.0 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 100 --language_list language_list_synchrony --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 10 --adam_epochs 5 --eval_suffix matched --return_last --top_p 0.99 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 1000 --language_list language_list_synchrony --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 10 --adam_epochs 5 --eval_suffix matched --return_last --top_p 0.99 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 10000 --language_list language_list_synchrony --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 10 --adam_epochs 5 --eval_suffix matched --return_last --top_p 0.99 --hot_temperature 1.0 --cold_temperature 1.0 --adam_lr 5e-4



python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 1 --language_list language_list_recursion --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 5 --adam_epochs 1 --eval_suffix matched --return_last --top_p 1.0 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 10 --language_list language_list_recursion --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 5 --adam_epochs 1 --eval_suffix for_paper --return_last --top_p 1.0 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 100 --language_list language_list_recursion --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 10 --adam_epochs 5 --eval_suffix matched --return_last --top_p 0.99 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 1000 --language_list language_list_recursion --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 10 --adam_epochs 5 --eval_suffix matched --return_last --top_p 0.99 --hot_temperature 1.0 --cold_temperature 0.5 --adam_lr 5e-4
python meta_train.py --n_meta_train 25000 --n_meta_valid 500 --n_meta_test 1000 --meta_train_batch_size 10 --meta_eval_batch_size 1000 --max_batches_per_language 20 --meta_test_size 1000 --dataset scfg_no_recursion --withheld_languages language_list --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1 --eval_every 100 --learning_rate 0.005 --inner_lr 1.0 --multi_step_loss --model_name meta_lm_no_recursion_hidden1024_17 --weight_dir weights/ --log_dir logs/ --formal_train_size 10000 --language_list language_list_recursion --eval --eval_formal --prec_rec_n_samples 1000000 --sgd_epochs 10 --adam_epochs 5 --eval_suffix matched --return_last --top_p 0.99 --hot_temperature 1.0 --cold_temperature 1.0 --adam_lr 5e-4



