2024-07-05 04:04:39,808 INFO     Namespace(n_meta_train=25000, n_meta_valid=500, n_meta_test=1000, meta_train_batch_size=10, meta_eval_batch_size=1000, max_batches_per_language=20, meta_train_size=10, meta_test_size=1000, dataset='scfg_no_recursion', yandp_param_file=None, formal_train_size=1, formal_test_size=10, language_list='language_list_synchrony', withheld_languages='language_list', prior_flat=0.5, recursion_base=0.8, prob_1_flat=0.5, architecture='LSTM', n_embd=1024, n_positions=256, n_head=12, n_layer=2, dropout=0.1, n_epochs=1, eval_every=100, weight_decay=0.1, learning_rate=0.005, inner_lr=1.0, lr_scheduler_type='cosine', warmup_proportion=0.05, patience=None, lr_decay_patience=None, multi_step_loss=True, multi_step_loss_eval=False, pseudo=False, model_name='meta_lm_no_recursion_hidden1024_2', weight_dir='weights/', log_dir='logs/', save_optimizer_scheduler=False, load_saved=False, start_epoch=0, start_batch_index=0, start_total_updates=0, eval=True, eval_formal=True, eval_valid=False, eval_generate=False, eval_extrapolation=False, top_p=1.0, hot_temperature=1.0, cold_temperature=0.5, prec_rec_n_samples=1000000, sgd_epochs=5, adam_lr=0.0005, adam_epochs=1, eval_suffix='_matched', return_last=True)
2024-07-05 04:04:43,131 INFO     Model size: 16.8M parameters
2024-07-05 04:04:43,682 INFO     Loading model checkpoint from weights/meta_lm_no_recursion_hidden1024_2
2024-07-05 04:04:43,904 INFO     Language: XX
2024-07-05 04:04:43,904 INFO     Description: XX (two copies of the same string)
2024-07-05 04:04:44,075 INFO     DONE TRAINING
2024-07-05 04:04:44,076 INFO     TRAINING SET LOSS: 0.0013171116588637233
2024-07-05 04:05:20,363 INFO     LM most common: [('0 0', 993361), ('1 0', 5378), ('1 1', 507), ('0 1', 362), ('0', 70), ('1 0 1', 59), ('', 46), ('1', 36), ('0 0 0', 35), ('2 0', 31), ('0 0 1', 28), ('3 0', 20), ('1 0 0', 19), ('4 0', 7), ('1 0 1 1 2 2', 5), ('1 0 1 1 2 2 2', 5), ('0 3', 5), ('5 0', 4), ('1 0 1 2 2 2', 3), ('6 0', 3), ('0 2', 3), ('8 0', 2), ('1 0 1 1 2 2 1', 1), ('1 0 1 1', 1), ('9 0', 1)]
2024-07-05 04:05:20,398 INFO     LM most common: [('0 0', -3.540453690220602e-05), ('1 0', -10.262057304382324), ('1 1', -14.81439208984375), ('0 1', -15.632505416870117), ('1 0 1', -19.0103702545166), ('0', -19.06960105895996), ('', -19.764141082763672), ('1', -19.837623596191406), ('0 0 1', -20.83728790283203), ('0 0 0', -20.896957397460938), ('2 0', -21.118968963623047), ('1 0 0', -21.21405029296875), ('3 0', -22.216102600097656), ('1 0 1 1 2 2', -23.119117736816406), ('1 0 1 1 2 2 2', -23.144073486328125), ('4 0', -24.24823760986328), ('1 0 1 1', -25.140703201293945), ('5 0', -25.443574905395508), ('0 3', -25.557769775390625), ('1 0 1 1 1', -26.078235626220703), ('6 0', -26.62281036376953), ('0 2', -26.856346130371094), ('1 0 1 0', -27.067874908447266), ('0 4', -27.158668518066406), ('1 0 1 2 2 2', -27.259538650512695)]
2024-07-05 04:05:20,398 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:05:20,398 INFO     ['1 0', '0 1', '1 0 1', '0', '', '1', '0 0 1', '0 0 0', '2 0', '1 0 0', '3 0', '1 0 1 1 2 2', '1 0 1 1 2 2 2', '4 0', '1 0 1 1', '5 0', '0 3', '1 0 1 1 1', '6 0', '0 2', '0 4', '1 0 1 2 2 2']
2024-07-05 04:05:20,398 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:05:20,398 INFO     ['1 1 1 1', '0 1 0 1', '0 0 0 0 0 0', '1 0 0 1 0 0', '0 0 1 0 0 1', '1 0 1 1 0 1', '0 1 1 0 1 1', '1 1 1 1 1 1', '0 1 0 0 1 0', '1 1 0 1 1 0', '1 1 0 1 1 1 0 1', '0 1 0 1 0 1 0 1', '1 0 0 0 1 0 0 0', '0 0 1 1 0 0 1 1', '0 1 0 0 0 1 0 0', '0 0 1 0 0 0 1 0', '1 0 0 1 1 0 0 1', '1 1 1 0 1 1 1 0', '0 0 0 0 0 0 0 0', '1 1 1 1 1 1 1 1', '1 0 1 0 1 0 1 0']
2024-07-05 04:05:20,398 INFO     LM precision, recall, fscore: 0.12 0.16 0.13714285714285712
2024-07-05 04:05:20,399 INFO     Memorization precision, recall, fscore: 1.0 0.04 0.07692307692307693
2024-07-05 04:05:20,399 INFO     
2024-07-05 04:05:20,441 INFO     Language: XXX
2024-07-05 04:05:20,441 INFO     Description: XXX
2024-07-05 04:05:20,454 INFO     DONE TRAINING
2024-07-05 04:05:20,457 INFO     TRAINING SET LOSS: 0.007323611527681351
2024-07-05 04:06:07,374 INFO     LM most common: [('1 1 1', 984771), ('0 0 1', 5748), ('0 1 1', 4533), ('1 0 1', 2480), ('1 1 0', 764), ('1 1', 696), ('1', 252), ('0', 142), ('0 0 0', 92), ('2 2 1', 53), ('', 46), ('3 1 1', 41), ('1 2 1', 33), ('0 1 0', 25), ('0 0 1 0 2 2 2 2 2 2', 24), ('1 0 0', 24), ('1 1 3', 23), ('1 1 1 1 2', 22), ('0 2 1', 22), ('1 1 1 1', 18), ('1 3 1', 15), ('4 1 1', 13), ('1 1 1 0 2 2 2 2 2 2', 13), ('1 1 4', 11), ('0 0', 10)]
2024-07-05 04:06:07,456 INFO     LM most common: [('1 1 1', -0.00012575883010867983), ('0 0 1', -9.526591300964355), ('0 1 1', -10.011160850524902), ('1 0 1', -11.895113945007324), ('1 1 0', -14.342657089233398), ('1 1', -14.467350006103516), ('1', -16.684572219848633), ('0', -17.037193298339844), ('0 0 0', -17.844953536987305), ('2 2 1', -19.1325740814209), ('0 0 1 0 2 2 2 2 2 2', -19.194854736328125), ('', -19.687124252319336), ('1 1 1 1 2', -19.738401412963867), ('0 2 1', -20.222543716430664), ('0 1 0', -20.287317276000977), ('3 1 1', -20.459491729736328), ('1 2 1', -20.657617568969727), ('1 1 1 1', -21.10313606262207), ('0 0 1 0 0', -21.11552619934082), ('1 1 1 0 2 2 2 2 2 2', -21.227500915527344), ('1 1 1 1 2 2 2 2 2 2', -21.407358169555664), ('1 1 3', -21.743568420410156), ('1 3 1', -21.945175170898438), ('0 0', -22.076934814453125), ('1 0 0', -22.336225509643555)]
2024-07-05 04:06:07,457 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:06:07,457 INFO     ['0 0 1', '0 1 1', '1 0 1', '1 1 0', '1 1', '1', '0', '2 2 1', '0 0 1 0 2 2 2 2 2 2', '', '1 1 1 1 2', '0 2 1', '0 1 0', '3 1 1', '1 2 1', '1 1 1 1', '0 0 1 0 0', '1 1 1 0 2 2 2 2 2 2', '1 1 1 1 2 2 2 2 2 2', '1 1 3', '1 3 1', '0 0', '1 0 0']
2024-07-05 04:06:07,457 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:06:07,457 INFO     ['1 0 1 0 1 0', '1 1 1 1 1 1', '0 1 0 1 0 1', '0 0 0 0 0 0', '0 1 1 0 1 1 0 1 1', '1 0 0 1 0 0 1 0 0', '0 0 1 0 0 1 0 0 1', '0 0 0 0 0 0 0 0 0', '1 1 0 1 1 0 1 1 0', '0 1 0 0 1 0 0 1 0', '1 1 1 1 1 1 1 1 1', '1 0 1 1 0 1 1 0 1', '1 0 0 0 1 0 0 0 1 0 0 0', '1 0 1 1 1 0 1 1 1 0 1 1', '0 1 1 1 0 1 1 1 0 1 1 1', '1 1 0 1 1 1 0 1 1 1 0 1', '1 1 1 1 1 1 1 1 1 1 1 1', '1 1 1 0 1 1 1 0 1 1 1 0', '0 1 0 0 0 1 0 0 0 1 0 0', '0 0 0 0 0 0 0 0 0 0 0 0', '1 0 1 0 1 0 1 0 1 0 1 0', '0 0 0 1 0 0 0 1 0 0 0 1', '0 0 1 1 0 0 1 1 0 0 1 1']
2024-07-05 04:06:07,457 INFO     LM precision, recall, fscore: 0.08 0.08 0.08
2024-07-05 04:06:07,457 INFO     Memorization precision, recall, fscore: 1.0 0.04 0.07692307692307693
2024-07-05 04:06:07,457 INFO     
2024-07-05 04:06:07,461 INFO     Language: AnBnCn
2024-07-05 04:06:07,461 INFO     Description: A^n B^n C^n
2024-07-05 04:06:07,473 INFO     DONE TRAINING
2024-07-05 04:06:07,475 INFO     TRAINING SET LOSS: 0.0021754265762865543
2024-07-05 04:06:51,161 INFO     LM most common: [('0 1 2', 990635), ('1 1 2', 2681), ('0 0 2', 1516), ('0 1 0', 1247), ('0 2 2', 1044), ('0 1 1', 853), ('2 1 2', 751), ('0 1', 317), ('0', 290), ('0 1 3', 166), ('0 3 2', 150), ('0 4 2', 69), ('0 1 4', 47), ('0 5 2', 35), ('3 1 2', 33), ('0 1 6', 19), ('0 1 5', 16), ('1 2 2', 14), ('0 6 2', 12), ('0 1 2 0 2 2', 11), ('4 1 2', 10), ('0 0 1', 10), ('1 2', 7), ('0 9 2', 7), ('0 1 9', 6)]
2024-07-05 04:06:51,205 INFO     LM most common: [('0 1 2', -1.3828237570123747e-05), ('1 1 2', -11.820618629455566), ('0 0 2', -12.948227882385254), ('0 1 0', -13.357000350952148), ('0 2 2', -13.869135856628418), ('0 1 1', -14.046266555786133), ('2 1 2', -14.449554443359375), ('0 1', -16.06240463256836), ('0', -16.44478416442871), ('0 1 3', -17.554466247558594), ('0 3 2', -17.5947208404541), ('0 4 2', -19.5072021484375), ('0 1 4', -19.831270217895508), ('3 1 2', -20.429180145263672), ('0 5 2', -21.187664031982422), ('1 2 2', -21.308866500854492), ('0 1 6', -21.86741828918457), ('0 1 5', -21.908546447753906), ('0 1 2 0 2 2', -22.30830192565918), ('0 6 2', -22.52452278137207), ('4 1 2', -22.81560707092285), ('0 1 2 1 2 2 2', -22.873672485351562), ('0 0 1', -23.115718841552734), ('1 2', -23.435222625732422), ('0 7 2', -23.6174373626709)]
2024-07-05 04:06:51,205 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:06:51,205 INFO     ['1 1 2', '0 0 2', '0 1 0', '0 2 2', '0 1 1', '2 1 2', '0 1', '0', '0 1 3', '0 3 2', '0 4 2', '0 1 4', '3 1 2', '0 5 2', '1 2 2', '0 1 6', '0 1 5', '0 1 2 0 2 2', '0 6 2', '4 1 2', '0 1 2 1 2 2 2', '0 0 1', '1 2', '0 7 2']
2024-07-05 04:06:51,205 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:06:51,205 INFO     ['0 0 1 1 2 2', '0 0 0 1 1 1 2 2 2', '0 0 0 0 1 1 1 1 2 2 2 2', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', '0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', '0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2024-07-05 04:06:51,205 INFO     LM precision, recall, fscore: 0.04 0.04 0.04
2024-07-05 04:06:51,205 INFO     Memorization precision, recall, fscore: 1.0 0.04 0.07692307692307693
2024-07-05 04:06:51,205 INFO     
2024-07-05 04:06:51,209 INFO     Language: AnBnCnDn
2024-07-05 04:06:51,209 INFO     Description: A^n B^n C^n D^n
2024-07-05 04:06:51,221 INFO     DONE TRAINING
2024-07-05 04:06:51,227 INFO     TRAINING SET LOSS: 0.004052781965583563
2024-07-05 04:08:32,792 INFO     LM most common: [('0 0 1 1 2 2 3 3', 967925), ('0 1 1 1 2 2 3 3', 3949), ('1 0 1 1 2 2 3 3', 3215), ('0 0 0 1 2 2 3 3', 2966), ('0 0 1 1 1 2 3 3', 2370), ('0 0 1 0 2 2 3 3', 1792), ('0 0 3 1 2 2 3 3', 1653), ('0 0 1 1 0 2 3 3', 1414), ('0 0 0 1 2 2 2 3', 1125), ('0 0 0 1 2 2 0 3', 995), ('0 0 1 2 2 2 3 3', 927), ('1 0 1 1 1 2 3 3', 677), ('1 1 1 1 2 2 3 3', 673), ('0 0', 672), ('2 2 1 1 2 2 3 3', 577), ('0 2 1 1 2 2 3 3', 445), ('0 0 2 1 2 2 3 3', 394), ('0 0 1 1 2 3 3 3', 332), ('0 0 0 1 1 2 2 3', 286), ('2 0 1 1 2 2 3 3', 284), ('0 0 1 1 3 2 3 3', 258), ('0 0 1 1 2 0 3 3', 246), ('0 0 1 1 2 2 3 1', 242), ('1 0 2 1 2 2 3 3', 231), ('0 0 1 1 2 2 3', 230)]
2024-07-05 04:08:33,784 INFO     LM most common: [('0 0 1 1 2 2 3 3', -0.00011265097418799996), ('1 0 1 1 2 2 3 3', -10.380962371826172), ('0 0 0 1 2 2 3 3', -10.438339233398438), ('0 1 1 1 2 2 3 3', -10.829216957092285), ('0 0 1 1 1 2 3 3', -12.0061616897583), ('0 0 0 1 2 2 2 3', -12.22335147857666), ('0 0 1 0 2 2 3 3', -12.398980140686035), ('0 0 0 1 2 2 0 3', -12.595063209533691), ('0 0 3 1 2 2 3 3', -12.66257095336914), ('0 0 1 1 0 2 3 3', -13.13056755065918), ('1 1 1 1 2 2 3 3', -13.146599769592285), ('2 2 1 1 2 2 3 3', -13.387018203735352), ('1 0 1 1 1 2 3 3', -13.484127044677734), ('0 0 1 2 2 2 3 3', -13.770233154296875), ('0 0', -14.533985137939453), ('0 2 1 1 2 2 3 3', -14.668212890625), ('0 0 2 1 2 2 3 3', -15.376323699951172), ('0 0 0 1 1 2 2 3', -15.595959663391113), ('2 0 1 1 2 2 3 3', -15.620261192321777), ('1 0 2 1 2 2 3 3', -15.787768363952637), ('2 2 2 1 2 2 3 3', -15.789137840270996), ('1 1 1 1 1 2 3 3', -15.963277816772461), ('0 0 1 1 2 3 3 3', -15.970059394836426), ('0 0 1 1 2 0 3 3', -16.27263641357422), ('2 2 3 1 2 2 3 3', -16.3131103515625)]
2024-07-05 04:08:33,784 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:08:33,784 INFO     ['1 0 1 1 2 2 3 3', '0 0 0 1 2 2 3 3', '0 1 1 1 2 2 3 3', '0 0 1 1 1 2 3 3', '0 0 0 1 2 2 2 3', '0 0 1 0 2 2 3 3', '0 0 0 1 2 2 0 3', '0 0 3 1 2 2 3 3', '0 0 1 1 0 2 3 3', '1 1 1 1 2 2 3 3', '2 2 1 1 2 2 3 3', '1 0 1 1 1 2 3 3', '0 0 1 2 2 2 3 3', '0 0', '0 2 1 1 2 2 3 3', '0 0 2 1 2 2 3 3', '0 0 0 1 1 2 2 3', '2 0 1 1 2 2 3 3', '1 0 2 1 2 2 3 3', '2 2 2 1 2 2 3 3', '1 1 1 1 1 2 3 3', '0 0 1 1 2 3 3 3', '0 0 1 1 2 0 3 3', '2 2 3 1 2 2 3 3']
2024-07-05 04:08:33,785 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:08:33,785 INFO     ['0 1 2 3', '0 0 0 1 1 1 2 2 2 3 3 3', '0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', '0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', '0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3']
2024-07-05 04:08:33,785 INFO     LM precision, recall, fscore: 0.04 0.04 0.04
2024-07-05 04:08:33,785 INFO     Memorization precision, recall, fscore: 1.0 0.04 0.07692307692307693
2024-07-05 04:08:33,785 INFO     
2024-07-05 04:08:33,789 INFO     Language: AnBnCnDnEn
2024-07-05 04:08:33,789 INFO     Description: A^n B^n C^n D^n E^n
2024-07-05 04:08:33,805 INFO     DONE TRAINING
2024-07-05 04:08:33,820 INFO     TRAINING SET LOSS: 0.017198799178004265
2024-07-05 04:19:40,840 INFO     LM most common: [('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 695717), ('2 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 22035), ('1 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 12284), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 4 3 3 3 3 4 4 4 4 4', 8716), ('1 0 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 8115), ('1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 7423), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4', 6946), ('1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 6392), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 4 4 4 4 4 4', 6186), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 3', 4607), ('0 0 0 0 0 1 1 1 1 0 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 4559), ('0 0 0 0 0 1 1 1 1 1 0 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 4546), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 2 4', 4521), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 3 4 4 4', 4240), ('0 0 0 0 0 0 1', 3899), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 4 3 4 4 4 4 4', 3622), ('0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 3433), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4', 3175), ('0 0 0 0 0 1 0 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 2972), ('0 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 2804), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4', 2653), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 4 4 4 4 4', 2534), ('0 0 0 0 0 1 1 0 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 2494), ('0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 2318), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 1 3 3 3 3 3 4 4 4 4 4', 2289)]
2024-07-05 04:20:27,596 INFO     LM most common: [('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -0.009571399539709091), ('1 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -6.00636100769043), ('2 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -6.617671012878418), ('1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -6.803450107574463), ('1 1 1 1 2 2 2 3 3 3 3 4 4 4 4 4', -7.209051132202148), ('1 0 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -7.270804405212402), ('1 1 1 1 2 2 3 3 3 3 3 4 4 4 4 4', -7.802138328552246), ('1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -7.990164756774902), ('1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -8.186432838439941), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 4 3 3 3 3 4 4 4 4 4', -8.612655639648438), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4', -9.116076469421387), ('0 0 0 0 0 1 0 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.160664558410645), ('1 1 0 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.301294326782227), ('0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.313371658325195), ('1 1 1 1 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.386674880981445), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 4 4 4 4 4 4', -9.391168594360352), ('0 0 0 0 0 0 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.46921443939209), ('1 1 1 1 1 1 1', -9.544528007507324), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 2 4', -9.846541404724121), ('0 0 0 0 0 0 1', -9.85721492767334), ('0 0 0 0 0 1 1 1 1 0 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.872066497802734), ('0 0 0 0 0 1 1 1 1 1 0 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -9.882306098937988), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 3', -9.953141212463379), ('1 1 2 2 2 2 2 3 3 3 3 4 4 4 4 4', -9.995855331420898), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 3 4 4 4', -10.01075553894043)]
2024-07-05 04:20:27,596 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:20:27,596 INFO     ['1 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '2 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 1 1 2 2 2 3 3 3 3 4 4 4 4 4', '1 0 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 1 1 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 4 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4', '0 0 0 0 0 1 0 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 0 2 2 2 3 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 1 1 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 4 4 4 4 4 4', '0 0 0 0 0 0 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '1 1 1 1 1 1 1', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 2 4', '0 0 0 0 0 0 1', '0 0 0 0 0 1 1 1 1 0 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 0 2 2 2 2 3 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 3', '1 1 2 2 2 2 2 3 3 3 3 4 4 4 4 4', '0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 3 4 4 4']
2024-07-05 04:20:27,596 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:20:27,596 INFO     ['0 1 2 3 4', '0 0 1 1 2 2 3 3 4 4', '0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', '0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', '0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', '0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4']
2024-07-05 04:20:27,598 INFO     LM precision, recall, fscore: 0.04 0.04 0.04
2024-07-05 04:20:27,598 INFO     Memorization precision, recall, fscore: 1.0 0.04 0.07692307692307693
2024-07-05 04:20:27,598 INFO     
2024-07-05 04:20:27,602 INFO     Language: AnBmCnDm
2024-07-05 04:20:27,602 INFO     Description: A^n B^m C^n D^m
2024-07-05 04:20:27,615 INFO     DONE TRAINING
2024-07-05 04:20:27,619 INFO     TRAINING SET LOSS: 0.0046112616546452045
2024-07-05 04:21:33,024 INFO     LM most common: [('0 0 1 2 2 3', 970171), ('0 1 1 2 2 3', 4607), ('0 0 0 2 2 3', 3876), ('1 0 1 2 2 3', 3731), ('0 0 1 0 2 3', 1592), ('0 0 1 1 2 3', 1286), ('2 0 1 2 2 3', 1139), ('0 0 3 2 2 3', 1114), ('2 2 1 2 2 3', 1091), ('0 2 1 2 2 3', 1051), ('0 0 2 2 2 3', 1002), ('0 0', 755), ('0 0 0 1 2 2 3', 500), ('3 0 1 2 2 3', 493), ('0 0 1', 458), ('1 0 1 1 2 3', 404), ('0 3 1 2 2 3', 363), ('0 0 1 2 2 0', 342), ('0 0 1 2 2 1', 320), ('1 1 1 2 2 3', 319), ('0 1 2 2 3', 264), ('0 0 1 2 3 3', 260), ('1 2 2 3', 230), ('0 0 1 3 2 3', 217), ('0 1 1 2 3 3', 204)]
2024-07-05 04:21:33,502 INFO     LM most common: [('0 0 1 2 2 3', -0.00010561769886408001), ('1 0 1 2 2 3', -10.365538597106934), ('0 1 1 2 2 3', -10.443070411682129), ('0 0 0 2 2 3', -10.584673881530762), ('2 2 1 2 2 3', -12.67440128326416), ('2 0 1 2 2 3', -12.727218627929688), ('0 0 1 0 2 3', -12.819157600402832), ('0 2 1 2 2 3', -13.125702857971191), ('0 0 1 1 2 3', -13.273963928222656), ('0 0 3 2 2 3', -13.409012794494629), ('0 0 2 2 2 3', -13.59975814819336), ('0 0 0 1 2 2 3', -14.24732780456543), ('0 0', -14.308713912963867), ('1 0 1 1 2 3', -14.519315719604492), ('1 2 2 3', -14.720476150512695), ('3 0 1 2 2 3', -14.954879760742188), ('1 1 1 2 2 3', -15.102506637573242), ('0 0 1', -15.380412101745605), ('0 3 1 2 2 3', -15.691115379333496), ('0 0 1 2 2 0', -15.865583419799805), ('0 0 1 2 2 1', -15.90251350402832), ('1 2 2 3 2 2', -15.940723419189453), ('0 0 1 2 3 3', -16.201053619384766), ('0 1 2 2 3', -16.249637603759766), ('0 0 1 3 2 3', -16.57103729248047)]
2024-07-05 04:21:33,502 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:21:33,502 INFO     ['1 0 1 2 2 3', '0 1 1 2 2 3', '0 0 0 2 2 3', '2 2 1 2 2 3', '2 0 1 2 2 3', '0 0 1 0 2 3', '0 2 1 2 2 3', '0 0 1 1 2 3', '0 0 3 2 2 3', '0 0 2 2 2 3', '0 0 0 1 2 2 3', '0 0', '1 0 1 1 2 3', '1 2 2 3', '3 0 1 2 2 3', '1 1 1 2 2 3', '0 0 1', '0 3 1 2 2 3', '0 0 1 2 2 0', '0 0 1 2 2 1', '1 2 2 3 2 2', '0 0 1 2 3 3', '0 1 2 2 3', '0 0 1 3 2 3']
2024-07-05 04:21:33,502 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:21:33,502 INFO     ['0 1 2 3', '0 1 1 1 2 3 3 3', '0 0 0 1 2 2 2 3', '0 0 1 1 2 2 3 3', '0 0 0 1 1 2 2 2 3 3', '0 0 1 1 1 2 2 3 3 3', '0 1 1 1 1 2 3 3 3 3', '0 0 0 0 1 2 2 2 2 3', '0 0 1 1 1 1 2 2 3 3 3 3', '0 0 0 0 1 1 2 2 2 2 3 3', '0 0 0 0 0 1 2 2 2 2 2 3', '0 0 0 1 1 1 2 2 2 3 3 3', '0 1 1 1 1 1 2 3 3 3 3 3', '0 0 1 1 1 1 1 2 2 3 3 3 3 3', '0 0 0 0 0 1 1 2 2 2 2 2 3 3', '0 1 1 1 1 1 1 2 3 3 3 3 3 3', '0 0 0 0 1 1 1 2 2 2 2 3 3 3', '0 0 0 0 0 0 1 2 2 2 2 2 2 3', '0 0 0 1 1 1 1 2 2 2 3 3 3 3', '0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 3', '0 0 0 0 0 0 1 1 2 2 2 2 2 2 3 3', '0 0 0 1 1 1 1 1 2 2 2 3 3 3 3 3', '0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3']
2024-07-05 04:21:33,502 INFO     LM precision, recall, fscore: 0.04 0.08 0.05333333333333334
2024-07-05 04:21:33,502 INFO     Memorization precision, recall, fscore: 1.0 0.04 0.07692307692307693
2024-07-05 04:21:33,502 INFO     
2024-07-05 04:21:33,506 INFO     Language: AnBmAnBm
2024-07-05 04:21:33,506 INFO     Description: A^n B^m A^n B^m
2024-07-05 04:21:33,522 INFO     DONE TRAINING
2024-07-05 04:21:33,532 INFO     TRAINING SET LOSS: 0.006922890432178974
2024-07-05 04:28:48,784 INFO     LM most common: [('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 914129), ('1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 36386), ('1 1 1 1 1 1 1 1 1', 6286), ('0 1 1 1 1 1 1 1 1', 5005), ('0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 4709), ('0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 4529), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 3648), ('2 2 2 2 2 2 1 1 1', 2572), ('0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 2290), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0', 1383), ('2 2 2 2 2 2 1 1 1 0 1 1 1 1 1 1 1 1', 1273), ('2 2 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 1156), ('0 1 0 1 1 1 1 1 1', 1035), ('2 2 1 1 1 1 1 1 1', 1031), ('0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 683), ('0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1', 599), ('2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1', 550), ('0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1', 431), ('0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1', 427), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1', 407), ('2 2 1 2 2 2 1 1 1 0 1 1 1 1 1 1 1 1', 393), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1', 385), ('0 1 1 1 1 1 1 1 1 0 1 1 1', 381), ('0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1', 313), ('0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1', 289)]
2024-07-05 04:28:50,465 INFO     LM most common: [('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -0.0023434634786099195), ('1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -6.201124668121338), ('2 2 2 2 2 2 1 1 1', -9.603939056396484), ('1 1 1 1 1 1 1 1 1', -9.747793197631836), ('0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -10.264701843261719), ('0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -10.280379295349121), ('0 1 1 1 1 1 1 1 1', -10.413558959960938), ('2 2 2 2 2 2 1 1 1 0 1 1 1 1 1 1 1 1', -10.853350639343262), ('2 2 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -10.988393783569336), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -11.048540115356445), ('2 2 1 1 1 1 1 1 1', -11.290914535522461), ('0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -12.011110305786133), ('2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1', -12.365535736083984), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0', -12.935133934020996), ('2 2 1 2 2 2 1 1 1 0 1 1 1 1 1 1 1 1', -12.9383544921875), ('0 1 0 1 1 1 1 1 1', -13.259180068969727), ('0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -14.16983413696289), ('2 2 1 2 2 2 1 1 1', -14.21888542175293), ('2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1', -14.249945640563965), ('0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1', -14.619916915893555), ('2 2 2 2 2 2 1 2 1', -14.989890098571777), ('0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1', -15.178607940673828), ('2 2 2 1 1 1 1 1 1', -15.187118530273438), ('0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1', -15.195171356201172), ('2 2 1 1 1 2 1 1 1', -15.268671035766602)]
2024-07-05 04:28:50,465 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:28:50,465 INFO     ['1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', '2 2 2 2 2 2 1 1 1', '1 1 1 1 1 1 1 1 1', '0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', '0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1', '2 2 2 2 2 2 1 1 1 0 1 1 1 1 1 1 1 1', '2 2 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', '2 2 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0', '2 2 1 2 2 2 1 1 1 0 1 1 1 1 1 1 1 1', '0 1 0 1 1 1 1 1 1', '0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1', '2 2 1 2 2 2 1 1 1', '2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1', '2 2 2 2 2 2 1 2 1', '0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1', '2 2 2 1 1 1 1 1 1', '0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1', '2 2 1 1 1 2 1 1 1']
2024-07-05 04:28:50,465 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:28:50,465 INFO     ['0 0 1 0 0 1', '0 1 1 0 1 1', '0 0 0 1 0 0 0 1', '0 1 1 1 0 1 1 1', '0 0 1 1 0 0 1 1', '0 0 0 1 1 0 0 0 1 1', '0 0 1 1 1 0 0 1 1 1', '0 0 0 0 1 0 0 0 0 1', '0 1 1 1 1 0 1 1 1 1', '0 0 1 1 1 1 0 0 1 1 1 1', '0 1 1 1 1 1 0 1 1 1 1 1', '0 0 0 0 0 1 0 0 0 0 0 1', '0 0 0 0 1 1 0 0 0 0 1 1', '0 0 0 1 1 1 0 0 0 1 1 1', '0 0 0 0 1 1 1 0 0 0 0 1 1 1', '0 0 0 1 1 1 1 0 0 0 1 1 1 1', '0 0 0 0 0 1 1 0 0 0 0 0 1 1', '0 1 1 1 1 1 1 0 1 1 1 1 1 1', '0 0 0 0 0 0 1 0 0 0 0 0 0 1', '0 0 1 1 1 1 1 0 0 1 1 1 1 1', '0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', '0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1', '0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1', '0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1']
2024-07-05 04:28:50,465 INFO     LM precision, recall, fscore: 0.04 0.04 0.04
2024-07-05 04:28:50,466 INFO     Memorization precision, recall, fscore: 1.0 0.0 0.0
2024-07-05 04:28:50,466 INFO     
2024-07-05 04:28:50,497 INFO     Language: XXI
2024-07-05 04:28:50,497 INFO     Description: X X^I (where X^I is the inverse of X - replace every A with B and vice-versa)
2024-07-05 04:28:50,513 INFO     DONE TRAINING
2024-07-05 04:28:50,527 INFO     TRAINING SET LOSS: 0.03278224542737007
2024-07-05 04:58:05,494 INFO     LM most common: [('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 534208), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0', 21105), ('1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0', 14308), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 13378), ('1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 12525), ('1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', 12254), ('1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', 11261), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0', 10964), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0', 10649), ('0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 10197), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0', 8198), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', 7573), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0', 7225), ('1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', 7085), ('1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 6869), ('1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 5505), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', 5477), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0', 5130), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0', 5020), ('1 1 1 0 0 0 0 0 1 1 1 0 0 1 0', 4782), ('1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 4671), ('1 1 1 0 0 0 0 0 1 1 0 0 0 0 0', 4273), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0', 4214), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', 4031), ('1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', 3991)]
2024-07-05 04:59:28,913 INFO     LM most common: [('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -0.02581612579524517), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0', -5.534778594970703), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -6.2116546630859375), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0', -6.5466461181640625), ('1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', -6.566288471221924), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', -6.593088626861572), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0', -6.614372253417969), ('1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', -6.761335372924805), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', -6.78093147277832), ('1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -6.906177043914795), ('1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0', -6.982121467590332), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', -7.204133987426758), ('1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -7.4472761154174805), ('1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', -7.475281715393066), ('0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -7.604808330535889), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0', -7.606662273406982), ('1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -7.656191349029541), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0', -8.04224681854248), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0', -8.08198356628418), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', -8.13463306427002), ('1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', -8.194276809692383), ('1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', -8.234275817871094), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0', -8.261943817138672), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0', -8.350189208984375), ('1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', -8.353852272033691)]
2024-07-05 04:59:28,913 INFO     LM-generated common sequences that are ungrammatical:
2024-07-05 04:59:28,913 INFO     ['1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0', '1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0', '0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0', '1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0', '1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0']
2024-07-05 04:59:28,913 INFO     Grammatical sequences that the model is missing:
2024-07-05 04:59:28,913 INFO     ['1 0', '0 1', '0 0 1 1', '1 0 0 1', '0 1 1 0', '0 1 0 1 0 1', '1 0 0 0 1 1', '1 1 0 0 0 1', '0 0 1 1 1 0', '1 0 1 0 1 0', '0 1 1 1 0 0', '0 0 0 1 1 1', '1 1 0 0 0 0 1 1', '0 1 1 1 1 0 0 0', '0 0 0 0 1 1 1 1', '0 1 0 1 1 0 1 0', '1 1 0 1 0 0 1 0', '1 0 1 0 0 1 0 1', '0 0 1 1 1 1 0 0', '1 0 0 1 0 1 1 0', '0 0 1 0 1 1 0 1']
2024-07-05 04:59:28,916 INFO     LM precision, recall, fscore: 0.0 0.16 0.0
2024-07-05 04:59:28,916 INFO     Memorization precision, recall, fscore: 0.0 0.0 0
2024-07-05 04:59:28,916 INFO     
2024-07-05 04:59:28,916 INFO     Average LM Y&P precision: 0.049999999999999996
2024-07-05 04:59:28,916 INFO     Average LM Y&P recall: 0.07999999999999999
2024-07-05 04:59:28,916 INFO     Average LM Y&P F-score: 0.0538095238095238
2024-07-05 04:59:28,916 INFO     
2024-07-05 04:59:28,916 INFO     Average memorization Y&P precision: 0.875
2024-07-05 04:59:28,916 INFO     Average memorization Y&P recall: 0.030000000000000002
2024-07-05 04:59:28,916 INFO     Average memorization Y&P F-score: 0.057692307692307696
2024-07-05 04:59:28,916 INFO     
