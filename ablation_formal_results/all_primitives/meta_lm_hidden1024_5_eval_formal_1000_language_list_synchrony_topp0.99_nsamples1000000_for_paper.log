2024-06-25 08:16:23,855 INFO     Namespace(n_meta_train=25000, n_meta_valid=500, n_meta_test=1000, meta_train_batch_size=10, meta_eval_batch_size=1000, max_batches_per_language=20, meta_train_size=10, meta_test_size=1000, dataset='scfg', yandp_param_file=None, formal_train_size=1000, formal_test_size=10, language_list='language_list_synchrony', withheld_languages='language_list', prior_flat=0.5, recursion_base=0.8, prob_1_flat=0.5, architecture='LSTM', n_embd=1024, n_positions=256, n_head=12, n_layer=2, dropout=0.1, n_epochs=1, eval_every=100, weight_decay=0.1, learning_rate=0.005, inner_lr=1.0, lr_scheduler_type='cosine', warmup_proportion=0.05, patience=None, lr_decay_patience=None, multi_step_loss=True, multi_step_loss_eval=False, pseudo=False, model_name='meta_lm_hidden1024_5', weight_dir='weights/', log_dir='logs/', save_optimizer_scheduler=False, load_saved=False, start_epoch=0, start_batch_index=0, start_total_updates=0, eval=True, eval_formal=True, eval_valid=False, eval_generate=False, eval_extrapolation=False, top_p=0.99, hot_temperature=1.0, cold_temperature=0.5, prec_rec_n_samples=1000000, sgd_epochs=10, adam_lr=0.0005, adam_epochs=5, eval_suffix='_for_paper', return_last=True)
2024-06-25 08:16:27,928 INFO     Model size: 16.8M parameters
2024-06-25 08:16:28,509 INFO     Loading model checkpoint from weights/meta_lm_hidden1024_5
2024-06-25 08:16:28,788 INFO     Language: XX
2024-06-25 08:16:28,788 INFO     Description: XX (two copies of the same string)
2024-06-25 08:16:37,911 INFO     DONE TRAINING
2024-06-25 08:16:38,282 INFO     TRAINING SET LOSS: 57.88567876815796
2024-06-25 09:22:34,030 INFO     LM most common: [('1 1', 168676), ('0 0', 140967), ('1 1 1 1', 51348), ('0 1 0 1', 43888), ('1 0 1 0', 35905), ('0 0 0 0', 35885), ('0 0 0 0 0 0', 32033), ('1 0 0 1 0 0', 23815), ('0 1 1 0 1 1', 21782), ('0 0 1 0 0 1', 20440), ('1 1 0 1 1 0', 20224), ('1 1 1 1 1 1', 16172), ('1 0 1 1 0 1', 15307), ('0 1 0 0 1 0', 14676), ('1 0 1 0 1 0 1 0', 12971), ('0 0 0 0 0 0 0 0', 10945), ('1 0 0 0 1 0 0 0', 10387), ('0 0 1 1 0 0 1 1', 9493), ('1 1 1 0 1 1 1 0', 7855), ('0 1 1 0 0 1 1 0', 7566), ('0 0 0 1 0 0 0 1', 7549), ('1 0 0 1 1 0 0 1', 6369), ('0 0 1 0 0 0 1 0', 6234), ('0 0 1 0 1 0 0 1 0 1', 5176), ('0 1 0 0 0 1 0 0', 5147)]
2024-06-25 09:24:35,763 INFO     LM most common: [('1 1', -1.3362360000610352), ('0 0', -1.6213877201080322), ('0 0 0 0 0 0', -2.679060697555542), ('1 1 1 1', -2.68040132522583), ('1 0 1 0', -3.047607421875), ('0 1 0 1', -3.1625428199768066), ('0 0 0 0', -3.16644287109375), ('0 0 1 0 0 1', -3.592503309249878), ('1 0 0 1 0 0', -3.8821816444396973), ('1 0 1 0 1 0 1 0', -3.9618892669677734), ('0 1 1 0 1 1', -3.990164279937744), ('1 0 1 1 0 1', -4.003969192504883), ('1 1 1 1 1 1', -4.149895191192627), ('0 0 0 0 0 0 0 0', -4.199408054351807), ('1 1 0 1 1 0', -4.28496789932251), ('0 1 0 0 1 0', -4.649704933166504), ('1 0 0 1 1 0 0 1', -4.6872239112854), ('0 0 1 1 0 0 1 1', -4.851821422576904), ('1 0 0 0 1 0 0 0', -4.962776184082031), ('0 0 0 1 0 0 0 1', -5.260687828063965), ('1 0 1 0 0 1 0 1 0 0', -5.464782238006592), ('0 0 1 0 0 0 1 0', -5.484657287597656), ('0 0 1 0 1 0 0 1 0 1', -5.684932231903076), ('0 1 1 0 0 1 1 0', -5.724063873291016), ('1 0 1 1 1 0 1 1', -5.871243000030518)]
2024-06-25 09:24:35,763 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 09:24:35,764 INFO     []
2024-06-25 09:24:35,764 INFO     Grammatical sequences that the model is missing:
2024-06-25 09:24:35,764 INFO     []
2024-06-25 09:24:35,769 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 09:24:35,769 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 09:24:35,769 INFO     
2024-06-25 09:24:35,876 INFO     Language: XXX
2024-06-25 09:24:35,877 INFO     Description: XXX
2024-06-25 09:24:48,037 INFO     DONE TRAINING
2024-06-25 09:24:48,491 INFO     TRAINING SET LOSS: 41.476552069187164
2024-06-25 10:55:06,885 INFO     LM most common: [('1 1 1', 176465), ('0 0 0', 175841), ('1 0 1 0 1 0', 85659), ('1 1 1 1 1 1', 64152), ('0 1 0 1 0 1', 57329), ('0 0 0 0 0 0', 52890), ('0 0 1 0 0 1 0 0 1', 28970), ('0 1 1 0 1 1 0 1 1', 28133), ('1 1 0 1 1 0 1 1 0', 22316), ('1 0 1 1 0 1 1 0 1', 20289), ('1 1 1 1 1 1 1 1 1', 17570), ('0 1 0 0 1 0 0 1 0', 14182), ('1 0 0 1 0 0 1 0 0', 13024), ('0 0 0 0 0 0 0 0 0', 9852), ('0 1 0 0 0 1 0 0 0 1 0 0', 8482), ('0 0 1 0 0 0 1 0 0 0 1 0', 8281), ('1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 7909), ('1 1 1 0 1 1 1 0 1 1 1 0', 6397), ('1 0 0 1 1 0 0 1 1 0 0 1', 5918), ('0 1 1 1 0 1 1 1 0 1 1 1', 5696), ('1 1 1 1 1 1 1 1 1 1 1 1', 5571), ('0 0 0 1 0 0 0 1 0 0 0 1', 5461), ('1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1', 5144), ('1 1 0 0 1 1 0 0 1 1 0 0', 4641), ('0 0 1 1 0 0 1 1 0 0 1 1', 4197)]
2024-06-25 10:56:38,213 INFO     LM most common: [('1 1 1', -1.179155945777893), ('0 0 0', -1.217472791671753), ('1 0 1 0 1 0', -2.3446226119995117), ('1 1 1 1 1 1', -2.430361747741699), ('0 0 0 0 0 0', -3.0363211631774902), ('0 1 0 1 0 1', -3.1027660369873047), ('0 0 1 0 0 1 0 0 1', -4.1640706062316895), ('0 1 1 0 1 1 0 1 1', -4.311458587646484), ('1 1 1 1 1 1 1 1 1', -4.331709384918213), ('1 0 1 1 0 1 1 0 1', -4.452938556671143), ('1 1 0 1 1 0 1 1 0', -4.693911075592041), ('1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.7791266441345215), ('0 1 0 0 1 0 0 1 0', -5.056269645690918), ('1 0 0 1 0 0 1 0 0', -5.147634506225586), ('0 0 0 0 0 0 0 0 0', -5.747440338134766), ('0 1 0 0 0 1 0 0 0 1 0 0', -5.850750923156738), ('1 1 1 1 1 1 1 1 1 1 1 1', -6.039862155914307), ('0 0 1 0 0 0 1 0 0 0 1 0', -6.122218132019043), ('1 0 0 1 1 0 0 1 1 0 0 1', -6.132327079772949), ('1 0 0 0 1 1 0 0 0 1 1 0 0 0 1', -6.496057033538818), ('1 1 1 0 1 1 1 0 1 1 1 0', -6.617218017578125), ('1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.674385070800781), ('0 0 0 1 0 0 0 1 0 0 0 1', -6.7456231117248535), ('0 0 1 1 0 0 1 1 0 0 1 1', -6.779247283935547), ('1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1', -6.80787992477417)]
2024-06-25 10:56:38,214 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 10:56:38,214 INFO     []
2024-06-25 10:56:38,214 INFO     Grammatical sequences that the model is missing:
2024-06-25 10:56:38,214 INFO     []
2024-06-25 10:56:38,217 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 10:56:38,218 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 10:56:38,218 INFO     
2024-06-25 10:56:38,278 INFO     Language: AnBnCn
2024-06-25 10:56:38,278 INFO     Description: A^n B^n C^n
2024-06-25 10:56:50,463 INFO     DONE TRAINING
2024-06-25 10:56:50,920 INFO     TRAINING SET LOSS: 19.40817593038082
2024-06-25 12:34:00,805 INFO     LM most common: [('0 1 2', 324795), ('0 0 1 1 2 2', 231659), ('0 0 0 1 1 1 2 2 2', 147935), ('0 0 0 0 1 1 1 1 2 2 2 2', 103405), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', 60748), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 39064), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', 34908), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 14991), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', 14888), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 7676), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', 6001), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', 3860), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 3034), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1769), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1652), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 942), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 751), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 515), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 340), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 246), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 237), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 136), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 99), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 57), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 52)]
2024-06-25 12:34:01,221 INFO     LM most common: [('0 1 2', -1.6685128211975098), ('0 0 1 1 2 2', -1.753095269203186), ('0 0 0 1 1 1 2 2 2', -2.054312229156494), ('0 0 0 0 1 1 1 1 2 2 2 2', -2.1609885692596436), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -2.388029098510742), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', -2.663212776184082), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -3.2334330081939697), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', -3.293182373046875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.8087501525878906), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', -3.8342196941375732), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', -4.034958362579346), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -4.070069313049316), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.415742874145508), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.811250686645508), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.973235607147217), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.024864673614502), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.082213878631592), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.3242316246032715), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.332918643951416), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.840558052062988), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.856378078460693), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.0441741943359375), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.1159138679504395), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.243544101715088), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.299887180328369)]
2024-06-25 12:34:01,221 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 12:34:01,221 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2024-06-25 12:34:01,221 INFO     Grammatical sequences that the model is missing:
2024-06-25 12:34:01,221 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2024-06-25 12:34:01,221 INFO     LM precision, recall, fscore: 0.92 0.96 0.9395744680851065
2024-06-25 12:34:01,221 INFO     Memorization precision, recall, fscore: 1.0 0.76 0.8636363636363636
2024-06-25 12:34:01,221 INFO     
2024-06-25 12:34:01,293 INFO     Language: AnBnCnDn
2024-06-25 12:34:01,293 INFO     Description: A^n B^n C^n D^n
2024-06-25 12:34:16,959 INFO     DONE TRAINING
2024-06-25 12:34:17,510 INFO     TRAINING SET LOSS: 14.835404373705387
2024-06-25 15:09:07,408 INFO     LM most common: [('0 1 2 3', 347757), ('0 0 1 1 2 2 3 3', 200877), ('0 0 0 1 1 1 2 2 2 3 3 3', 141670), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', 100656), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', 63218), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', 43525), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', 39820), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', 17941), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', 16961), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', 8166), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', 5071), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', 3907), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', 3738), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 1896), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 1741), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 838), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 528), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 438), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 433), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 245), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 191), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 93), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 65), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 57), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 52)]
2024-06-25 15:09:07,783 INFO     LM most common: [('0 1 2 3', -1.510481595993042), ('0 0 1 1 2 2 3 3', -2.0490050315856934), ('0 0 0 1 1 1 2 2 2 3 3 3', -2.1853315830230713), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', -2.2663397789001465), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', -2.412623882293701), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', -2.6584484577178955), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', -2.8493754863739014), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', -2.899397373199463), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', -3.629971981048584), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', -3.8429102897644043), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', -3.8803300857543945), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -4.001420021057129), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', -4.373416423797607), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', -4.384579658508301), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -4.946624279022217), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.078099727630615), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.083408355712891), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.231198787689209), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.585683822631836), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.755375385284424), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.10638427734375), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.145457744598389), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.351501941680908), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.633981704711914), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.876258850097656)]
2024-06-25 15:09:07,785 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 15:09:07,785 INFO     []
2024-06-25 15:09:07,785 INFO     Grammatical sequences that the model is missing:
2024-06-25 15:09:07,785 INFO     []
2024-06-25 15:09:07,785 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 15:09:07,785 INFO     Memorization precision, recall, fscore: 1.0 0.68 0.8095238095238095
2024-06-25 15:09:07,785 INFO     
2024-06-25 15:09:07,860 INFO     Language: AnBnCnDnEn
2024-06-25 15:09:07,861 INFO     Description: A^n B^n C^n D^n E^n
2024-06-25 15:09:25,125 INFO     DONE TRAINING
2024-06-25 15:09:25,673 INFO     TRAINING SET LOSS: 12.275165610015392
2024-06-25 17:44:07,639 INFO     LM most common: [('0 1 2 3 4', 391783), ('0 0 1 1 2 2 3 3 4 4', 261203), ('0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', 133452), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', 78797), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 50982), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', 34413), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', 15809), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', 10897), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', 10037), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', 4109), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', 3095), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', 2371), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 860), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', 784), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 619), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 224), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 204), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 145), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 60), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 48), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 33), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 15), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', 12), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', 9), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 4)]
2024-06-25 17:44:07,977 INFO     LM most common: [('0 1 2 3 4', -1.23276686668396), ('0 0 1 1 2 2 3 3 4 4', -1.3614044189453125), ('0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', -2.06265926361084), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', -2.499988555908203), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -2.7146482467651367), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', -2.860152244567871), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', -3.3456196784973145), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', -3.812152862548828), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', -4.192758560180664), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', -4.510250091552734), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', -4.645275592803955), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', -4.695198059082031), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.033200263977051), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.27186918258667), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.311334133148193), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.331039905548096), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.561612606048584), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.687110424041748), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.8852057456970215), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -8.2781982421875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -8.317146301269531), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -13.782853126525879), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -13.80823040008545), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -14.255002975463867), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -14.433870315551758)]
2024-06-25 17:44:07,980 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 17:44:07,980 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4']
2024-06-25 17:44:07,980 INFO     Grammatical sequences that the model is missing:
2024-06-25 17:44:07,980 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4']
2024-06-25 17:44:07,982 INFO     LM precision, recall, fscore: 0.84 0.84 0.8399999999999999
2024-06-25 17:44:07,982 INFO     Memorization precision, recall, fscore: 1.0 0.6 0.7499999999999999
2024-06-25 17:44:07,982 INFO     
2024-06-25 17:44:08,151 INFO     Language: AnBmCnDm
2024-06-25 17:44:08,151 INFO     Description: A^n B^m C^n D^m
2024-06-25 17:44:20,878 INFO     DONE TRAINING
2024-06-25 17:44:21,375 INFO     TRAINING SET LOSS: 29.584929823875427
2024-06-25 18:30:56,548 INFO     LM most common: [('0 1 2 3', 115935), ('0 0 1 2 2 3', 86533), ('0 1 1 2 3 3', 83077), ('0 1 1 1 2 3 3 3', 63589), ('0 0 0 1 2 2 2 3', 56353), ('0 0 1 1 2 2 3 3', 47215), ('0 0 0 0 1 2 2 2 2 3', 42302), ('0 0 0 1 1 2 2 2 3 3', 38551), ('0 1 1 1 1 2 3 3 3 3', 37401), ('0 0 1 1 1 2 2 3 3 3', 27373), ('0 0 1 1 1 1 2 2 3 3 3 3', 22625), ('0 0 0 0 0 1 2 2 2 2 2 3', 21131), ('0 1 1 1 1 1 2 3 3 3 3 3', 20555), ('0 0 0 0 0 0 1 2 2 2 2 2 2 3', 19991), ('0 1 1 1 1 1 1 2 3 3 3 3 3 3', 16312), ('0 0 0 1 1 1 2 2 2 3 3 3', 16138), ('0 0 0 0 1 1 2 2 2 2 3 3', 16103), ('0 0 0 1 1 1 1 2 2 2 3 3 3 3', 13207), ('0 0 1 1 1 1 1 2 2 3 3 3 3 3', 12494), ('0 0 0 0 1 1 1 2 2 2 2 3 3 3', 11058), ('0 0 0 0 0 1 1 2 2 2 2 2 3 3', 10987), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', 9703), ('0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3', 9249), ('0 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3', 8680), ('0 0 1 1 1 1 1 1 2 2 3 3 3 3 3 3', 8304)]
2024-06-25 18:30:58,296 INFO     LM most common: [('0 0 1 2 2 3', -3.0235722064971924), ('0 1 1 1 2 3 3 3', -3.085156202316284), ('0 1 2 3', -3.119821548461914), ('0 1 1 2 3 3', -3.2017581462860107), ('0 0 0 0 1 2 2 2 2 3', -3.209902763366699), ('0 0 0 1 2 2 2 3', -3.2708349227905273), ('0 0 0 1 1 2 2 2 3 3', -3.3617959022521973), ('0 0 0 0 0 0 1 2 2 2 2 2 2 3', -3.4492571353912354), ('0 1 1 1 1 2 3 3 3 3', -3.5312318801879883), ('0 0 1 1 2 2 3 3', -3.6330602169036865), ('0 0 1 1 1 1 2 2 3 3 3 3', -3.883906364440918), ('0 1 1 1 1 1 1 2 3 3 3 3 3 3', -4.006962299346924), ('0 0 0 0 0 1 2 2 2 2 2 3', -4.059345245361328), ('0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 3', -4.088466167449951), ('0 1 1 1 1 1 2 3 3 3 3 3', -4.1551971435546875), ('0 0 1 1 1 2 2 3 3 3', -4.157154560089111), ('0 0 0 0 0 0 1 1 1 2 2 2 2 2 2 3 3 3', -4.215545654296875), ('0 0 0 1 1 1 1 2 2 2 3 3 3 3', -4.29970121383667), ('0 0 0 0 0 1 1 1 1 2 2 2 2 2 3 3 3 3', -4.34690523147583), ('0 1 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3 3', -4.3716535568237305), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', -4.396779537200928), ('0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 3 3 3', -4.439310073852539), ('0 0 1 1 1 1 1 2 2 3 3 3 3 3', -4.465744972229004), ('0 0 0 1 1 1 2 2 2 3 3 3', -4.531600475311279), ('0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3', -4.548632621765137)]
2024-06-25 18:30:58,296 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 18:30:58,296 INFO     []
2024-06-25 18:30:58,296 INFO     Grammatical sequences that the model is missing:
2024-06-25 18:30:58,296 INFO     []
2024-06-25 18:30:58,296 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 18:30:58,296 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 18:30:58,296 INFO     
2024-06-25 18:30:58,384 INFO     Language: AnBmAnBm
2024-06-25 18:30:58,385 INFO     Description: A^n B^m A^n B^m
2024-06-25 18:31:11,468 INFO     DONE TRAINING
2024-06-25 18:31:11,930 INFO     TRAINING SET LOSS: 29.60222029685974
2024-06-25 19:45:54,539 INFO     LM most common: [('0 1 0 1', 104026), ('0 1 1 0 1 1', 71251), ('0 0 1 0 0 1', 58340), ('0 0 1 1 0 0 1 1', 52303), ('0 0 0 1 0 0 0 1', 52150), ('0 1 1 1 0 1 1 1', 46934), ('0 0 1 1 1 0 0 1 1 1', 35851), ('0 1 1 1 1 0 1 1 1 1', 35520), ('0 0 0 1 1 0 0 0 1 1', 32971), ('0 0 0 0 1 0 0 0 0 1', 24646), ('0 0 0 1 1 1 0 0 0 1 1 1', 22533), ('0 0 0 0 0 1 0 0 0 0 0 1', 22340), ('0 0 1 1 1 1 0 0 1 1 1 1', 21690), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1', 21134), ('0 0 0 0 1 1 0 0 0 0 1 1', 20809), ('0 1 1 1 1 1 0 1 1 1 1 1', 18654), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1', 17469), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1', 17252), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1', 16975), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1', 13849), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', 13463), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1', 12488), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1', 10039), ('0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1', 9793), ('0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1', 9330)]
2024-06-25 19:45:58,059 INFO     LM most common: [('0 1 0 1', -3.378129482269287), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1', -3.5459234714508057), ('0 1 1 0 1 1', -3.5569849014282227), ('0 0 0 1 0 0 0 1', -3.5652294158935547), ('0 0 1 1 0 0 1 1', -3.678839921951294), ('0 1 1 1 1 0 1 1 1 1', -3.8178367614746094), ('0 1 1 1 0 1 1 1', -3.8406152725219727), ('0 0 1 1 1 0 0 1 1 1', -3.844491481781006), ('0 0 0 1 1 0 0 0 1 1', -3.906278610229492), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', -4.033923625946045), ('0 0 1 0 0 1', -4.03980016708374), ('0 0 0 1 1 1 0 0 0 1 1 1', -4.046339511871338), ('0 0 0 0 0 1 0 0 0 0 0 1', -4.133017539978027), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1', -4.146090984344482), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1', -4.183964729309082), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1', -4.251760482788086), ('0 0 1 1 1 1 0 0 1 1 1 1', -4.282279014587402), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1', -4.409368991851807), ('0 0 0 0 1 1 0 0 0 0 1 1', -4.41862154006958), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1', -4.4436869621276855), ('0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1', -4.581984996795654), ('0 0 0 0 1 0 0 0 0 1', -4.604821681976318), ('0 1 1 1 1 1 0 1 1 1 1 1', -4.619874000549316), ('0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1', -4.656911849975586), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -4.709723472595215)]
2024-06-25 19:45:58,080 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 19:45:58,080 INFO     []
2024-06-25 19:45:58,080 INFO     Grammatical sequences that the model is missing:
2024-06-25 19:45:58,080 INFO     []
2024-06-25 19:45:58,080 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 19:45:58,080 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 19:45:58,080 INFO     
2024-06-25 19:45:58,174 INFO     Language: XXI
2024-06-25 19:45:58,174 INFO     Description: X X^I (where X^I is the inverse of X - replace every A with B and vice-versa)
2024-06-25 19:46:07,145 INFO     DONE TRAINING
2024-06-25 19:46:07,504 INFO     TRAINING SET LOSS: 57.76978087425232
2024-06-25 20:27:50,118 INFO     LM most common: [('0 1', 219701), ('1 0', 179616), ('0 1 1 0', 74314), ('1 0 0 1', 70688), ('0 0 1 1', 64044), ('1 1 0 0', 53813), ('1 0 0 0 1 1', 23356), ('1 0 1 0 1 0', 21107), ('1 1 0 0 0 1', 17585), ('0 0 1 1 1 0', 17072), ('0 1 1 1 0 0', 16994), ('0 0 0 1 1 1', 16245), ('0 1 0 1 0 1', 15120), ('1 1 1 0 0 0', 8903), ('1 0 0 1 0 1 1 0', 8161), ('1 0 0 0 0 1 1 1', 8048), ('0 1 0 0 1 0 1 1', 6524), ('1 1 0 0 0 0 1 1', 5881), ('0 0 0 0 1 1 1 1', 5765), ('1 1 1 1 0 0 0 0', 5696), ('0 1 1 1 1 0 0 0', 5677), ('0 0 0 1 1 1 1 0', 5180), ('1 1 1 0 0 0 0 1', 4981), ('1 1 0 0 0 0 0 1 1 1', 4957), ('1 1 1 0 0 0 0 0 1 1', 4936)]
2024-06-25 20:28:20,463 INFO     LM most common: [('0 1', -1.046452283859253), ('1 0', -1.337765097618103), ('1 0 0 1', -2.2037408351898193), ('0 1 1 0', -2.581770658493042), ('0 0 1 1', -2.8988196849823), ('1 1 0 0', -3.2377710342407227), ('1 0 0 0 1 1', -3.7492637634277344), ('1 0 1 0 1 0', -4.578459739685059), ('0 1 1 1 0 0', -4.747184753417969), ('1 1 0 0 0 1', -4.828856945037842), ('0 0 1 1 1 0', -5.064937591552734), ('0 1 0 1 0 1', -5.076032638549805), ('0 0 0 1 1 1', -5.252134323120117), ('1 0 0 1 0 1 1 0', -5.52557373046875), ('1 0 0 0 0 1 1 1', -5.814012050628662), ('1 1 1 0 0 0', -5.952091693878174), ('1 1 1 0 0 0 0 0 1 1', -6.006784915924072), ('1 1 0 0 0 0 1 1', -6.230302810668945), ('0 1 0 0 1 0 1 1', -6.314321517944336), ('1 1 0 0 0 0 0 1 1 1', -6.400413990020752), ('0 1 1 1 1 0 0 0', -6.420652389526367), ('1 1 1 0 0 0 0 1', -6.477345943450928), ('1 1 1 1 0 0 0 0', -6.542950630187988), ('1 0 1 1 0 1 0 0', -6.762816429138184), ('0 0 0 0 1 1 1 1', -6.935204982757568)]
2024-06-25 20:28:20,463 INFO     LM-generated common sequences that are ungrammatical:
2024-06-25 20:28:20,463 INFO     []
2024-06-25 20:28:20,463 INFO     Grammatical sequences that the model is missing:
2024-06-25 20:28:20,463 INFO     []
2024-06-25 20:28:20,465 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 20:28:20,474 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2024-06-25 20:28:20,474 INFO     
2024-06-25 20:28:20,474 INFO     Average LM Y&P precision: 0.97
2024-06-25 20:28:20,474 INFO     Average LM Y&P recall: 0.975
2024-06-25 20:28:20,484 INFO     Average LM Y&P F-score: 0.9724468085106384
2024-06-25 20:28:20,484 INFO     
2024-06-25 20:28:20,484 INFO     Average memorization Y&P precision: 1.0
2024-06-25 20:28:20,484 INFO     Average memorization Y&P recall: 0.88
2024-06-25 20:28:20,484 INFO     Average memorization Y&P F-score: 0.9278950216450217
2024-06-25 20:28:20,484 INFO     
