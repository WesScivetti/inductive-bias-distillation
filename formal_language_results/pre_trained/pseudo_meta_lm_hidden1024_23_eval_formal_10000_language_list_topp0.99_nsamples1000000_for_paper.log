2023-05-02 08:05:22,107 INFO     Namespace(n_meta_train=25000, n_meta_valid=500, n_meta_test=1000, meta_train_batch_size=10, meta_eval_batch_size=1000, max_batches_per_language=20, meta_train_size=10, meta_test_size=1000, dataset='scfg', yandp_param_file=None, formal_train_size=10000, formal_test_size=10, language_list='language_list', withheld_languages='language_list', architecture='LSTM', n_embd=1024, n_positions=256, n_head=12, n_layer=2, dropout=0.1, n_epochs=1, eval_every=100, weight_decay=0.1, learning_rate=0.005, inner_lr=1.0, lr_scheduler_type='cosine', warmup_proportion=0.05, patience=None, lr_decay_patience=None, multi_step_loss=True, model_name='pseudo_meta_lm_hidden1024_23', weight_dir='/scratch/gpfs/tm4633/inductive_bias_distillation/weights/', log_dir='/scratch/gpfs/tm4633/inductive_bias_distillation/logs/', eval=True, eval_formal=True, eval_valid=False, top_p=0.99, hot_temperature=1.0, cold_temperature=0.5, prec_rec_n_samples=1000000, sgd_epochs=5, adam_lr=0.0005, adam_epochs=5, eval_suffix='_for_paper', random_normalized=False, return_last=True, force_precision_denominator=False)
2023-05-02 08:05:26,388 INFO     Model size: 16.8M parameters
2023-05-02 08:05:26,389 INFO     Loading model checkpoint from /scratch/gpfs/tm4633/inductive_bias_distillation/weights/pseudo_meta_lm_hidden1024_23
2023-05-02 08:05:26,741 INFO     Language: An
2023-05-02 08:05:26,742 INFO     Description: Any number of As
2023-05-02 08:05:51,062 INFO     DONE TRAINING
2023-05-02 08:05:51,824 INFO     TRAINING SET LOSS: 479.4974780380726
2023-05-02 08:07:45,575 INFO     LM most common: [('0', 367489), ('0 0', 216322), ('0 0 0', 145487), ('0 0 0 0', 94186), ('0 0 0 0 0', 61638), ('0 0 0 0 0 0', 40143), ('0 0 0 0 0 0 0', 26035), ('0 0 0 0 0 0 0 0', 17012), ('0 0 0 0 0 0 0 0 0', 11121), ('0 0 0 0 0 0 0 0 0 0', 7162), ('0 0 0 0 0 0 0 0 0 0 0', 4650), ('0 0 0 0 0 0 0 0 0 0 0 0', 3157), ('0 0 0 0 0 0 0 0 0 0 0 0 0', 1924), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1329), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 826), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 503), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 342), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 233), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 146), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 97), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 68), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 41), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 33), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 20), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 11)]
2023-05-02 08:07:45,609 INFO     LM most common: [('0', -1.3761603832244873), ('0 0', -1.846369743347168), ('0 0 0', -2.0269546508789062), ('0 0 0 0', -2.281050443649292), ('0 0 0 0 0', -2.533723831176758), ('0 0 0 0 0 0', -2.786860466003418), ('0 0 0 0 0 0 0', -3.0398950576782227), ('0 0 0 0 0 0 0 0', -3.292797803878784), ('0 0 0 0 0 0 0 0 0', -3.5454769134521484), ('0 0 0 0 0 0 0 0 0 0', -3.7979085445404053), ('0 0 0 0 0 0 0 0 0 0 0', -4.050090312957764), ('0 0 0 0 0 0 0 0 0 0 0 0', -4.30200719833374), ('0 0 0 0 0 0 0 0 0 0 0 0 0', -4.553657531738281), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.805039882659912), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.056142807006836), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.306962490081787), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.557514190673828), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.807796478271484), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.057806491851807), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.3075480461120605), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.557019233703613), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.806222915649414), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.0551605224609375), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.303832530975342), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.552249431610107)]
2023-05-02 08:07:45,609 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:07:45,609 INFO     []
2023-05-02 08:07:45,610 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:07:45,610 INFO     []
2023-05-02 08:07:45,610 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:07:45,610 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 08:07:45,610 INFO     
2023-05-02 08:07:45,922 INFO     Language: AB
2023-05-02 08:07:45,922 INFO     Description: Sigma* over {A, B}
2023-05-02 08:08:09,954 INFO     DONE TRAINING
2023-05-02 08:08:10,719 INFO     TRAINING SET LOSS: 991.6994476318359
2023-05-02 08:10:09,883 INFO     LM most common: [('1', 180631), ('0', 172768), ('1 1', 58292), ('0 1', 57350), ('1 0', 56588), ('0 0', 54786), ('1 0 1', 18556), ('1 1 0', 18076), ('0 1 0', 17774), ('1 0 0', 17729), ('0 0 1', 17707), ('1 1 1', 17698), ('0 1 1', 17198), ('0 0 0', 17102), ('1 0 0 1', 6287), ('1 0 1 1', 6191), ('0 1 0 1', 6181), ('1 1 0 1', 6080), ('0 0 0 1', 6070), ('0 0 1 0', 6023), ('1 0 1 0', 6021), ('1 1 1 1', 5988), ('0 0 1 1', 5941), ('1 1 0 0', 5907), ('1 0 0 0', 5809)]
2023-05-02 08:10:21,146 INFO     LM most common: [('1', -1.6349247694015503), ('0', -1.7173888683319092), ('1 1', -2.795164108276367), ('0 1', -2.829536199569702), ('1 0', -2.859389543533325), ('0 0', -2.926453113555908), ('1 0 1', -4.00252628326416), ('1 1 0', -4.050534725189209), ('1 1 1', -4.062150478363037), ('0 0 1', -4.066195487976074), ('1 0 0', -4.07298469543457), ('0 1 0', -4.085031509399414), ('0 1 1', -4.118575096130371), ('0 0 0', -4.132439613342285), ('1 1 0 1', -5.0734968185424805), ('1 0 1 1', -5.0902509689331055), ('1 0 0 1', -5.0903425216674805), ('0 1 0 1', -5.119956970214844), ('1 0 1 0', -5.130285739898682), ('1 1 1 1', -5.149021148681641), ('0 0 0 1', -5.1595563888549805), ('0 0 1 1', -5.170230388641357), ('1 1 0 0', -5.182224273681641), ('1 0 0 0', -5.193086624145508), ('0 0 1 0', -5.196164131164551)]
2023-05-02 08:10:21,146 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:10:21,146 INFO     []
2023-05-02 08:10:21,146 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:10:21,146 INFO     []
2023-05-02 08:10:21,147 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:10:21,147 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:10:21,147 INFO     
2023-05-02 08:10:21,524 INFO     Language: ABn
2023-05-02 08:10:21,524 INFO     Description: (AB)^n
2023-05-02 08:10:53,268 INFO     DONE TRAINING
2023-05-02 08:10:54,281 INFO     TRAINING SET LOSS: 275.345844194293
2023-05-02 08:16:27,296 INFO     LM most common: [('0 1', 356241), ('0 1 0 1', 234050), ('0 1 0 1 0 1', 145176), ('0 1 0 1 0 1 0 1', 93946), ('0 1 0 1 0 1 0 1 0 1', 61297), ('0 1 0 1 0 1 0 1 0 1 0 1', 38994), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', 25080), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 16160), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 10294), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 6723), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 4312), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 2726), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1807), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1157), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 712), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 471), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 297), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 184), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 127), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 79), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 66), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 39), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 27), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 12), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 10)]
2023-05-02 08:16:27,336 INFO     LM most common: [('0 1', -1.4475511312484741), ('0 1 0 1', -1.671205997467041), ('0 1 0 1 0 1', -2.02054500579834), ('0 1 0 1 0 1 0 1', -2.26621675491333), ('0 1 0 1 0 1 0 1 0 1', -2.525430202484131), ('0 1 0 1 0 1 0 1 0 1 0 1', -2.790163516998291), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.055396556854248), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.322384834289551), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.5908780097961426), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.8604989051818848), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.131069183349609), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.402406692504883), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.67437219619751), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.946863174438477), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.219786167144775), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.4931111335754395), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.766775608062744), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.040722370147705), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.314932346343994), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.589375972747803), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.864034175872803), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.138869762420654), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.413885593414307), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.689061641693115), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.964377403259277)]
2023-05-02 08:16:27,336 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:16:27,336 INFO     []
2023-05-02 08:16:27,336 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:16:27,336 INFO     []
2023-05-02 08:16:27,337 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:16:27,337 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 08:16:27,337 INFO     
2023-05-02 08:16:27,534 INFO     Language: AAA
2023-05-02 08:16:27,535 INFO     Description: A, AA, or AAA
2023-05-02 08:16:45,583 INFO     DONE TRAINING
2023-05-02 08:16:46,225 INFO     TRAINING SET LOSS: 369.4902363419533
2023-05-02 08:17:20,861 INFO     LM most common: [('0', 566637), ('0 0', 277214), ('0 0 0', 156149)]
2023-05-02 08:17:20,864 INFO     LM most common: [('0', -0.4581204950809479), ('0 0', -1.2771202325820923), ('0 0 0', -2.4226126670837402)]
2023-05-02 08:17:20,864 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:17:20,864 INFO     []
2023-05-02 08:17:20,864 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:17:20,864 INFO     []
2023-05-02 08:17:20,864 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:17:20,864 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:17:20,865 INFO     
2023-05-02 08:17:21,067 INFO     Language: AAAA
2023-05-02 08:17:21,068 INFO     Description: A, AA, AAA, or AAAA
2023-05-02 08:17:39,739 INFO     DONE TRAINING
2023-05-02 08:17:40,402 INFO     TRAINING SET LOSS: 412.4623773097992
2023-05-02 08:18:17,613 INFO     LM most common: [('0', 567871), ('0 0', 255410), ('0 0 0', 125607), ('0 0 0 0', 51112)]
2023-05-02 08:18:17,617 INFO     LM most common: [('0', -0.45559078454971313), ('0 0', -1.3976061344146729), ('0 0 0', -2.2875778675079346), ('0 0 0 0', -4.061290740966797)]
2023-05-02 08:18:17,617 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:18:17,617 INFO     []
2023-05-02 08:18:17,617 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:18:17,617 INFO     []
2023-05-02 08:18:17,617 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:18:17,617 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:18:17,617 INFO     
2023-05-02 08:18:17,966 INFO     Language: AnBm
2023-05-02 08:18:17,966 INFO     Description: A^n B^m (n and m can be equal)
2023-05-02 08:18:46,524 INFO     DONE TRAINING
2023-05-02 08:18:47,431 INFO     TRAINING SET LOSS: 549.4633455276489
2023-05-02 08:21:50,288 INFO     LM most common: [('0 1', 118612), ('0 0 1', 79011), ('0 1 1', 76761), ('0 0 1 1', 50668), ('0 1 1 1', 50643), ('0 0 0 1', 50241), ('0 1 1 1 1', 33663), ('0 0 1 1 1', 33225), ('0 0 0 0 1', 33111), ('0 0 0 1 1', 32635), ('0 1 1 1 1 1', 22455), ('0 0 1 1 1 1', 22263), ('0 0 0 0 1 1', 21664), ('0 0 0 0 0 1', 21512), ('0 0 0 1 1 1', 21259), ('0 1 1 1 1 1 1', 14685), ('0 0 1 1 1 1 1', 14604), ('0 0 0 0 0 0 1', 14522), ('0 0 0 0 0 1 1', 14153), ('0 0 0 1 1 1 1', 14135), ('0 0 0 0 1 1 1', 13915), ('0 0 0 0 0 0 0 1', 9565), ('0 0 1 1 1 1 1 1', 9539), ('0 0 0 0 0 0 1 1', 9495), ('0 1 1 1 1 1 1 1', 9470)]
2023-05-02 08:21:50,822 INFO     LM most common: [('0 1', -3.061741828918457), ('0 0 1', -3.273189067840576), ('0 1 1', -3.3418376445770264), ('0 0 1 1', -3.5507078170776367), ('0 1 1 1', -3.5799617767333984), ('0 0 0 1', -3.5834951400756836), ('0 1 1 1 1', -3.799130439758301), ('0 0 1 1 1', -3.800034999847412), ('0 0 0 0 1', -3.815901279449463), ('0 0 0 1 1', -3.851457118988037), ('0 0 1 1 1 1', -4.024168968200684), ('0 1 1 1 1 1', -4.026658535003662), ('0 0 0 0 0 1', -4.053555965423584), ('0 0 0 0 1 1', -4.078495025634766), ('0 0 0 1 1 1', -4.1002960205078125), ('0 1 1 1 1 1 1', -4.256594181060791), ('0 0 1 1 1 1 1', -4.257254600524902), ('0 0 0 0 0 0 1', -4.290315628051758), ('0 0 0 0 0 1 1', -4.3112101554870605), ('0 0 0 1 1 1 1', -4.324753761291504), ('0 0 0 0 1 1 1', -4.327856540679932), ('0 1 1 1 1 1 1 1', -4.489767074584961), ('0 0 1 1 1 1 1 1', -4.49195671081543), ('0 0 0 0 0 0 0 1', -4.527338027954102), ('0 0 0 0 0 0 1 1', -4.543246746063232)]
2023-05-02 08:21:50,822 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:21:50,822 INFO     []
2023-05-02 08:21:50,822 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:21:50,822 INFO     []
2023-05-02 08:21:50,822 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:21:50,822 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:21:50,823 INFO     
2023-05-02 08:21:51,146 INFO     Language: GoldenMean
2023-05-02 08:21:51,146 INFO     Description: Strings over {A, B} where no 2 A's ever appear in a row
2023-05-02 08:22:15,160 INFO     DONE TRAINING
2023-05-02 08:22:15,932 INFO     TRAINING SET LOSS: 867.1001204252243
2023-05-02 08:24:15,594 INFO     LM most common: [('0', 191354), ('1', 175552), ('0 1', 113109), ('1 0', 57778), ('1 1', 50405), ('0 1 0', 40035), ('0 1 1', 35793), ('1 0 1', 34568), ('0 1 0 1', 23605), ('1 1 0', 17427), ('1 1 1', 14152), ('0 1 1 0', 13151), ('1 0 1 0', 12925), ('1 0 1 1', 11747), ('0 1 1 1', 11348), ('1 1 0 1', 10309), ('0 1 0 1 0', 8462), ('0 1 1 0 1', 8024), ('1 0 1 0 1', 7977), ('0 1 0 1 1', 7914), ('0 1 0 1 0 1', 5356), ('1 1 1 0', 5144), ('1 0 1 1 0', 4444), ('1 1 1 1', 4407), ('0 1 1 1 0', 4061)]
2023-05-02 08:24:19,591 INFO     LM most common: [('1', -1.6966811418533325), ('0 1', -1.9477629661560059), ('0', -1.9895684719085693), ('1 1', -3.0941061973571777), ('0 1 1', -3.149325370788574), ('1 0 1', -3.231616497039795), ('1 0', -3.3165035247802734), ('0 1 0 1', -3.3535895347595215), ('0 1 0', -3.4068949222564697), ('1 0 1 1', -4.310633659362793), ('0 1 1 1', -4.375999450683594), ('0 1 1 0 1', -4.440163612365723), ('0 1 0 1 1', -4.46756649017334), ('0 1 1 0', -4.492015361785889), ('1 0 1 0 1', -4.496700286865234), ('1 1 1', -4.533697128295898), ('1 1 0 1', -4.546270370483398), ('1 1 0', -4.610569477081299), ('0 1 0 1 0 1', -4.624895095825195), ('1 0 1 0', -4.625349044799805), ('0 1 0 1 0', -4.804630279541016), ('1 0 1 1 1', -5.531002998352051), ('1 0 1 1 0 1', -5.554032325744629), ('0 1 1 1 1', -5.563272476196289), ('1 0 1 1 0', -5.6164751052856445)]
2023-05-02 08:24:19,591 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:24:19,591 INFO     []
2023-05-02 08:24:19,591 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:24:19,591 INFO     []
2023-05-02 08:24:19,591 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:24:19,592 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:24:19,592 INFO     
2023-05-02 08:24:19,943 INFO     Language: Even
2023-05-02 08:24:19,943 INFO     Description: Strings over {A, B} where A's only appear in even-length groups
2023-05-02 08:24:47,158 INFO     DONE TRAINING
2023-05-02 08:24:48,017 INFO     TRAINING SET LOSS: 755.8322595357895
2023-05-02 08:27:46,600 INFO     LM most common: [('1', 218790), ('0 0', 142655), ('1 1', 84333), ('1 0 0', 60231), ('0 0 1', 52666), ('0 0 0 0', 34881), ('1 1 1', 32498), ('1 1 0 0', 21933), ('1 0 0 1', 21811), ('0 0 1 1', 21042), ('1 0 0 0 0', 14606), ('0 0 0 0 1', 13468), ('0 0 1 0 0', 13268), ('1 1 1 1', 12053), ('1 1 1 0 0', 8866), ('1 0 0 1 1', 8854), ('0 0 0 0 0 0', 8493), ('0 0 1 1 1', 8365), ('1 1 0 0 1', 8313), ('1 0 0 1 0 0', 5612), ('1 0 0 0 0 1', 5485), ('0 0 1 0 0 1', 5441), ('0 0 0 0 1 1', 5434), ('1 1 0 0 0 0', 5161), ('0 0 1 1 0 0', 5065)]
2023-05-02 08:27:55,940 INFO     LM most common: [('1', -1.3181004524230957), ('1 1', -2.1664040088653564), ('0 0', -2.1790823936462402), ('1 0 0', -2.83396315574646), ('1 1 1', -2.9891347885131836), ('0 0 1', -3.11037015914917), ('1 0 0 1', -3.7815074920654297), ('1 1 0 0', -3.7980353832244873), ('0 0 1 1', -3.8679938316345215), ('1 1 1 1', -3.902869701385498), ('0 0 0 0', -3.9533305168151855), ('1 1 1 0 0', -4.528853416442871), ('1 0 0 1 1', -4.556097030639648), ('1 0 0 0 0', -4.634739398956299), ('0 0 1 1 1', -4.656884670257568), ('1 1 0 0 1', -4.676556587219238), ('1 1 1 1 1', -4.692798614501953), ('0 0 1 0 0', -4.783562660217285), ('0 0 0 0 1', -4.816531181335449), ('1 1 1 0 0 1', -5.395827293395996), ('1 1 0 0 1 1', -5.429450035095215), ('0 0 1 1 1 1', -5.43787956237793), ('1 0 0 1 1 1', -5.444848537445068), ('1 0 0 1 0 0', -5.452115058898926), ('1 1 1 1 1 1', -5.476012706756592)]
2023-05-02 08:27:55,940 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:27:55,940 INFO     []
2023-05-02 08:27:55,940 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:27:55,940 INFO     []
2023-05-02 08:27:55,941 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:27:55,941 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:27:55,941 INFO     
2023-05-02 08:27:56,267 INFO     Language: ApBAp
2023-05-02 08:27:56,267 INFO     Description: A+ B A+
2023-05-02 08:28:21,458 INFO     DONE TRAINING
2023-05-02 08:28:22,246 INFO     TRAINING SET LOSS: 458.91506201028824
2023-05-02 08:29:58,581 INFO     LM most common: [('0 1 0', 266060), ('0 1 0 0', 128827), ('0 0 1 0', 127413), ('0 1 0 0 0', 63777), ('0 0 1 0 0', 61898), ('0 0 0 1 0', 59743), ('0 1 0 0 0 0', 32176), ('0 0 1 0 0 0', 30648), ('0 0 0 1 0 0', 29362), ('0 0 0 0 1 0', 28578), ('0 1 0 0 0 0 0', 15815), ('0 0 1 0 0 0 0', 15697), ('0 0 0 1 0 0 0', 14477), ('0 0 0 0 1 0 0', 13911), ('0 0 0 0 0 1 0', 13839), ('0 1 0 0 0 0 0 0', 7781), ('0 0 1 0 0 0 0 0', 7777), ('0 0 0 1 0 0 0 0', 7314), ('0 0 0 0 1 0 0 0', 6848), ('0 0 0 0 0 1 0 0', 6715), ('0 0 0 0 0 0 1 0', 6422), ('0 1 0 0 0 0 0 0 0', 3933), ('0 0 1 0 0 0 0 0 0', 3832), ('0 0 0 1 0 0 0 0 0', 3577), ('0 0 0 0 1 0 0 0 0', 3540)]
2023-05-02 08:29:58,772 INFO     LM most common: [('0 1 0', -1.26823091506958), ('0 1 0 0', -2.020328998565674), ('0 0 1 0', -2.044417381286621), ('0 1 0 0 0', -2.7324228286743164), ('0 0 1 0 0', -2.7982821464538574), ('0 0 0 1 0', -2.8562841415405273), ('0 1 0 0 0 0', -3.4122095108032227), ('0 0 1 0 0 0', -3.5013129711151123), ('0 0 0 1 0 0', -3.603623867034912), ('0 0 0 0 1 0', -3.653827428817749), ('0 1 0 0 0 0 0', -4.129792213439941), ('0 0 1 0 0 0 0', -4.171674728393555), ('0 0 0 1 0 0 0', -4.3047356605529785), ('0 0 0 0 1 0 0', -4.3911519050598145), ('0 0 0 0 0 1 0', -4.445840835571289), ('0 1 0 0 0 0 0 0', -4.839911460876465), ('0 0 1 0 0 0 0 0', -4.879488945007324), ('0 0 0 1 0 0 0 0', -4.972779750823975), ('0 0 0 0 1 0 0 0', -5.090179443359375), ('0 0 0 0 0 1 0 0', -5.173091411590576), ('0 0 0 0 0 0 1 0', -5.232300758361816), ('0 1 0 0 0 0 0 0 0', -5.553250789642334), ('0 0 1 0 0 0 0 0 0', -5.580757141113281), ('0 0 0 1 0 0 0 0 0', -5.678655624389648), ('0 0 0 0 1 0 0 0 0', -5.756008625030518)]
2023-05-02 08:29:58,772 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:29:58,772 INFO     []
2023-05-02 08:29:58,772 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:29:58,772 INFO     []
2023-05-02 08:29:58,772 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:29:58,772 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:29:58,772 INFO     
2023-05-02 08:29:59,310 INFO     Language: ApBApp
2023-05-02 08:29:59,311 INFO     Description: A+ (B A+)+
2023-05-02 08:30:34,789 INFO     DONE TRAINING
2023-05-02 08:30:35,936 INFO     TRAINING SET LOSS: 475.7909090220928
2023-05-02 08:50:21,069 INFO     LM most common: [('0 1 0', 140381), ('0 0 1 0', 68598), ('0 1 0 1 0', 62414), ('0 1 0 0', 61911), ('0 1 0 0 0', 33679), ('0 0 0 1 0', 33114), ('0 1 0 1 0 1 0', 31385), ('0 0 1 0 1 0', 31265), ('0 0 1 0 0', 29969), ('0 1 0 0 1 0 0', 28126), ('0 0 1 0 0 0', 16988), ('0 0 0 0 1 0', 16423), ('0 1 0 0 0 0', 15577), ('0 1 0 1 0 1 0 1 0', 15459), ('0 0 0 1 0 1 0', 15347), ('0 0 1 0 1 0 1 0', 15338), ('0 1 0 0 0 1 0 0 0', 15231), ('0 0 0 1 0 0', 15088), ('0 1 0 0 1 0 0 1 0 0', 13807), ('0 0 1 0 0 1 0 0', 13731), ('0 1 0 0 0 0 0', 8806), ('0 0 0 1 0 0 0', 8373), ('0 0 0 0 0 1 0', 7963), ('0 0 1 0 0 0 0', 7742), ('0 0 0 0 1 0 1 0', 7703)]
2023-05-02 08:50:24,354 INFO     LM most common: [('0 1 0', -2.230682849884033), ('0 1 0 0', -2.925211191177368), ('0 0 1 0', -2.9743573665618896), ('0 1 0 0 0', -3.1524901390075684), ('0 1 0 1 0', -3.154792308807373), ('0 0 1 0 0', -3.6722240447998047), ('0 1 0 0 0 0', -3.7512896060943604), ('0 0 0 1 0', -3.754843235015869), ('0 1 0 0 1 0 0', -3.810607433319092), ('0 0 1 0 1 0', -3.851358652114868), ('0 1 0 1 0 1 0', -3.8523640632629395), ('0 0 1 0 0 0', -3.8603057861328125), ('0 1 0 0 0 0 0', -3.981844425201416), ('0 1 0 0 0 1 0 0 0', -4.070553779602051), ('0 1 0 0 0 0 0 0', -4.30647611618042), ('0 0 0 1 0 0', -4.379359245300293), ('0 0 0 0 1 0', -4.466085910797119), ('0 0 1 0 0 0 0', -4.505546569824219), ('0 1 0 0 1 0 0 1 0 0', -4.544158935546875), ('0 0 1 0 0 1 0 0', -4.546597003936768), ('0 1 0 1 0 1 0 1 0', -4.560837745666504), ('0 0 1 0 1 0 1 0', -4.58621883392334), ('0 0 0 1 0 1 0', -4.5878190994262695), ('0 0 0 1 0 0 0', -4.610249042510986), ('0 1 0 0 0 0 1 0 0 0 0', -4.63377571105957)]
2023-05-02 08:50:24,354 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:50:24,354 INFO     []
2023-05-02 08:50:24,354 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:50:24,355 INFO     []
2023-05-02 08:50:24,355 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:50:24,355 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:50:24,355 INFO     
2023-05-02 08:50:24,730 INFO     Language: AsBAsp
2023-05-02 08:50:24,730 INFO     Description: A* (B A*)+
2023-05-02 08:50:54,687 INFO     DONE TRAINING
2023-05-02 08:50:55,639 INFO     TRAINING SET LOSS: 713.0683878362179
2023-05-02 08:58:03,575 INFO     LM most common: [('1', 128555), ('1 0', 66593), ('1 1', 65882), ('0 1', 62121), ('1 0 0', 33994), ('1 1 1', 32513), ('0 1 1', 32507), ('0 1 0', 31648), ('0 0 1', 29317), ('1 0 1 0', 27309), ('1 0 0 0', 16625), ('0 0 1 0', 16078), ('0 1 1 1', 15937), ('0 0 1 1', 15798), ('1 1 1 1', 15787), ('0 1 0 0', 15165), ('0 0 0 1', 14855), ('1 0 0 1 0 0', 14760), ('1 0 1 0 1 0', 14177), ('0 1 0 1 0', 13503), ('1 0 0 0 0', 8875), ('0 1 1 1 1', 8026), ('1 1 1 1 1', 7956), ('0 0 1 0 0', 7906), ('0 0 0 1 0', 7812)]
2023-05-02 08:58:05,011 INFO     LM most common: [('1', -2.4241864681243896), ('1 0', -2.7667717933654785), ('1 1', -3.0552563667297363), ('1 0 0', -3.115201711654663), ('0 1', -3.1736068725585938), ('0 1 0', -3.5102248191833496), ('1 0 0 0', -3.5806221961975098), ('0 1 1', -3.7835872173309326), ('1 1 1', -3.7932448387145996), ('1 0 0 0 0', -3.8104209899902344), ('1 0 1 0', -3.8456172943115234), ('0 1 0 0', -3.9983768463134766), ('0 0 1', -3.9987258911132812), ('1 0 0 1 0 0', -4.085505485534668), ('0 0 1 0', -4.236133098602295), ('1 0 0 0 0 0', -4.346321105957031), ('1 0 0 0 1 0 0 0', -4.408344745635986), ('0 1 0 0 0', -4.442481994628906), ('1 0 1 0 1 0', -4.4865498542785645), ('1 1 1 1', -4.5247344970703125), ('0 1 1 1', -4.527764320373535), ('0 0 1 1', -4.538759708404541), ('0 1 0 1 0', -4.540764808654785), ('1 0 0 0 0 1 0 0 0 0', -4.54083251953125), ('1 0 0 0 0 0 0', -4.57499361038208)]
2023-05-02 08:58:05,011 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:58:05,011 INFO     []
2023-05-02 08:58:05,011 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:58:05,011 INFO     []
2023-05-02 08:58:05,011 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:58:05,011 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:58:05,011 INFO     
2023-05-02 08:58:05,370 INFO     Language: CountA2
2023-05-02 08:58:05,370 INFO     Description: Strings over {A, B} where the number of A's is at least 2
2023-05-02 08:58:31,921 INFO     DONE TRAINING
2023-05-02 08:58:32,747 INFO     TRAINING SET LOSS: 862.1432930827141
2023-05-02 09:00:51,202 INFO     LM most common: [('0 0', 157293), ('0 1 0', 53263), ('1 0 0', 52014), ('0 0 0', 51463), ('0 0 1', 47887), ('0 1 0 0', 18432), ('1 1 0 0', 18001), ('0 0 0 0', 17763), ('0 1 1 0', 17588), ('1 0 1 0', 17274), ('0 1 0 1', 16647), ('1 0 0 0', 16433), ('0 0 1 0', 16420), ('1 0 0 1', 16316), ('0 0 0 1', 15890), ('0 0 1 1', 14751), ('1 0 1 0 0', 6072), ('0 1 1 1 0', 6037), ('1 1 1 0 0', 5994), ('0 1 1 0 0', 5956), ('1 1 0 1 0', 5910), ('0 0 0 0 0', 5909), ('1 1 0 0 0', 5740), ('0 1 0 1 0', 5737), ('1 0 0 0 0', 5667)]
2023-05-02 09:01:11,904 INFO     LM most common: [('0 0', -1.4249485731124878), ('0 0 0', -2.5476083755493164), ('0 0 1', -2.704435348510742), ('0 1 0', -2.985393524169922), ('1 0 0', -3.034501791000366), ('0 0 0 0', -3.58089542388916), ('0 0 1 0', -3.7538647651672363), ('0 0 0 1', -3.808553695678711), ('0 0 1 1', -3.9541730880737305), ('0 1 0 0', -4.0356125831604), ('0 1 0 1', -4.223969459533691), ('1 0 0 1', -4.240706443786621), ('1 0 0 0', -4.242138862609863), ('1 1 0 0', -4.574524402618408), ('0 1 1 0', -4.628522872924805), ('1 0 1 0', -4.64330530166626), ('0 0 0 0 0', -4.699179649353027), ('0 0 1 0 0', -4.810866355895996), ('0 0 0 0 1', -4.852598190307617), ('0 0 0 1 0', -4.893952369689941), ('0 0 1 0 1', -4.958374977111816), ('0 0 1 1 0', -4.983553409576416), ('0 0 0 1 1', -5.077200889587402), ('0 0 1 1 1', -5.128393173217773), ('0 1 0 1 0', -5.238059997558594)]
2023-05-02 09:01:11,904 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:01:11,904 INFO     []
2023-05-02 09:01:11,904 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:01:11,904 INFO     []
2023-05-02 09:01:11,906 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:01:11,906 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:01:11,906 INFO     
2023-05-02 09:01:12,217 INFO     Language: CountAEven
2023-05-02 09:01:12,217 INFO     Description: Strings over {A, B} where the number of A's is even
2023-05-02 09:01:36,381 INFO     DONE TRAINING
2023-05-02 09:01:37,141 INFO     TRAINING SET LOSS: 815.9936525225639
2023-05-02 09:03:20,522 INFO     LM most common: [('1', 354777), ('0 0', 114333), ('1 1', 110263), ('0 0 1', 42083), ('1 1 1', 36726), ('1 0 0', 35583), ('0 1 0', 35385), ('1 0 0 1', 13158), ('0 0 0 0', 12946), ('0 0 1 1', 12277), ('0 1 0 1', 12215), ('1 1 0 0', 12103), ('0 1 1 0', 11570), ('1 1 1 1', 11373), ('1 0 1 0', 10190), ('0 0 0 0 1', 4474), ('0 0 1 0 0', 4433), ('1 0 0 0 0', 4396), ('1 1 0 0 1', 4354), ('1 0 0 1 1', 4212), ('0 1 1 0 1', 4150), ('0 1 0 1 1', 3909), ('0 0 1 1 1', 3776), ('0 1 0 0 0', 3726), ('0 0 0 1 0', 3720)]
2023-05-02 09:03:27,295 INFO     LM most common: [('1', -0.5811328887939453), ('1 1', -2.0165352821350098), ('0 0', -2.2508440017700195), ('1 1 1', -3.3368499279022217), ('0 0 1', -3.361405849456787), ('1 0 0', -3.6803691387176514), ('0 1 0', -4.013657093048096), ('1 0 0 1', -4.773127555847168), ('1 1 1 1', -4.8055500984191895), ('0 0 1 1', -4.882214069366455), ('1 1 0 0', -4.990271091461182), ('0 0 0 0', -5.118599891662598), ('0 1 0 1', -5.206719398498535), ('0 1 1 0', -5.682534694671631), ('1 0 1 0', -5.695680618286133), ('1 0 0 1 1', -6.1261067390441895), ('1 1 0 0 1', -6.129303932189941), ('1 1 1 1 1', -6.18607234954834), ('0 0 1 1 1', -6.289320945739746), ('1 0 0 0 0', -6.350384712219238), ('0 0 0 0 1', -6.3897385597229), ('0 0 1 0 0', -6.463444709777832), ('0 1 0 1 1', -6.530134201049805), ('1 1 1 0 0', -6.601757049560547), ('0 1 1 0 1', -6.822347640991211)]
2023-05-02 09:03:27,295 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:03:27,295 INFO     []
2023-05-02 09:03:27,295 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:03:27,295 INFO     []
2023-05-02 09:03:27,296 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:03:27,296 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:03:27,296 INFO     
2023-05-02 09:03:27,618 INFO     Language: aABb
2023-05-02 09:03:27,618 INFO     Description: a Sigma+ b
2023-05-02 09:03:53,901 INFO     DONE TRAINING
2023-05-02 09:03:54,712 INFO     TRAINING SET LOSS: 659.2914953529835
2023-05-02 09:06:11,872 INFO     LM most common: [('0 0 1', 176353), ('0 1 1', 164200), ('0 0 1 1', 58471), ('0 0 0 1', 56068), ('0 1 1 1', 55101), ('0 1 0 1', 52323), ('0 0 1 1 1', 20231), ('0 0 0 0 1', 19153), ('0 0 0 1 1', 18850), ('0 1 1 1 1', 18600), ('0 1 0 0 1', 18362), ('0 0 1 0 1', 17235), ('0 1 0 1 1', 17180), ('0 1 1 0 1', 16509), ('0 0 0 1 1 1', 6688), ('0 0 0 0 1 1', 6675), ('0 0 1 1 1 1', 6613), ('0 1 0 0 1 1', 6370), ('0 0 0 0 0 1', 6343), ('0 1 0 0 0 1', 6222), ('0 0 1 0 0 1', 6195), ('0 1 0 1 1 1', 6154), ('0 0 1 1 0 1', 6149), ('0 1 1 1 1 1', 6081), ('0 0 1 0 1 1', 5787)]
2023-05-02 09:06:24,238 INFO     LM most common: [('0 0 1', -1.2714924812316895), ('0 1 1', -1.4017257690429688), ('0 0 1 1', -2.5443410873413086), ('0 1 1 1', -2.665900707244873), ('0 0 0 1', -2.961731195449829), ('0 1 0 1', -3.0756757259368896), ('0 0 1 1 1', -3.768609046936035), ('0 1 1 1 1', -3.912411689758301), ('0 0 0 1 1', -4.17949104309082), ('0 1 0 1 1', -4.327446460723877), ('0 0 1 0 1', -4.373824596405029), ('0 1 1 0 1', -4.450498580932617), ('0 0 0 0 1', -4.496751308441162), ('0 1 0 0 1', -4.568465232849121), ('0 0 1 1 1 1', -5.039731979370117), ('0 1 1 1 1 1', -5.198019504547119), ('0 0 0 1 1 1', -5.357419967651367), ('0 0 1 1 0 1', -5.463916301727295), ('0 1 0 1 1 1', -5.4650726318359375), ('0 0 1 0 1 1', -5.6217169761657715), ('0 1 1 1 0 1', -5.638548851013184), ('0 0 0 0 1 1', -5.691291809082031), ('0 1 1 0 1 1', -5.736494541168213), ('0 1 0 0 1 1', -5.741497039794922), ('0 0 1 0 0 1', -5.847192764282227)]
2023-05-02 09:06:24,238 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:06:24,239 INFO     []
2023-05-02 09:06:24,239 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:06:24,239 INFO     []
2023-05-02 09:06:24,239 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:06:24,239 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:06:24,239 INFO     
2023-05-02 09:06:24,608 INFO     Language: AnBn
2023-05-02 09:06:24,608 INFO     Description: A^n B^n
2023-05-02 09:06:56,435 INFO     DONE TRAINING
2023-05-02 09:06:57,442 INFO     TRAINING SET LOSS: 275.40061032772064
2023-05-02 09:12:30,809 INFO     LM most common: [('0 1', 358101), ('0 0 1 1', 233956), ('0 0 0 1 1 1', 143302), ('0 0 0 0 1 1 1 1', 92650), ('0 0 0 0 0 1 1 1 1 1', 60266), ('0 0 0 0 0 0 1 1 1 1 1 1', 38899), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', 25392), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', 16711), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', 10829), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', 7044), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', 4529), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', 2962), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1', 1920), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 1214), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 775), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 543), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 314), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 204), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 143), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 85), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 59), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 35), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 27), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 18), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 7)]
2023-05-02 09:12:30,854 INFO     LM most common: [('0 1', -1.4411202669143677), ('0 0 1 1', -1.6629431247711182), ('0 0 0 1 1 1', -2.0403788089752197), ('0 0 0 0 1 1 1 1', -2.3092594146728516), ('0 0 0 0 0 1 1 1 1 1', -2.563291072845459), ('0 0 0 0 0 0 1 1 1 1 1 1', -2.814032554626465), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', -3.064622402191162), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', -3.315931558609009), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', -3.568243980407715), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', -3.821638584136963), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', -4.076132297515869), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', -4.331730842590332), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.588430881500244), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.846224784851074), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.105088233947754), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.3650102615356445), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.625964164733887), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.887946128845215), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.150935649871826), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.414908409118652), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.6798505783081055), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.945741653442383), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.212566375732422), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.480298042297363), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.748931884765625)]
2023-05-02 09:12:30,854 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:12:30,854 INFO     []
2023-05-02 09:12:30,854 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:12:30,854 INFO     []
2023-05-02 09:12:30,854 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:12:30,854 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 09:12:30,854 INFO     
2023-05-02 09:12:31,251 INFO     Language: Dyck
2023-05-02 09:12:31,251 INFO     Description: Balanced sequences of parentheses
2023-05-02 09:13:02,823 INFO     DONE TRAINING
2023-05-02 09:13:03,821 INFO     TRAINING SET LOSS: 466.20732536911964
2023-05-02 09:18:23,370 INFO     LM most common: [('0 1', 342023), ('0 0 1 1', 124189), ('0 1 0 1', 108666), ('0 1 0 0 1 1', 39023), ('0 0 0 1 1 1', 38031), ('0 0 1 0 1 1', 36578), ('0 1 0 1 0 1', 36407), ('0 1 0 1 0 0 1 1', 13325), ('0 0 0 0 1 1 1 1', 12727), ('0 1 0 1 0 1 0 1', 12374), ('0 0 0 1 0 1 1 1', 12192), ('0 0 1 0 0 1 1 1', 12010), ('0 1 0 0 0 1 1 1', 11799), ('0 1 0 0 1 0 1 1', 11782), ('0 0 1 0 1 0 1 1', 10631), ('0 1 0 0 0 1 0 1 1 1', 4427), ('0 1 0 1 0 1 0 0 1 1', 4369), ('0 1 0 1 0 1 0 1 0 1', 4090), ('0 1 0 1 0 0 1 0 1 1', 4035), ('0 0 0 0 0 1 1 1 1 1', 4018), ('0 1 0 0 0 0 1 1 1 1', 3953), ('0 0 0 1 0 1 0 1 1 1', 3921), ('0 0 0 1 0 0 1 1 1 1', 3915), ('0 1 0 0 1 0 0 1 1 1', 3886), ('0 1 0 1 0 0 0 1 1 1', 3866)]
2023-05-02 09:18:33,147 INFO     LM most common: [('0 1', -0.8629554510116577), ('0 1 0 1', -1.8829967975616455), ('0 0 1 1', -2.3322033882141113), ('0 1 0 1 0 1', -2.7890522480010986), ('0 1 0 0 1 1', -3.3559350967407227), ('0 0 1 0 1 1', -3.507152557373047), ('0 1 0 1 0 1 0 1', -3.698129415512085), ('0 0 0 1 1 1', -4.099185943603516), ('0 1 0 1 0 0 1 1', -4.231632709503174), ('0 1 0 0 1 0 1 1', -4.461849212646484), ('0 1 0 1 0 1 0 1 0 1', -4.622683525085449), ('0 0 1 0 1 0 1 1', -4.659290313720703), ('0 0 0 1 0 1 1 1', -5.099090576171875), ('0 1 0 1 0 1 0 0 1 1', -5.146228790283203), ('0 0 1 0 0 1 1 1', -5.166971206665039), ('0 1 0 0 0 1 1 1', -5.191712379455566), ('0 1 0 1 0 0 1 0 1 1', -5.369287014007568), ('0 1 0 1 0 1 0 1 0 1 0 1', -5.5571112632751465), ('0 1 0 0 1 0 1 0 1 1', -5.586442470550537), ('0 0 0 0 1 1 1 1', -5.736509323120117), ('0 0 1 0 1 0 1 0 1 1', -5.737068176269531), ('0 1 0 0 0 1 0 1 1 1', -5.855607986450195), ('0 1 0 1 0 1 0 1 0 0 1 1', -6.075427055358887), ('0 1 0 0 1 0 0 1 1 1', -6.091623306274414), ('0 1 0 1 0 0 0 1 1 1', -6.118708610534668)]
2023-05-02 09:18:33,147 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:18:33,147 INFO     []
2023-05-02 09:18:33,147 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:18:33,147 INFO     []
2023-05-02 09:18:33,147 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:18:33,147 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:18:33,147 INFO     
2023-05-02 09:18:33,565 INFO     Language: AnB2n
2023-05-02 09:18:33,566 INFO     Description: A^n B^(2n)
2023-05-02 09:19:12,843 INFO     DONE TRAINING
2023-05-02 09:19:14,111 INFO     TRAINING SET LOSS: 194.55592299997807
2023-05-02 09:28:53,434 INFO     LM most common: [('0 1 1', 373361), ('0 0 1 1 1 1', 232123), ('0 0 0 1 1 1 1 1 1', 147504), ('0 0 0 0 1 1 1 1 1 1 1 1', 90930), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', 57425), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', 36181), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 23240), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 14649), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 9137), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 5830), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 3467), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 2135), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 1270), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 763), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 475), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 300), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 187), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 148), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 120), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 112), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 109), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 104), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 104), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 73), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 59)]
2023-05-02 09:28:53,500 INFO     LM most common: [('0 1 1', -1.341274619102478), ('0 0 1 1 1 1', -1.6634236574172974), ('0 0 0 1 1 1 1 1 1', -1.939734697341919), ('0 0 0 0 1 1 1 1 1 1 1 1', -2.2729644775390625), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', -2.5759360790252686), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', -2.860291004180908), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.1368274688720703), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.419214963912964), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.7065930366516113), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.9974842071533203), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.292900562286377), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.591949462890625), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.899616241455078), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.211736679077148), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.5363030433654785), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.867099285125732), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.214419364929199), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.574343204498291), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.95422887802124), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.351630210876465), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.769834041595459), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -8.207297325134277), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -8.664794921875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -9.140965461730957), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -9.635197639465332)]
2023-05-02 09:28:53,501 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:28:53,501 INFO     []
2023-05-02 09:28:53,501 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:28:53,501 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1']
2023-05-02 09:28:53,501 INFO     LM precision, recall, fscore: 1.0 0.96 0.9795918367346939
2023-05-02 09:28:53,501 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 09:28:53,501 INFO     
2023-05-02 09:28:53,884 INFO     Language: AnCBn
2023-05-02 09:28:53,884 INFO     Description: A^n C B^n
2023-05-02 09:29:26,396 INFO     DONE TRAINING
2023-05-02 09:29:27,432 INFO     TRAINING SET LOSS: 239.79430225491524
2023-05-02 09:35:32,733 INFO     LM most common: [('0 2 1', 343714), ('0 0 2 1 1', 227455), ('0 0 0 2 1 1 1', 148996), ('0 0 0 0 2 1 1 1 1', 97514), ('0 0 0 0 0 2 1 1 1 1 1', 63254), ('0 0 0 0 0 0 2 1 1 1 1 1 1', 41317), ('0 0 0 0 0 0 0 2 1 1 1 1 1 1 1', 27081), ('0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1', 17680), ('0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1', 11539), ('0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1', 7410), ('0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1', 4838), ('0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1', 3113), ('0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1', 2101), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 1381), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 882), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 615), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 394), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 262), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 146), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 112), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 68), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 44), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 30), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 15), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 14)]
2023-05-02 09:35:32,785 INFO     LM most common: [('0 2 1', -1.537718653678894), ('0 0 2 1 1', -1.7545462846755981), ('0 0 0 2 1 1 1', -2.0022830963134766), ('0 0 0 0 2 1 1 1 1', -2.2516822814941406), ('0 0 0 0 0 2 1 1 1 1 1', -2.5003092288970947), ('0 0 0 0 0 0 2 1 1 1 1 1 1', -2.7489428520202637), ('0 0 0 0 0 0 0 2 1 1 1 1 1 1 1', -2.997840404510498), ('0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1', -3.2470204830169678), ('0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1', -3.4964652061462402), ('0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1', -3.7461352348327637), ('0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1', -3.995980739593506), ('0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1', -4.245966911315918), ('0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.496047019958496), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.746184349060059), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.996339797973633), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.246485233306885), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.496594429016113), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.746635437011719), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.996585845947266), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.2464375495910645), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.49616003036499), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.74574089050293), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.995163917541504), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.244422435760498), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.493493556976318)]
2023-05-02 09:35:32,785 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:35:32,785 INFO     []
2023-05-02 09:35:32,785 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:35:32,785 INFO     []
2023-05-02 09:35:32,785 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:35:32,785 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 09:35:32,786 INFO     
2023-05-02 09:35:33,262 INFO     Language: AnABn
2023-05-02 09:35:33,262 INFO     Description: A^n (AB)^n
2023-05-02 09:36:12,590 INFO     DONE TRAINING
2023-05-02 09:36:13,873 INFO     TRAINING SET LOSS: 193.70829743146896
2023-05-02 09:48:29,025 INFO     LM most common: [('0 0 1', 355513), ('0 0 0 1 0 1', 226194), ('0 0 0 0 1 0 1 0 1', 146656), ('0 0 0 0 0 1 0 1 0 1 0 1', 94874), ('0 0 0 0 0 0 1 0 1 0 1 0 1 0 1', 61384), ('0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1', 40034), ('0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 26223), ('0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 17165), ('0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 10902), ('0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 7128), ('0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 4799), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 3080), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 2047), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1418), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 843), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 551), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 413), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 280), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 167), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 111), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 60), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 56), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 30), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 22), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 15)]
2023-05-02 09:48:29,085 INFO     LM most common: [('0 0 1', -1.4522899389266968), ('0 0 0 1 0 1', -1.7451609373092651), ('0 0 0 0 1 0 1 0 1', -2.011443614959717), ('0 0 0 0 0 1 0 1 0 1 0 1', -2.2761197090148926), ('0 0 0 0 0 0 1 0 1 0 1 0 1 0 1', -2.5388498306274414), ('0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1', -2.799272060394287), ('0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.0572431087493896), ('0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.3127055168151855), ('0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.565631866455078), ('0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.816032648086548), ('0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.06395149230957), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.309434413909912), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.552546977996826), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.793346405029297), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.031895160675049), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.268285751342773), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.502574920654297), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.734835147857666), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.965138912200928), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.1935577392578125), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.4201555252075195), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.64499568939209), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.868150234222412), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.0896759033203125), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.309635162353516)]
2023-05-02 09:48:29,085 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:48:29,085 INFO     []
2023-05-02 09:48:29,085 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:48:29,085 INFO     []
2023-05-02 09:48:29,085 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:48:29,085 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 09:48:29,085 INFO     
2023-05-02 09:48:29,653 INFO     Language: ABnABAn
2023-05-02 09:48:29,653 INFO     Description: (AB)^n (ABA)^n
2023-05-02 09:49:23,130 INFO     DONE TRAINING
2023-05-02 09:49:24,877 INFO     TRAINING SET LOSS: 121.35737949609756
2023-05-02 10:20:16,204 INFO     LM most common: [('0 1 0 1 0', 341194), ('0 1 0 1 0 1 0 0 1 0', 221890), ('0 1 0 1 0 1 0 1 0 0 1 0 0 1 0', 149342), ('0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0', 98002), ('0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 65159), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 42522), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 28076), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 18081), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 12213), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 7998), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 5301), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 3527), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 2286), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 1500), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 965), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 635), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 438), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 275), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 206), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 137), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 86), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', 54), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1', 35), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 22), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', 21)]
2023-05-02 10:20:16,286 INFO     LM most common: [('0 1 0 1 0', -1.5563406944274902), ('0 1 0 1 0 1 0 0 1 0', -1.8221735954284668), ('0 1 0 1 0 1 0 1 0 0 1 0 0 1 0', -2.0096354484558105), ('0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0', -2.2535207271575928), ('0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -2.496943473815918), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -2.738166332244873), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -2.9775233268737793), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.2154619693756104), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.4523673057556152), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.6885623931884766), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.924318313598633), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.159880638122559), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.395460605621338), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.63123893737793), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.867383003234863), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.104018211364746), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.341249465942383), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.5791521072387695), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.817803382873535), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -6.057229042053223), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -6.29747200012207), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -41.53215026855469), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -44.1102294921875), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', -45.77362060546875), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -46.14337921142578)]
2023-05-02 10:20:16,286 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:20:16,286 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0']
2023-05-02 10:20:16,286 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:20:16,286 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0']
2023-05-02 10:20:16,286 INFO     LM precision, recall, fscore: 0.84 0.84 0.8399999999999999
2023-05-02 10:20:16,286 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 10:20:16,287 INFO     
2023-05-02 10:20:16,681 INFO     Language: AnBmCn
2023-05-02 10:20:16,681 INFO     Description: A^n B^m C^n
2023-05-02 10:20:51,950 INFO     DONE TRAINING
2023-05-02 10:20:53,082 INFO     TRAINING SET LOSS: 385.0663754940033
2023-05-02 10:27:29,367 INFO     LM most common: [('0 1 2', 124716), ('0 0 1 2 2', 79811), ('0 1 1 2', 78084), ('0 0 0 1 2 2 2', 52226), ('0 0 1 1 2 2', 50905), ('0 1 1 1 2', 50734), ('0 0 0 0 1 2 2 2 2', 33545), ('0 0 0 1 1 2 2 2', 33468), ('0 1 1 1 1 2', 33306), ('0 0 1 1 1 2 2', 32843), ('0 0 0 1 1 1 2 2 2', 21876), ('0 0 0 0 1 1 2 2 2 2', 21861), ('0 1 1 1 1 1 2', 21808), ('0 0 0 0 0 1 2 2 2 2 2', 21606), ('0 0 1 1 1 1 2 2', 21448), ('0 1 1 1 1 1 1 2', 14361), ('0 0 1 1 1 1 1 2 2', 14221), ('0 0 0 1 1 1 1 2 2 2', 14214), ('0 0 0 0 1 1 1 2 2 2 2', 14080), ('0 0 0 0 0 1 1 2 2 2 2 2', 13841), ('0 0 0 0 0 0 1 2 2 2 2 2 2', 13768), ('0 0 0 1 1 1 1 1 2 2 2', 9455), ('0 1 1 1 1 1 1 1 2', 9400), ('0 0 1 1 1 1 1 1 2 2', 9336), ('0 0 0 0 1 1 1 1 2 2 2 2', 9335)]
2023-05-02 10:27:29,953 INFO     LM most common: [('0 1 2', -2.9409000873565674), ('0 0 1 2 2', -3.240631341934204), ('0 1 1 2', -3.2558512687683105), ('0 0 0 1 2 2 2', -3.480656623840332), ('0 1 1 1 2', -3.532743453979492), ('0 0 1 1 2 2', -3.542116165161133), ('0 0 0 0 1 2 2 2 2', -3.7546963691711426), ('0 0 0 1 1 2 2 2', -3.761638641357422), ('0 1 1 1 1 2', -3.782756805419922), ('0 0 1 1 1 2 2', -3.8024322986602783), ('0 0 0 1 1 1 2 2 2', -4.012945652008057), ('0 0 0 0 0 1 2 2 2 2 2', -4.025770664215088), ('0 1 1 1 1 1 2', -4.026504993438721), ('0 0 0 0 1 1 2 2 2 2', -4.028284072875977), ('0 0 1 1 1 1 2 2', -4.051171779632568), ('0 0 0 1 1 1 1 2 2 2', -4.254513740539551), ('0 1 1 1 1 1 1 2', -4.267706394195557), ('0 0 0 0 1 1 1 2 2 2 2', -4.276214599609375), ('0 0 0 0 0 0 1 2 2 2 2 2 2', -4.29337215423584), ('0 0 1 1 1 1 1 2 2', -4.296403884887695), ('0 0 0 0 0 1 1 2 2 2 2 2', -4.296695709228516), ('0 0 0 1 1 1 1 1 2 2 2', -4.494325637817383), ('0 1 1 1 1 1 1 1 2', -4.5073981285095215), ('0 0 0 0 1 1 1 1 2 2 2 2', -4.513786315917969), ('0 0 1 1 1 1 1 1 2 2', -4.540446758270264)]
2023-05-02 10:27:29,953 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:27:29,953 INFO     []
2023-05-02 10:27:29,953 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:27:29,953 INFO     []
2023-05-02 10:27:29,953 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:27:29,953 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:27:29,953 INFO     
2023-05-02 10:27:30,414 INFO     Language: AnBmA2n
2023-05-02 10:27:30,414 INFO     Description: A^n B^m A^(2n)
2023-05-02 10:28:12,682 INFO     DONE TRAINING
2023-05-02 10:28:14,058 INFO     TRAINING SET LOSS: 298.4815651923418
2023-05-02 10:41:18,977 INFO     LM most common: [('0 1 0 0', 117354), ('0 0 1 0 0 0 0', 80061), ('0 1 1 0 0', 77219), ('0 0 0 1 0 0 0 0 0 0', 54430), ('0 0 1 1 0 0 0 0', 52081), ('0 1 1 1 0 0', 48451), ('0 0 0 1 1 0 0 0 0 0 0', 34638), ('0 0 0 0 1 0 0 0 0 0 0 0 0', 34575), ('0 0 1 1 1 0 0 0 0', 33553), ('0 1 1 1 1 0 0', 31970), ('0 0 0 1 1 1 0 0 0 0 0 0', 22645), ('0 0 1 1 1 1 0 0 0 0', 22502), ('0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0', 22215), ('0 0 0 0 1 1 0 0 0 0 0 0 0 0', 21340), ('0 1 1 1 1 1 0 0', 21129), ('0 0 0 1 1 1 1 0 0 0 0 0 0', 15156), ('0 0 1 1 1 1 1 0 0 0 0', 14810), ('0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0', 14438), ('0 0 0 0 1 1 1 0 0 0 0 0 0 0 0', 13879), ('0 1 1 1 1 1 1 0 0', 13633), ('0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0', 13535), ('0 0 0 1 1 1 1 1 0 0 0 0 0 0', 10225), ('0 0 1 1 1 1 1 1 0 0 0 0', 9899), ('0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0', 9498), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 9214)]
2023-05-02 10:41:19,671 INFO     LM most common: [('0 1 0 0', -3.091996192932129), ('0 0 1 0 0 0 0', -3.24298095703125), ('0 1 1 0 0', -3.329354763031006), ('0 0 0 1 0 0 0 0 0 0', -3.379923105239868), ('0 0 1 1 0 0 0 0', -3.5028867721557617), ('0 1 1 1 0 0', -3.650423049926758), ('0 0 0 0 1 0 0 0 0 0 0 0 0', -3.6873884201049805), ('0 0 0 1 1 0 0 0 0 0 0', -3.709414005279541), ('0 0 1 1 1 0 0 0 0', -3.803098201751709), ('0 1 1 1 1 0 0', -3.884552240371704), ('0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0', -3.9349772930145264), ('0 0 0 1 1 1 0 0 0 0 0 0', -3.991283416748047), ('0 0 1 1 1 1 0 0 0 0', -4.026773929595947), ('0 0 0 0 1 1 0 0 0 0 0 0 0 0', -4.0652570724487305), ('0 1 1 1 1 1 0 0', -4.11802339553833), ('0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0', -4.1829681396484375), ('0 0 0 1 1 1 1 0 0 0 0 0 0', -4.199044227600098), ('0 0 1 1 1 1 1 0 0 0 0', -4.250632286071777), ('0 0 0 0 1 1 1 0 0 0 0 0 0 0 0', -4.332985877990723), ('0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0', -4.34214973449707), ('0 1 1 1 1 1 1 0 0', -4.352694988250732), ('0 0 0 1 1 1 1 1 0 0 0 0 0 0', -4.40726375579834), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.4457502365112305), ('0 0 1 1 1 1 1 1 0 0 0 0', -4.472331523895264), ('0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0', -4.530534744262695)]
2023-05-02 10:41:19,671 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:41:19,671 INFO     []
2023-05-02 10:41:19,671 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:41:19,671 INFO     []
2023-05-02 10:41:19,671 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:41:19,672 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:41:19,672 INFO     
2023-05-02 10:41:20,155 INFO     Language: AnBnC2n
2023-05-02 10:41:20,155 INFO     Description: A^n B^n C^(2n)
2023-05-02 10:42:05,937 INFO     DONE TRAINING
2023-05-02 10:42:07,439 INFO     TRAINING SET LOSS: 150.192322447896
2023-05-02 10:59:28,748 INFO     LM most common: [('0 1 2 2', 371655), ('0 0 1 1 2 2 2 2', 239050), ('0 0 0 1 1 1 2 2 2 2 2 2', 143023), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2', 92671), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 56484), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 36177), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 22460), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 14294), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8963), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 5665), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 3501), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 2227), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1430), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 565), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 356), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 235), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 141), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 89), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 57), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 32), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 24), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 14), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 5), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 4)]
2023-05-02 10:59:28,800 INFO     LM most common: [('0 1 2 2', -1.3499696254730225), ('0 0 1 1 2 2 2 2', -1.6006916761398315), ('0 0 0 1 1 1 2 2 2 2 2 2', -1.996009111404419), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2', -2.2330610752105713), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -2.585460662841797), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -2.8521838188171387), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.1814839839935303), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.4577512741088867), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.767336845397949), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.050614833831787), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.352941989898682), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.643548011779785), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.945772171020508), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.243866920471191), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.549788475036621), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.855330467224121), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.166578769683838), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.479153156280518), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.796150207519531), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.115205764770508), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.437878608703613), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.762887477874756), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.091029167175293), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.421610832214355), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.75503158569336)]
2023-05-02 10:59:28,800 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:59:28,800 INFO     []
2023-05-02 10:59:28,800 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:59:28,800 INFO     []
2023-05-02 10:59:28,800 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:59:28,800 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 10:59:28,800 INFO     
2023-05-02 10:59:29,201 INFO     Language: AnBmCm
2023-05-02 10:59:29,201 INFO     Description: A^n B^m C^m
2023-05-02 11:00:04,751 INFO     DONE TRAINING
2023-05-02 11:00:05,892 INFO     TRAINING SET LOSS: 385.38627395033836
2023-05-02 11:07:46,855 INFO     LM most common: [('0 1 2', 116757), ('0 0 1 2', 76872), ('0 1 1 2 2', 75195), ('0 0 0 1 2', 50288), ('0 0 1 1 2 2', 48868), ('0 1 1 1 2 2 2', 48789), ('0 0 0 0 1 2', 33248), ('0 1 1 1 1 2 2 2 2', 33199), ('0 0 1 1 1 2 2 2', 32559), ('0 0 0 1 1 2 2', 32307), ('0 0 0 0 0 1 2', 22156), ('0 1 1 1 1 1 2 2 2 2 2', 21846), ('0 0 1 1 1 1 2 2 2 2', 21695), ('0 0 0 1 1 1 2 2 2', 21137), ('0 0 0 0 1 1 2 2', 21069), ('0 1 1 1 1 1 1 2 2 2 2 2 2', 14685), ('0 0 1 1 1 1 1 2 2 2 2 2', 14586), ('0 0 0 1 1 1 1 2 2 2 2', 14485), ('0 0 0 0 0 0 1 2', 14478), ('0 0 0 0 0 1 1 2 2', 14082), ('0 0 0 0 1 1 1 2 2 2', 13737), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 9916), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2', 9719), ('0 0 0 0 0 0 0 1 2', 9600), ('0 0 0 0 1 1 1 1 2 2 2 2', 9519)]
2023-05-02 11:07:47,538 INFO     LM most common: [('0 1 2', -3.1005725860595703), ('0 0 1 2', -3.342432975769043), ('0 1 1 2 2', -3.3917064666748047), ('0 0 0 1 2', -3.5980582237243652), ('0 0 1 1 2 2', -3.6504111289978027), ('0 1 1 1 2 2 2', -3.6684956550598145), ('0 0 0 0 1 2', -3.838733673095703), ('0 1 1 1 1 2 2 2 2', -3.8640494346618652), ('0 0 0 1 1 2 2', -3.9054694175720215), ('0 0 1 1 1 2 2 2', -3.909430742263794), ('0 0 0 0 0 1 2', -4.073611259460449), ('0 1 1 1 1 1 2 2 2 2 2', -4.091327667236328), ('0 0 1 1 1 1 2 2 2 2', -4.108449459075928), ('0 0 0 0 1 1 2 2', -4.145914077758789), ('0 0 0 1 1 1 2 2 2', -4.157440662384033), ('0 0 0 0 0 0 1 2', -4.305218696594238), ('0 1 1 1 1 1 1 2 2 2 2 2 2', -4.311722755432129), ('0 0 1 1 1 1 1 2 2 2 2 2', -4.332959175109863), ('0 0 0 1 1 1 1 2 2 2 2', -4.357308864593506), ('0 0 0 0 0 1 1 2 2', -4.380630970001221), ('0 0 0 0 1 1 1 2 2 2', -4.396981716156006), ('0 0 0 0 0 0 0 1 2', -4.5346174240112305), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -4.534904479980469), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2', -4.5513176918029785), ('0 0 0 1 1 1 1 1 2 2 2 2 2', -4.580794334411621)]
2023-05-02 11:07:47,539 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 11:07:47,539 INFO     []
2023-05-02 11:07:47,539 INFO     Grammatical sequences that the model is missing:
2023-05-02 11:07:47,539 INFO     []
2023-05-02 11:07:47,539 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:07:47,539 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:07:47,539 INFO     
2023-05-02 11:07:47,971 INFO     Language: AnBmCnpm
2023-05-02 11:07:47,971 INFO     Description: A^n B^m C^(n+m)
2023-05-02 11:08:28,937 INFO     DONE TRAINING
2023-05-02 11:08:30,266 INFO     TRAINING SET LOSS: 296.4392989575863
2023-05-02 11:18:36,264 INFO     LM most common: [('0 1 2 2', 119613), ('0 0 1 2 2 2', 79883), ('0 1 1 2 2 2', 75890), ('0 0 0 1 2 2 2 2', 52229), ('0 0 1 1 2 2 2 2', 51538), ('0 1 1 1 2 2 2 2', 48128), ('0 0 0 0 1 2 2 2 2 2', 35960), ('0 0 0 1 1 2 2 2 2 2', 33337), ('0 0 1 1 1 2 2 2 2 2', 32886), ('0 1 1 1 1 2 2 2 2 2', 30395), ('0 0 0 0 0 1 2 2 2 2 2 2', 24450), ('0 0 0 0 1 1 2 2 2 2 2 2', 22836), ('0 0 0 1 1 1 2 2 2 2 2 2', 21007), ('0 0 1 1 1 1 2 2 2 2 2 2', 20512), ('0 1 1 1 1 1 2 2 2 2 2 2', 19196), ('0 0 0 0 0 0 1 2 2 2 2 2 2 2', 17092), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2', 15535), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2', 14217), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2', 13349), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2', 13033), ('0 1 1 1 1 1 1 2 2 2 2 2 2 2', 12258), ('0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2', 11813), ('0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2', 10615), ('0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2', 9628), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2', 8969)]
2023-05-02 11:18:36,988 INFO     LM most common: [('0 1 2 2', -3.0339879989624023), ('0 0 1 2 2 2', -3.2709388732910156), ('0 1 1 2 2 2', -3.332322120666504), ('0 0 1 1 2 2 2 2', -3.523176431655884), ('0 0 0 1 2 2 2 2', -3.5457763671875), ('0 1 1 1 2 2 2 2', -3.606961727142334), ('0 0 0 0 1 2 2 2 2 2', -3.721489906311035), ('0 0 1 1 1 2 2 2 2 2', -3.800692081451416), ('0 0 0 1 1 2 2 2 2 2', -3.827579975128174), ('0 1 1 1 1 2 2 2 2 2', -3.9074342250823975), ('0 0 0 0 0 1 2 2 2 2 2 2', -3.9311976432800293), ('0 0 0 0 1 1 2 2 2 2 2 2', -4.0189008712768555), ('0 0 1 1 1 1 2 2 2 2 2 2', -4.102076053619385), ('0 0 0 1 1 1 2 2 2 2 2 2', -4.112473487854004), ('0 0 0 0 0 0 1 2 2 2 2 2 2 2', -4.11848258972168), ('0 1 1 1 1 1 2 2 2 2 2 2', -4.205436706542969), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2', -4.242346286773682), ('0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2', -4.2975664138793945), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2', -4.3120503425598145), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2', -4.4015092849731445), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2', -4.41218376159668), ('0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2', -4.439813137054443), ('0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 2', -4.467165946960449), ('0 1 1 1 1 1 1 2 2 2 2 2 2 2', -4.49981689453125), ('0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2', -4.542421340942383)]
2023-05-02 11:18:36,988 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 11:18:36,988 INFO     []
2023-05-02 11:18:36,988 INFO     Grammatical sequences that the model is missing:
2023-05-02 11:18:36,988 INFO     []
2023-05-02 11:18:36,988 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:18:36,988 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:18:36,989 INFO     
2023-05-02 11:18:37,734 INFO     Language: AnBmCnm
2023-05-02 11:18:37,734 INFO     Description: A^n B^m C^(n*m)
2023-05-02 11:19:35,213 INFO     DONE TRAINING
2023-05-02 11:19:37,094 INFO     TRAINING SET LOSS: 260.3991421312094
2023-05-02 11:57:51,952 INFO     LM most common: [('0 1 2', 131591), ('0 1 1 2 2', 83730), ('0 0 1 2 2', 75396), ('0 0 0 1 2 2 2', 54371), ('0 1 1 1 2 2 2', 53142), ('0 0 1 1 2 2 2 2', 52276), ('0 0 0 1 1 2 2 2 2 2 2', 34649), ('0 1 1 1 1 2 2 2 2', 34619), ('0 0 0 0 1 2 2 2 2', 34238), ('0 0 1 1 1 2 2 2 2 2 2', 34202), ('0 1 1 1 1 1 2 2 2 2 2', 22661), ('0 0 1 1 1 1 2 2 2 2 2 2 2 2', 22510), ('0 0 0 1 1 1 2 2 2 2 2 2 2 2 2', 22153), ('0 0 0 0 1 1 2 2 2 2 2 2 2 2', 21983), ('0 0 0 0 0 1 2 2 2 2 2', 20909), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 15097), ('0 1 1 1 1 1 1 2 2 2 2 2 2', 14882), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 14866), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 13782), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2', 13311), ('0 0 0 0 0 0 1 2 2 2 2 2 2', 12952), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 10074), ('0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 9895), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 9363), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8837)]
2023-05-02 11:57:55,439 INFO     LM most common: [('0 1 2', -2.810511589050293), ('0 1 1 2 2', -3.106651782989502), ('0 0 0 1 2 2 2', -3.323659896850586), ('0 0 1 2 2', -3.323965549468994), ('0 1 1 1 2 2 2', -3.4031460285186768), ('0 0 1 1 2 2 2 2', -3.4827022552490234), ('0 0 0 0 1 2 2 2 2', -3.597146511077881), ('0 0 0 1 1 2 2 2 2 2 2', -3.6372175216674805), ('0 1 1 1 1 2 2 2 2', -3.6419873237609863), ('0 0 1 1 1 2 2 2 2 2 2', -3.742184638977051), ('0 0 0 1 1 1 2 2 2 2 2 2 2 2 2', -3.8978967666625977), ('0 1 1 1 1 1 2 2 2 2 2', -3.898763656616211), ('0 0 0 0 1 1 2 2 2 2 2 2 2 2', -3.9069745540618896), ('0 0 0 0 0 1 2 2 2 2 2', -3.9443039894104004), ('0 0 1 1 1 1 2 2 2 2 2 2 2 2', -3.9944963455200195), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.100341796875), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.133208274841309), ('0 1 1 1 1 1 1 2 2 2 2 2 2', -4.147515296936035), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -4.249753475189209), ('0 0 0 0 0 0 1 2 2 2 2 2 2', -4.257167339324951), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2', -4.260830879211426), ('0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.313838005065918), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.345484256744385), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -4.4038004875183105), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.455245494842529)]
2023-05-02 11:57:55,439 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 11:57:55,439 INFO     []
2023-05-02 11:57:55,439 INFO     Grammatical sequences that the model is missing:
2023-05-02 11:57:55,439 INFO     []
2023-05-02 11:57:55,439 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:57:55,439 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:57:55,439 INFO     
2023-05-02 11:57:55,828 INFO     Language: AnBk
2023-05-02 11:57:55,829 INFO     Description: A^n B^(n+m)
2023-05-02 11:58:30,800 INFO     DONE TRAINING
2023-05-02 11:58:31,921 INFO     TRAINING SET LOSS: 386.24242347478867
2023-05-02 12:05:20,691 INFO     LM most common: [('0 1 1', 123095), ('0 0 1 1 1', 76944), ('0 1 1 1', 76909), ('0 0 0 1 1 1 1', 55504), ('0 0 1 1 1 1', 50353), ('0 1 1 1 1', 49235), ('0 0 0 0 1 1 1 1 1', 35470), ('0 0 0 1 1 1 1 1', 34938), ('0 0 1 1 1 1 1', 32520), ('0 1 1 1 1 1', 31683), ('0 0 0 0 0 1 1 1 1 1 1', 23300), ('0 0 0 1 1 1 1 1 1', 22366), ('0 0 0 0 1 1 1 1 1 1', 22216), ('0 0 1 1 1 1 1 1', 21153), ('0 1 1 1 1 1 1', 20591), ('0 0 0 0 0 0 1 1 1 1 1 1 1', 15116), ('0 0 0 0 0 1 1 1 1 1 1 1', 14830), ('0 0 0 0 1 1 1 1 1 1 1', 14396), ('0 0 0 1 1 1 1 1 1 1', 14337), ('0 0 1 1 1 1 1 1 1', 13683), ('0 1 1 1 1 1 1 1', 13507), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1', 9735), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', 9705), ('0 0 0 0 0 1 1 1 1 1 1 1 1', 9436), ('0 0 0 1 1 1 1 1 1 1 1', 9394)]
2023-05-02 12:05:21,296 INFO     LM most common: [('0 1 1', -2.9814553260803223), ('0 1 1 1', -3.3078460693359375), ('0 0 1 1 1', -3.3454976081848145), ('0 0 0 1 1 1 1', -3.375425338745117), ('0 0 1 1 1 1', -3.5761232376098633), ('0 1 1 1 1', -3.5936532020568848), ('0 0 0 0 1 1 1 1 1', -3.6507115364074707), ('0 0 0 1 1 1 1 1', -3.6807098388671875), ('0 0 1 1 1 1 1', -3.8573904037475586), ('0 1 1 1 1 1', -3.869534492492676), ('0 0 0 0 0 1 1 1 1 1 1', -3.904855251312256), ('0 0 0 0 1 1 1 1 1 1', -3.9680426120758057), ('0 0 0 1 1 1 1 1 1', -3.9770493507385254), ('0 0 1 1 1 1 1 1', -4.122317314147949), ('0 1 1 1 1 1 1', -4.132974624633789), ('0 0 0 0 0 0 1 1 1 1 1 1 1', -4.151934623718262), ('0 0 0 0 0 1 1 1 1 1 1 1', -4.200198173522949), ('0 0 0 0 1 1 1 1 1 1 1', -4.257706642150879), ('0 0 0 1 1 1 1 1 1 1', -4.260054588317871), ('0 0 1 1 1 1 1 1 1', -4.378429412841797), ('0 1 1 1 1 1 1 1', -4.388144493103027), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', -4.397426128387451), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1', -4.455147743225098), ('0 0 0 0 0 1 1 1 1 1 1 1 1', -4.488448143005371), ('0 0 0 1 1 1 1 1 1 1 1', -4.530457496643066)]
2023-05-02 12:05:21,296 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:05:21,296 INFO     []
2023-05-02 12:05:21,296 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:05:21,296 INFO     []
2023-05-02 12:05:21,296 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:05:21,296 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:05:21,296 INFO     
2023-05-02 12:05:21,727 INFO     Language: AnBmCmAn
2023-05-02 12:05:21,727 INFO     Description: A^n B^m C^m A^n
2023-05-02 12:06:02,133 INFO     DONE TRAINING
2023-05-02 12:06:03,436 INFO     TRAINING SET LOSS: 296.88791635632515
2023-05-02 12:16:01,665 INFO     LM most common: [('0 1 2 0', 115896), ('0 1 1 2 2 0', 77162), ('0 0 1 2 0 0', 76501), ('0 1 1 1 2 2 2 0', 50625), ('0 0 1 1 2 2 0 0', 49990), ('0 0 0 1 2 0 0 0', 49820), ('0 1 1 1 1 2 2 2 2 0', 33771), ('0 0 1 1 1 2 2 2 0 0', 33113), ('0 0 0 0 1 2 0 0 0 0', 32572), ('0 0 0 1 1 2 2 0 0 0', 32448), ('0 0 1 1 1 1 2 2 2 2 0 0', 22226), ('0 1 1 1 1 1 2 2 2 2 2 0', 22122), ('0 0 0 1 1 1 2 2 2 0 0 0', 21772), ('0 0 0 0 1 1 2 2 0 0 0 0', 21654), ('0 0 0 0 0 1 2 0 0 0 0 0', 20873), ('0 0 1 1 1 1 1 2 2 2 2 2 0 0', 14882), ('0 1 1 1 1 1 1 2 2 2 2 2 2 0', 14704), ('0 0 0 1 1 1 1 2 2 2 2 0 0 0', 14635), ('0 0 0 0 1 1 1 2 2 2 0 0 0 0', 14562), ('0 0 0 0 0 1 1 2 2 0 0 0 0 0', 14000), ('0 0 0 0 0 0 1 2 0 0 0 0 0 0', 13807), ('0 0 0 1 1 1 1 1 2 2 2 2 2 0 0 0', 9965), ('0 0 0 0 1 1 1 1 2 2 2 2 0 0 0 0', 9803), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 0 0', 9755), ('0 0 0 0 0 1 1 1 2 2 2 0 0 0 0 0', 9579)]
2023-05-02 12:16:02,401 INFO     LM most common: [('0 1 2 0', -3.127473831176758), ('0 1 1 2 2 0', -3.33717679977417), ('0 0 1 2 0 0', -3.3467674255371094), ('0 1 1 1 2 2 2 0', -3.557201385498047), ('0 0 1 1 2 2 0 0', -3.616807460784912), ('0 0 0 1 2 0 0 0', -3.6187844276428223), ('0 1 1 1 1 2 2 2 2 0', -3.7896080017089844), ('0 0 1 1 1 2 2 2 0 0', -3.8307204246520996), ('0 0 0 0 1 2 0 0 0 0', -3.8676230907440186), ('0 0 0 1 1 2 2 0 0 0', -3.8951146602630615), ('0 1 1 1 1 1 2 2 2 2 2 0', -4.026813507080078), ('0 0 1 1 1 1 2 2 2 2 0 0', -4.049232482910156), ('0 0 0 1 1 1 2 2 2 0 0 0', -4.103654861450195), ('0 0 0 0 1 1 2 2 0 0 0 0', -4.119272232055664), ('0 0 0 0 0 1 2 0 0 0 0 0', -4.128838539123535), ('0 1 1 1 1 1 1 2 2 2 2 2 2 0', -4.266445159912109), ('0 0 1 1 1 1 1 2 2 2 2 2 0 0', -4.27140998840332), ('0 0 0 1 1 1 1 2 2 2 2 0 0 0', -4.312956809997559), ('0 0 0 0 1 1 1 2 2 2 0 0 0 0', -4.325264930725098), ('0 0 0 0 0 1 1 2 2 0 0 0 0 0', -4.348823070526123), ('0 0 0 0 0 0 1 2 0 0 0 0 0 0', -4.3928327560424805), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 0 0', -4.497159481048584), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0', -4.50753116607666), ('0 0 0 1 1 1 1 1 2 2 2 2 2 0 0 0', -4.522334575653076), ('0 0 0 0 1 1 1 1 2 2 2 2 0 0 0 0', -4.532837867736816)]
2023-05-02 12:16:02,401 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:16:02,401 INFO     []
2023-05-02 12:16:02,401 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:16:02,401 INFO     []
2023-05-02 12:16:02,401 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:16:02,401 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:16:02,402 INFO     
2023-05-02 12:16:03,064 INFO     Language: AnB2nC3n
2023-05-02 12:16:03,064 INFO     Description: A^n B^2n C^3n
2023-05-02 12:17:03,434 INFO     DONE TRAINING
2023-05-02 12:17:05,402 INFO     TRAINING SET LOSS: 102.65432804077864
2023-05-02 12:47:22,009 INFO     LM most common: [('0 1 1 2 2 2', 368459), ('0 0 1 1 1 1 2 2 2 2 2 2', 239457), ('0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 146728), ('0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 93016), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 58988), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 36694), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 22598), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 13759), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8173), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 5001), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 3007), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1673), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 992), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 611), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 371), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 178), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 120), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 64), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 40), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 27), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 20), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 9), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 7), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 4), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 3)]
2023-05-02 12:47:22,072 INFO     LM most common: [('0 1 1 2 2 2', -1.368701457977295), ('0 0 1 1 1 1 2 2 2 2 2 2', -1.593637466430664), ('0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -1.9383964538574219), ('0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -2.217754364013672), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -2.4927468299865723), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -2.7871952056884766), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.1042094230651855), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.444636106491089), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.8074889183044434), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.187591552734375), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.5791473388671875), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.977445125579834), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.379099369049072), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.781885623931885), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.184356212615967), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.585581302642822), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.984920501708984), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -44.907474517822266), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -63.93418502807617), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -65.10392761230469), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -65.59911346435547), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -66.06977844238281), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -66.5209732055664), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -66.95721435546875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -67.38015747070312)]
2023-05-02 12:47:22,072 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:47:22,072 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2023-05-02 12:47:22,072 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:47:22,072 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2023-05-02 12:47:22,072 INFO     LM precision, recall, fscore: 0.68 0.68 0.68
2023-05-02 12:47:22,072 INFO     Memorization precision, recall, fscore: 1.0 0.84 0.9130434782608696
2023-05-02 12:47:22,072 INFO     
2023-05-02 12:47:22,528 INFO     Language: AnBnp1Cnp2
2023-05-02 12:47:22,528 INFO     Description: A^n B^(n+1) C^(n+2)
2023-05-02 12:48:04,252 INFO     DONE TRAINING
2023-05-02 12:48:05,605 INFO     TRAINING SET LOSS: 147.36885054409504
2023-05-02 12:59:08,264 INFO     LM most common: [('0 1 1 2 2 2', 356989), ('0 0 1 1 1 2 2 2 2', 238895), ('0 0 0 1 1 1 1 2 2 2 2 2', 151997), ('0 0 0 0 1 1 1 1 1 2 2 2 2 2 2', 94797), ('0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2', 59071), ('0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', 36974), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 23089), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 14383), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', 9027), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 5480), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', 3498), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 2248), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1331), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 817), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 514), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 350), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 217), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 127), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 81), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 46), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 25), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 14), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 12), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 5), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 5)]
2023-05-02 12:59:08,317 INFO     LM most common: [('0 1 1 2 2 2', -1.4491984844207764), ('0 0 1 1 1 2 2 2 2', -1.6199579238891602), ('0 0 0 1 1 1 1 2 2 2 2 2', -1.891678810119629), ('0 0 0 0 1 1 1 1 1 2 2 2 2 2 2', -2.1960062980651855), ('0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2', -2.5053322315216064), ('0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', -2.816410541534424), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -3.1278419494628906), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -3.439345121383667), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', -3.7507410049438477), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.062006950378418), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.3731255531311035), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.684118747711182), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.995008945465088), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.305821418762207), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.6165947914123535), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.92736291885376), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.238160610198975), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.549032688140869), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.860008716583252), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.1711320877075195), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.482440948486328), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.79396915435791), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.10574722290039), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.417815208435059), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.730195999145508)]
2023-05-02 12:59:08,317 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:59:08,317 INFO     []
2023-05-02 12:59:08,317 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:59:08,317 INFO     []
2023-05-02 12:59:08,317 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:59:08,317 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 12:59:08,317 INFO     
2023-05-02 12:59:08,610 INFO     Language: AnUBn
2023-05-02 12:59:08,611 INFO     Description: A^n | B^n
2023-05-02 12:59:32,779 INFO     DONE TRAINING
2023-05-02 12:59:33,536 INFO     TRAINING SET LOSS: 657.6802921295166
2023-05-02 13:01:24,876 INFO     LM most common: [('0', 187686), ('1', 177625), ('0 0', 115211), ('1 1', 110396), ('0 0 0', 74464), ('1 1 1', 70426), ('0 0 0 0', 47958), ('1 1 1 1', 45723), ('0 0 0 0 0', 30734), ('1 1 1 1 1', 30023), ('1 1 1 1 1 1', 19422), ('0 0 0 0 0 0', 19302), ('1 1 1 1 1 1 1', 12483), ('0 0 0 0 0 0 0', 12468), ('1 1 1 1 1 1 1 1', 8351), ('0 0 0 0 0 0 0 0', 8001), ('1 1 1 1 1 1 1 1 1', 5465), ('0 0 0 0 0 0 0 0 0', 5102), ('1 1 1 1 1 1 1 1 1 1', 3561), ('0 0 0 0 0 0 0 0 0 0', 3230), ('1 1 1 1 1 1 1 1 1 1 1', 2354), ('0 0 0 0 0 0 0 0 0 0 0', 2108), ('1 1 1 1 1 1 1 1 1 1 1 1', 1550), ('0 0 0 0 0 0 0 0 0 0 0 0', 1280), ('1 1 1 1 1 1 1 1 1 1 1 1 1', 962)]
2023-05-02 13:01:24,932 INFO     LM most common: [('0', -2.0322773456573486), ('1', -2.145482063293457), ('0 0', -2.3873424530029297), ('1 1', -2.493709087371826), ('0 0 0', -2.6349120140075684), ('1 1 1', -2.7727341651916504), ('0 0 0 0', -2.9011874198913574), ('1 1 1 1', -3.033224105834961), ('0 0 0 0 0', -3.176903486251831), ('1 1 1 1 1', -3.2888288497924805), ('0 0 0 0 0 0', -3.454317092895508), ('1 1 1 1 1 1', -3.541325569152832), ('0 0 0 0 0 0 0', -3.732835054397583), ('1 1 1 1 1 1 1', -3.792029619216919), ('0 0 0 0 0 0 0 0', -4.012285232543945), ('1 1 1 1 1 1 1 1', -4.041451930999756), ('1 1 1 1 1 1 1 1 1', -4.289895534515381), ('0 0 0 0 0 0 0 0 0', -4.292505264282227), ('1 1 1 1 1 1 1 1 1 1', -4.537539005279541), ('0 0 0 0 0 0 0 0 0 0', -4.573431015014648), ('1 1 1 1 1 1 1 1 1 1 1', -4.784534454345703), ('0 0 0 0 0 0 0 0 0 0 0', -4.854986190795898), ('1 1 1 1 1 1 1 1 1 1 1 1', -5.030942440032959), ('0 0 0 0 0 0 0 0 0 0 0 0', -5.137131690979004), ('1 1 1 1 1 1 1 1 1 1 1 1 1', -5.276859283447266)]
2023-05-02 13:01:24,932 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:01:24,932 INFO     []
2023-05-02 13:01:24,932 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:01:24,932 INFO     []
2023-05-02 13:01:24,933 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:01:24,933 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:01:24,933 INFO     
2023-05-02 13:01:25,293 INFO     Language: AnUAnBn
2023-05-02 13:01:25,294 INFO     Description: A^n | (A^n B^n)
2023-05-02 13:01:54,240 INFO     DONE TRAINING
2023-05-02 13:01:55,141 INFO     TRAINING SET LOSS: 486.82921317219734
2023-05-02 13:06:21,378 INFO     LM most common: [('0', 179382), ('0 1', 176368), ('0 0', 114297), ('0 0 1 1', 112481), ('0 0 0', 75684), ('0 0 0 1 1 1', 71344), ('0 0 0 0', 49714), ('0 0 0 0 1 1 1 1', 46648), ('0 0 0 0 0', 32666), ('0 0 0 0 0 1 1 1 1 1', 30538), ('0 0 0 0 0 0', 20810), ('0 0 0 0 0 0 1 1 1 1 1 1', 19501), ('0 0 0 0 0 0 0', 13193), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', 12269), ('0 0 0 0 0 0 0 0', 8569), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', 8004), ('0 0 0 0 0 0 0 0 0', 5426), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', 5135), ('0 0 0 0 0 0 0 0 0 0', 3360), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', 3201), ('0 0 0 0 0 0 0 0 0 0 0', 2182), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', 2066), ('0 0 0 0 0 0 0 0 0 0 0 0', 1408), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', 1240), ('0 0 0 0 0 0 0 0 0 0 0 0 0', 847)]
2023-05-02 13:06:21,441 INFO     LM most common: [('0', -2.696040391921997), ('0 1', -2.7425711154937744), ('0 0', -2.8705949783325195), ('0 0 1 1', -2.8993749618530273), ('0 0 0', -2.967536687850952), ('0 0 0 0', -3.056457281112671), ('0 0 0 1 1 1', -3.0856685638427734), ('0 0 0 0 1 1 1 1', -3.170647144317627), ('0 0 0 0 0', -3.1763806343078613), ('0 0 0 0 0 1 1 1 1 1', -3.293595314025879), ('0 0 0 0 0 0', -3.311141014099121), ('0 0 0 0 0 0 1 1 1 1 1 1', -3.4370555877685547), ('0 0 0 0 0 0 0', -3.4518566131591797), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', -3.588650703430176), ('0 0 0 0 0 0 0 0', -3.5950732231140137), ('0 0 0 0 0 0 0 0 0', -3.7397947311401367), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', -3.7426633834838867), ('0 0 0 0 0 0 0 0 0 0', -3.885590076446533), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', -3.897952079772949), ('0 0 0 0 0 0 0 0 0 0 0', -4.032209873199463), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', -4.054072856903076), ('0 0 0 0 0 0 0 0 0 0 0 0', -4.179509162902832), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', -4.210751533508301), ('0 0 0 0 0 0 0 0 0 0 0 0 0', -4.327355861663818), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', -4.3678388595581055)]
2023-05-02 13:06:21,442 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:06:21,442 INFO     []
2023-05-02 13:06:21,442 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:06:21,442 INFO     []
2023-05-02 13:06:21,442 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:06:21,442 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:06:21,442 INFO     
2023-05-02 13:06:21,798 INFO     Language: ABnUBAn
2023-05-02 13:06:21,798 INFO     Description: (AB)^n | (BA)^n
2023-05-02 13:06:53,561 INFO     DONE TRAINING
2023-05-02 13:06:54,570 INFO     TRAINING SET LOSS: 378.8562610447407
2023-05-02 13:12:40,118 INFO     LM most common: [('0 1', 182702), ('1 0', 167808), ('1 0 1 0', 118774), ('0 1 0 1', 115990), ('0 1 0 1 0 1', 77747), ('1 0 1 0 1 0', 69206), ('0 1 0 1 0 1 0 1', 50087), ('1 0 1 0 1 0 1 0', 43175), ('0 1 0 1 0 1 0 1 0 1', 32921), ('1 0 1 0 1 0 1 0 1 0', 27640), ('0 1 0 1 0 1 0 1 0 1 0 1', 21353), ('1 0 1 0 1 0 1 0 1 0 1 0', 18135), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', 13825), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0', 11818), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 9087), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 7573), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 5928), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 5125), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 3884), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 3348), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 2622), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 2206), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1682), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 1479), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 990)]
2023-05-02 13:12:40,200 INFO     LM most common: [('0 1', -2.104344367980957), ('1 0', -2.276031970977783), ('1 0 1 0', -2.315770149230957), ('0 1 0 1', -2.403895854949951), ('0 1 0 1 0 1', -2.6143298149108887), ('1 0 1 0 1 0', -2.7918245792388916), ('0 1 0 1 0 1 0 1', -2.8681061267852783), ('1 0 1 0 1 0 1 0', -3.120284080505371), ('0 1 0 1 0 1 0 1 0 1', -3.1234869956970215), ('0 1 0 1 0 1 0 1 0 1 0 1', -3.3777108192443848), ('1 0 1 0 1 0 1 0 1 0', -3.4030396938323975), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.63036847114563), ('1 0 1 0 1 0 1 0 1 0 1 0', -3.666147232055664), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.881789207458496), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0', -3.9192562103271484), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.132329940795898), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.166219234466553), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.382333278656006), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.408867835998535), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.63205623626709), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.6481852531433105), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.881692886352539), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.8847551345825195), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -5.118948936462402), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.131401062011719)]
2023-05-02 13:12:40,200 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:12:40,200 INFO     []
2023-05-02 13:12:40,200 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:12:40,200 INFO     []
2023-05-02 13:12:40,200 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:12:40,201 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:12:40,201 INFO     
2023-05-02 13:12:40,597 INFO     Language: XX
2023-05-02 13:12:40,597 INFO     Description: XX (two copies of the same string)
2023-05-02 13:13:12,203 INFO     DONE TRAINING
2023-05-02 13:13:13,197 INFO     TRAINING SET LOSS: 597.0343433022499
2023-05-02 13:19:55,740 INFO     LM most common: [('0 0', 192995), ('1 1', 174262), ('0 0 0 0', 62104), ('0 1 0 1', 61463), ('1 1 1 1', 55276), ('1 0 1 0', 54899), ('1 0 1 1 0 1', 24919), ('1 0 0 1 0 0', 22614), ('0 1 1 0 1 1', 20798), ('0 0 1 0 0 1', 20412), ('1 1 0 1 1 0', 19934), ('1 1 1 1 1 1', 18666), ('0 0 0 0 0 0', 15382), ('0 1 0 0 1 0', 13485), ('1 0 1 1 1 0 1 1', 8008), ('0 1 1 1 0 1 1 1', 7799), ('1 0 0 1 1 0 0 1', 7104), ('0 0 0 1 0 0 0 1', 6998), ('1 0 0 0 1 0 0 0', 6865), ('1 1 1 0 1 1 1 0', 6601), ('1 1 0 1 1 1 0 1', 6332), ('0 0 1 1 0 0 1 1', 6328), ('0 1 0 1 0 1 0 1', 6049), ('1 1 1 1 1 1 1 1', 5922), ('1 1 0 0 1 1 0 0', 5402)]
2023-05-02 13:20:21,677 INFO     LM most common: [('0 0', -1.174008846282959), ('1 1', -1.3155345916748047), ('1 1 1 1', -2.5412278175354004), ('0 0 0 0', -2.5822699069976807), ('0 1 0 1', -2.8238377571105957), ('1 0 1 0', -2.8956704139709473), ('1 1 1 1 1 1', -3.928626775741577), ('1 0 1 1 0 1', -4.094340801239014), ('0 0 1 0 0 1', -4.230138301849365), ('1 0 0 1 0 0', -4.2706193923950195), ('1 1 0 1 1 0', -4.283267974853516), ('0 1 1 0 1 1', -4.416004180908203), ('0 0 0 0 0 0', -4.8120317459106445), ('0 1 0 0 1 0', -5.059826850891113), ('1 1 1 1 1 1 1 1', -5.4637250900268555), ('1 0 1 1 1 0 1 1', -5.708882808685303), ('1 0 0 1 1 0 0 1', -5.90911865234375), ('1 1 1 0 1 1 1 0', -5.963787078857422), ('0 1 1 1 0 1 1 1', -5.980347633361816), ('1 1 0 1 1 1 0 1', -5.986522197723389), ('1 0 0 0 1 0 0 0', -6.138514995574951), ('0 0 0 1 0 0 0 1', -6.176089286804199), ('0 0 1 1 0 0 1 1', -6.1994171142578125), ('1 1 0 0 1 1 0 0', -6.2544684410095215), ('0 1 1 0 0 1 1 0', -6.390716552734375)]
2023-05-02 13:20:21,677 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:20:21,677 INFO     []
2023-05-02 13:20:21,677 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:20:21,677 INFO     []
2023-05-02 13:20:21,678 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:20:21,679 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:20:21,679 INFO     
2023-05-02 13:20:22,140 INFO     Language: XXX
2023-05-02 13:20:22,140 INFO     Description: XXX
2023-05-02 13:21:01,482 INFO     DONE TRAINING
2023-05-02 13:21:02,759 INFO     TRAINING SET LOSS: 428.3706717789173
2023-05-02 13:32:42,540 INFO     LM most common: [('0 0 0', 177623), ('1 1 1', 171574), ('1 1 1 1 1 1', 61024), ('0 0 0 0 0 0', 58487), ('0 1 0 1 0 1', 56625), ('1 0 1 0 1 0', 53426), ('0 1 1 0 1 1 0 1 1', 21310), ('0 1 0 0 1 0 0 1 0', 20794), ('1 1 0 1 1 0 1 1 0', 20677), ('1 0 0 1 0 0 1 0 0', 20049), ('0 0 1 0 0 1 0 0 1', 19397), ('0 0 0 0 0 0 0 0 0', 19042), ('1 0 1 1 0 1 1 0 1', 18973), ('1 1 1 1 1 1 1 1 1', 18508), ('1 0 1 0 1 0 1 0 1 0 1 0', 7830), ('1 0 0 0 1 0 0 0 1 0 0 0', 6872), ('1 1 0 1 1 1 0 1 1 1 0 1', 6659), ('0 0 1 0 0 0 1 0 0 0 1 0', 6554), ('0 0 1 1 0 0 1 1 0 0 1 1', 6485), ('0 1 0 0 0 1 0 0 0 1 0 0', 6295), ('0 0 0 1 0 0 0 1 0 0 0 1', 6280), ('0 0 0 0 0 0 0 0 0 0 0 0', 6184), ('0 1 1 0 0 1 1 0 0 1 1 0', 6063), ('0 1 1 1 0 1 1 1 0 1 1 1', 6045), ('1 1 1 1 1 1 1 1 1 1 1 1', 5787)]
2023-05-02 13:33:15,387 INFO     LM most common: [('0 0 0', -1.1557053327560425), ('1 1 1', -1.2402892112731934), ('1 1 1 1 1 1', -2.611509084701538), ('0 0 0 0 0 0', -2.6714978218078613), ('0 1 0 1 0 1', -2.7606494426727295), ('1 0 1 0 1 0', -2.880251407623291), ('0 1 0 0 1 0 0 1 0', -4.324222087860107), ('0 0 0 0 0 0 0 0 0', -4.340661525726318), ('0 1 1 0 1 1 0 1 1', -4.378605842590332), ('1 1 1 1 1 1 1 1 1', -4.441656589508057), ('1 0 0 1 0 0 1 0 0', -4.5285515785217285), ('1 0 1 1 0 1 1 0 1', -4.55308723449707), ('1 1 0 1 1 0 1 1 0', -4.6876444816589355), ('0 0 1 0 0 1 0 0 1', -4.694359302520752), ('1 0 0 0 1 0 0 0 1 0 0 0', -5.895919322967529), ('0 0 0 0 0 0 0 0 0 0 0 0', -6.046104431152344), ('0 1 0 0 0 1 0 0 0 1 0 0', -6.058623313903809), ('0 1 1 0 0 1 1 0 0 1 1 0', -6.088789939880371), ('0 1 1 1 0 1 1 1 0 1 1 1', -6.131767272949219), ('1 1 1 1 1 1 1 1 1 1 1 1', -6.1454339027404785), ('0 0 1 0 0 0 1 0 0 0 1 0', -6.289173603057861), ('0 0 1 1 0 0 1 1 0 0 1 1', -6.3434157371521), ('1 1 0 1 1 1 0 1 1 1 0 1', -6.345114231109619), ('0 0 0 1 0 0 0 1 0 0 0 1', -6.377077102661133), ('1 0 1 0 1 0 1 0 1 0 1 0', -6.436511039733887)]
2023-05-02 13:33:15,388 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:33:15,388 INFO     []
2023-05-02 13:33:15,388 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:33:15,388 INFO     []
2023-05-02 13:33:15,389 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:33:15,389 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:33:15,389 INFO     
2023-05-02 13:33:15,810 INFO     Language: XY
2023-05-02 13:33:15,810 INFO     Description: XY: X != Y (2 non-empty strings that are not identical; could include BBBB = B + BBB)
2023-05-02 13:33:44,764 INFO     DONE TRAINING
2023-05-02 13:33:45,670 INFO     TRAINING SET LOSS: 929.5602191090584
2023-05-02 13:36:58,155 INFO     LM most common: [('1 0', 36870), ('0 1', 29906), ('0 0 0', 23931), ('1 1 1', 22646), ('0 1 1', 22271), ('1 1 0', 21777), ('1 0 1', 20592), ('1 0 0', 20379), ('0 1 0', 19252), ('0 0 1', 19048), ('1 1 1 0', 11320), ('0 0 1 1', 10654), ('1 1 0 0', 10602), ('1 1 0 1', 9998), ('0 1 1 1', 9977), ('1 0 0 0', 9953), ('1 0 1 1', 9935), ('1 0 0 1', 9933), ('0 0 0 1', 9852), ('0 1 1 0', 9435), ('0 0 1 0', 9134), ('0 1 0 1', 8898), ('0 1 0 0', 8755), ('0 0 0 0', 7608), ('1 0 1 0', 7013)]
2023-05-02 13:37:46,781 INFO     LM most common: [('1 0', -4.270547866821289), ('0 1 1', -4.3177947998046875), ('0 0 0', -4.358039379119873), ('1 0 1', -4.4456892013549805), ('1 0 0', -4.464932918548584), ('1 1 1', -4.514086723327637), ('1 1 0', -4.581118583679199), ('0 1 0', -4.614889144897461), ('0 1', -4.734198093414307), ('1 0 1 1', -4.847497940063477), ('1 0 0 0', -4.878391265869141), ('0 0 1', -4.882248401641846), ('1 0 0 1', -4.890542507171631), ('1 1 1 0', -4.903956413269043), ('0 1 1 1', -4.915375709533691), ('1 1 0 0', -4.986960411071777), ('0 0 1 1', -4.993565559387207), ('0 1 1 0', -5.028449058532715), ('0 0 0 1', -5.11407470703125), ('0 1 0 1', -5.133178234100342), ('1 1 0 1', -5.137856483459473), ('0 1 0 0', -5.1596574783325195), ('1 1 1 0 0', -5.252598762512207), ('0 0 1 0', -5.264056205749512), ('1 1 1 1 0', -5.3292670249938965)]
2023-05-02 13:37:46,781 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:37:46,782 INFO     []
2023-05-02 13:37:46,782 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:37:46,782 INFO     []
2023-05-02 13:37:46,784 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:37:46,784 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:37:46,784 INFO     
2023-05-02 13:37:47,181 INFO     Language: XXR
2023-05-02 13:37:47,181 INFO     Description: X X^R (even-length palindromes)
2023-05-02 13:38:18,443 INFO     DONE TRAINING
2023-05-02 13:38:19,423 INFO     TRAINING SET LOSS: 592.8153168559074
2023-05-02 13:43:13,171 INFO     LM most common: [('1 1', 181063), ('0 0', 176670), ('1 0 0 1', 62758), ('0 0 0 0', 57114), ('0 1 1 0', 53609), ('1 1 1 1', 52748), ('0 1 0 0 1 0', 25461), ('1 0 0 0 0 1', 23725), ('1 1 0 0 1 1', 21290), ('1 0 1 1 0 1', 20299), ('0 0 1 1 0 0', 19508), ('0 1 1 1 1 0', 16602), ('0 0 0 0 0 0', 16224), ('1 1 1 1 1 1', 12978), ('0 1 0 0 0 0 1 0', 8560), ('1 0 0 1 1 0 0 1', 8040), ('1 1 0 0 0 0 1 1', 7718), ('0 0 1 1 1 1 0 0', 7567), ('1 1 1 0 0 1 1 1', 7315), ('0 1 0 1 1 0 1 0', 7262), ('1 0 0 0 0 0 0 1', 7177), ('0 0 1 0 0 1 0 0', 6799), ('0 1 1 0 0 1 1 0', 6652), ('1 0 1 1 1 1 0 1', 6428), ('0 1 1 1 1 1 1 0', 5941)]
2023-05-02 13:43:28,347 INFO     LM most common: [('1 1', -1.2356258630752563), ('0 0', -1.2780505418777466), ('0 0 0 0', -2.6110987663269043), ('1 0 0 1', -2.656775951385498), ('1 1 1 1', -2.679452419281006), ('0 1 1 0', -2.934906482696533), ('1 1 0 0 1 1', -4.004412651062012), ('0 1 0 0 1 0', -4.055517673492432), ('0 0 1 1 0 0', -4.100335597991943), ('1 0 0 0 0 1', -4.107154846191406), ('0 0 0 0 0 0', -4.413412094116211), ('1 0 1 1 0 1', -4.4911017417907715), ('0 1 1 1 1 0', -4.6507568359375), ('1 1 1 1 1 1', -4.790053367614746), ('1 1 0 0 0 0 1 1', -5.498660564422607), ('0 0 1 1 1 1 0 0', -5.628562927246094), ('0 0 1 0 0 1 0 0', -5.6321563720703125), ('0 1 0 0 0 0 1 0', -5.728379249572754), ('1 1 1 0 0 1 1 1', -5.781484603881836), ('1 0 0 0 0 0 0 1', -6.005011558532715), ('1 0 0 1 1 0 0 1', -6.07393741607666), ('0 0 0 0 0 0 0 0', -6.095284938812256), ('0 1 1 1 1 1 1 0', -6.114107131958008), ('0 1 0 1 1 0 1 0', -6.160576820373535), ('1 0 1 1 1 1 0 1', -6.2168869972229)]
2023-05-02 13:43:28,347 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:43:28,347 INFO     []
2023-05-02 13:43:28,347 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:43:28,347 INFO     []
2023-05-02 13:43:28,348 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:43:28,348 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:43:28,348 INFO     
2023-05-02 13:43:28,741 INFO     Language: XXI
2023-05-02 13:43:28,741 INFO     Description: X X^I (where X^I is the inverse of X - replace every A with B and vice-versa)
2023-05-02 13:44:00,344 INFO     DONE TRAINING
2023-05-02 13:44:01,355 INFO     TRAINING SET LOSS: 591.4579840302467
2023-05-02 13:52:56,852 INFO     LM most common: [('1 0', 181702), ('0 1', 169144), ('0 1 1 0', 57517), ('1 1 0 0', 55387), ('0 0 1 1', 52525), ('1 0 0 1', 49717), ('1 0 1 0 1 0', 23039), ('0 0 1 1 1 0', 20748), ('0 1 0 1 0 1', 20425), ('1 1 0 0 0 1', 16576), ('0 1 1 1 0 0', 16223), ('0 0 0 1 1 1', 15828), ('1 0 0 0 1 1', 15490), ('1 1 1 0 0 0', 15000), ('0 0 1 1 1 1 0 0', 7114), ('1 0 0 1 0 1 1 0', 6610), ('1 1 1 0 0 0 0 1', 6391), ('1 0 0 0 0 1 1 1', 6371), ('1 1 1 1 0 0 0 0', 6178), ('1 1 0 1 0 0 1 0', 6123), ('0 1 0 0 1 0 1 1', 6069), ('0 1 1 1 1 0 0 0', 6063), ('1 0 1 0 0 1 0 1', 5937), ('1 0 1 1 0 1 0 0', 5865), ('0 0 0 1 1 1 1 0', 5575)]
2023-05-02 13:53:37,590 INFO     LM most common: [('1 0', -1.2193100452423096), ('0 1', -1.3514301776885986), ('0 1 1 0', -2.5425219535827637), ('1 0 0 1', -2.6172966957092285), ('1 1 0 0', -2.8606696128845215), ('0 0 1 1', -2.9252145290374756), ('1 0 1 0 1 0', -3.796846866607666), ('0 0 1 1 1 0', -4.0359206199646), ('0 1 0 1 0 1', -4.134760856628418), ('1 0 0 0 1 1', -4.150210857391357), ('1 1 0 0 0 1', -4.388768196105957), ('0 1 1 1 0 0', -4.394861221313477), ('1 1 1 0 0 0', -4.7135210037231445), ('0 0 0 1 1 1', -4.715546607971191), ('0 0 1 1 1 1 0 0', -5.46620512008667), ('1 0 0 0 0 1 1 1', -5.591797828674316), ('1 0 0 1 0 1 1 0', -5.597106456756592), ('1 1 1 0 0 0 0 1', -5.704434394836426), ('0 1 0 0 1 0 1 1', -5.813286304473877), ('1 1 0 0 0 0 1 1', -5.885982036590576), ('0 1 1 1 1 0 0 0', -5.902551651000977), ('1 0 1 1 0 1 0 0', -5.9057207107543945), ('1 1 1 1 0 0 0 0', -5.976046562194824), ('1 0 1 0 0 1 0 1', -5.9984612464904785), ('0 0 0 1 1 1 1 0', -6.146385669708252)]
2023-05-02 13:53:37,591 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:53:37,591 INFO     []
2023-05-02 13:53:37,591 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:53:37,591 INFO     []
2023-05-02 13:53:37,593 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:53:37,593 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:53:37,593 INFO     
2023-05-02 13:53:37,981 INFO     Language: XXRI
2023-05-02 13:53:37,981 INFO     Description: X (X^R)^I
2023-05-02 13:54:09,651 INFO     DONE TRAINING
2023-05-02 13:54:10,653 INFO     TRAINING SET LOSS: 586.2163473963737
2023-05-02 14:11:45,109 INFO     LM most common: [('1 0', 178064), ('0 1', 164416), ('1 1 0 0', 59549), ('0 1 0 1', 57734), ('0 0 1 1', 57081), ('1 0 1 0', 53255), ('1 1 1 0 0 0', 19606), ('1 1 0 1 0 0', 19555), ('0 1 0 1 0 1', 19253), ('0 1 1 0 0 1', 19097), ('0 0 1 0 1 1', 18945), ('1 0 1 0 1 0', 17985), ('1 0 0 1 1 0', 17063), ('0 0 0 1 1 1', 17037), ('1 0 1 1 0 0 1 0', 7668), ('1 1 1 1 0 0 0 0', 6897), ('0 1 1 1 0 0 0 1', 6705), ('1 1 0 0 1 1 0 0', 6659), ('1 1 1 0 1 0 0 0', 6636), ('1 1 0 1 0 1 0 0', 6505), ('0 1 1 0 1 0 0 1', 6398), ('0 1 0 0 1 1 0 1', 6271), ('0 0 0 1 0 1 1 1', 5899), ('1 0 0 1 0 1 1 0', 5833), ('0 0 1 1 0 0 1 1', 5687)]
2023-05-02 14:12:13,685 INFO     LM most common: [('1 0', -1.26434326171875), ('0 1', -1.399259090423584), ('0 1 0 1', -2.4546210765838623), ('1 0 1 0', -2.5589985847473145), ('1 1 0 0', -2.705620288848877), ('0 0 1 1', -2.8545966148376465), ('1 0 1 0 1 0', -3.9367012977600098), ('0 1 0 1 0 1', -4.02259635925293), ('0 1 1 0 0 1', -4.070873737335205), ('1 1 0 1 0 0', -4.178121566772461), ('1 1 1 0 0 0', -4.182971954345703), ('1 0 0 1 1 0', -4.428248882293701), ('0 0 1 0 1 1', -4.469053268432617), ('0 0 0 1 1 1', -4.586925506591797), ('1 1 0 1 0 1 0 0', -5.624034404754639), ('0 1 1 0 1 0 0 1', -5.668740272521973), ('1 0 1 1 0 0 1 0', -5.671681880950928), ('1 1 1 0 1 0 0 0', -5.744431972503662), ('0 1 1 1 0 0 0 1', -5.789839744567871), ('1 0 1 0 1 0 1 0', -5.793990135192871), ('1 1 1 1 0 0 0 0', -5.889912128448486), ('0 1 0 0 1 1 0 1', -5.891388416290283), ('1 0 0 1 0 1 1 0', -5.968428611755371), ('1 1 0 0 1 1 0 0', -6.147510051727295), ('0 0 0 1 0 1 1 1', -6.324657440185547)]
2023-05-02 14:12:13,685 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:12:13,685 INFO     []
2023-05-02 14:12:13,685 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:12:13,685 INFO     []
2023-05-02 14:12:13,686 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:12:13,686 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:12:13,686 INFO     
2023-05-02 14:12:14,268 INFO     Language: An2
2023-05-02 14:12:14,268 INFO     Description: A^(n^2)
2023-05-02 14:12:56,024 INFO     DONE TRAINING
2023-05-02 14:12:57,388 INFO     TRAINING SET LOSS: 217.30199608951807
2023-05-02 14:39:10,786 INFO     LM most common: [('0', 546520), ('0 0 0 0', 254253), ('0 0 0 0 0 0 0 0 0', 115690), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 49243), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 20254), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 7907), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 2664), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 705), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 470), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 266), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 259), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 246), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 187), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 174), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 137), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 102), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 83), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 82), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 78), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 65), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 54), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 42), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 39), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 32), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 31)]
2023-05-02 14:39:10,909 INFO     LM most common: [('0', -0.5257261991500854), ('0 0 0 0', -1.3782734870910645), ('0 0 0 0 0 0 0 0 0', -2.2750730514526367), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -3.31510329246521), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.420441150665283), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.612678050994873), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.911818027496338), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -8.642005920410156), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -10.294853210449219), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -10.314391136169434), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.229836463928223), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.308475494384766), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.365126609802246), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.645145416259766), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.832643508911133), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.194425582885742), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.236404418945312), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.268708229064941), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.68919563293457), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.689669609069824), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.813300132751465), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.903753280639648), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.908352851867676), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -13.006128311157227), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -13.408021926879883)]
2023-05-02 14:39:10,910 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:39:10,910 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 14:39:10,911 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:39:10,911 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 14:39:10,911 INFO     LM precision, recall, fscore: 0.4 0.5 0.4444444444444445
2023-05-02 14:39:10,911 INFO     Memorization precision, recall, fscore: 1.0 0.65 0.787878787878788
2023-05-02 14:39:10,911 INFO     
2023-05-02 14:39:11,353 INFO     Language: AnBmCnDm
2023-05-02 14:39:11,354 INFO     Description: A^n B^m C^n D^m
2023-05-02 14:39:52,203 INFO     DONE TRAINING
2023-05-02 14:39:53,529 INFO     TRAINING SET LOSS: 296.3832842409611
2023-05-02 14:51:00,587 INFO     LM most common: [('0 1 2 3', 104932), ('0 1 1 2 3 3', 73662), ('0 0 1 2 2 3', 73175), ('0 1 1 1 2 3 3 3', 49563), ('0 0 0 1 2 2 2 3', 48898), ('0 0 1 1 2 2 3 3', 48503), ('0 1 1 1 1 2 3 3 3 3', 34413), ('0 0 1 1 1 2 2 3 3 3', 33112), ('0 0 0 0 1 2 2 2 2 3', 32080), ('0 0 0 1 1 2 2 2 3 3', 32055), ('0 1 1 1 1 1 2 3 3 3 3 3', 23405), ('0 0 1 1 1 1 2 2 3 3 3 3', 23201), ('0 0 0 1 1 1 2 2 2 3 3 3', 21572), ('0 0 0 0 1 1 2 2 2 2 3 3', 21023), ('0 0 0 0 0 1 2 2 2 2 2 3', 20959), ('0 1 1 1 1 1 1 2 3 3 3 3 3 3', 16286), ('0 0 1 1 1 1 1 2 2 3 3 3 3 3', 15991), ('0 0 0 1 1 1 1 2 2 2 3 3 3 3', 14901), ('0 0 0 0 1 1 1 2 2 2 2 3 3 3', 14275), ('0 0 0 0 0 0 1 2 2 2 2 2 2 3', 13797), ('0 0 0 0 0 1 1 2 2 2 2 2 3 3', 13667), ('0 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3', 11158), ('0 0 1 1 1 1 1 1 2 2 3 3 3 3 3 3', 11003), ('0 0 0 1 1 1 1 1 2 2 2 3 3 3 3 3', 9966), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', 9578)]
2023-05-02 14:51:01,463 INFO     LM most common: [('0 1 2 3', -3.3599915504455566), ('0 0 1 2 2 3', -3.4635801315307617), ('0 1 1 2 3 3', -3.4993133544921875), ('0 0 0 1 2 2 2 3', -3.6472864151000977), ('0 0 1 1 2 2 3 3', -3.7169227600097656), ('0 1 1 1 2 3 3 3', -3.725853443145752), ('0 0 0 0 1 2 2 2 2 3', -3.8948707580566406), ('0 0 1 1 1 2 2 3 3 3', -3.910141944885254), ('0 1 1 1 1 2 3 3 3 3', -3.9188342094421387), ('0 0 0 1 1 2 2 2 3 3', -3.9367775917053223), ('0 0 1 1 1 1 2 2 3 3 3 3', -4.098911285400391), ('0 1 1 1 1 1 2 3 3 3 3 3', -4.098945617675781), ('0 0 0 1 1 1 2 2 2 3 3 3', -4.132080078125), ('0 0 0 0 0 1 2 2 2 2 2 3', -4.1497697830200195), ('0 0 0 0 1 1 2 2 2 2 3 3', -4.192755699157715), ('0 1 1 1 1 1 1 2 3 3 3 3 3 3', -4.278940200805664), ('0 0 1 1 1 1 1 2 2 3 3 3 3 3', -4.2830915451049805), ('0 0 0 1 1 1 1 2 2 2 3 3 3 3', -4.331847190856934), ('0 0 0 0 1 1 1 2 2 2 2 3 3 3', -4.384464740753174), ('0 0 0 0 0 0 1 2 2 2 2 2 2 3', -4.403499603271484), ('0 0 0 0 0 1 1 2 2 2 2 2 3 3', -4.444512844085693), ('0 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3', -4.460690498352051), ('0 0 1 1 1 1 1 1 2 2 3 3 3 3 3 3', -4.469512939453125), ('0 0 0 1 1 1 1 1 2 2 2 3 3 3 3 3', -4.528143882751465), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', -4.58405065536499)]
2023-05-02 14:51:01,464 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:51:01,464 INFO     []
2023-05-02 14:51:01,464 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:51:01,464 INFO     []
2023-05-02 14:51:01,465 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:51:01,465 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:51:01,465 INFO     
2023-05-02 14:51:01,908 INFO     Language: AnBmAnBm
2023-05-02 14:51:01,908 INFO     Description: A^n B^m A^n B^m
2023-05-02 14:51:42,327 INFO     DONE TRAINING
2023-05-02 14:51:43,638 INFO     TRAINING SET LOSS: 296.82140013575554
2023-05-02 15:00:38,797 INFO     LM most common: [('0 1 0 1', 121257), ('0 0 1 0 0 1', 84678), ('0 1 1 0 1 1', 72710), ('0 0 0 1 0 0 0 1', 56945), ('0 0 1 1 0 0 1 1', 53672), ('0 1 1 1 0 1 1 1', 46481), ('0 0 0 0 1 0 0 0 0 1', 36948), ('0 0 0 1 1 0 0 0 1 1', 36941), ('0 0 1 1 1 0 0 1 1 1', 34134), ('0 1 1 1 1 0 1 1 1 1', 29672), ('0 0 0 0 1 1 0 0 0 0 1 1', 23685), ('0 0 0 0 0 1 0 0 0 0 0 1', 23518), ('0 0 0 1 1 1 0 0 0 1 1 1', 23374), ('0 0 1 1 1 1 0 0 1 1 1 1', 21674), ('0 1 1 1 1 1 0 1 1 1 1 1', 19171), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1', 15482), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1', 15412), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1', 14982), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1', 14696), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1', 13950), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1', 12344), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', 9961), ('0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1', 9781), ('0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1', 9675), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1', 9607)]
2023-05-02 15:00:39,446 INFO     LM most common: [('0 1 0 1', -3.0077691078186035), ('0 0 1 0 0 1', -3.15592098236084), ('0 0 0 1 0 0 0 1', -3.3159401416778564), ('0 1 1 0 1 1', -3.406994342803955), ('0 0 1 1 0 0 1 1', -3.427183151245117), ('0 0 0 1 1 0 0 0 1 1', -3.5682528018951416), ('0 0 0 0 1 0 0 0 0 1', -3.5726451873779297), ('0 1 1 1 0 1 1 1', -3.7033586502075195), ('0 0 1 1 1 0 0 1 1 1', -3.7168502807617188), ('0 0 0 0 1 1 0 0 0 0 1 1', -3.824784755706787), ('0 0 0 1 1 1 0 0 0 1 1 1', -3.8495354652404785), ('0 0 0 0 0 1 0 0 0 0 0 1', -3.8691914081573486), ('0 1 1 1 1 0 1 1 1 1', -3.9717719554901123), ('0 0 1 1 1 1 0 0 1 1 1 1', -3.99690842628479), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1', -4.087555885314941), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1', -4.113404750823975), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1', -4.132143020629883), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1', -4.164066791534424), ('0 1 1 1 1 1 0 1 1 1 1 1', -4.239011764526367), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1', -4.279937744140625), ('0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1', -4.362803936004639), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', -4.363000869750977), ('0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1', -4.402557373046875), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1', -4.419009208679199), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1', -4.454500198364258)]
2023-05-02 15:00:39,446 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:00:39,446 INFO     []
2023-05-02 15:00:39,446 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:00:39,446 INFO     []
2023-05-02 15:00:39,447 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:00:39,447 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:00:39,447 INFO     
2023-05-02 15:00:39,923 INFO     Language: AnBmAnBmCCC
2023-05-02 15:00:39,924 INFO     Description: A^n B^m A^n B^m CCC
2023-05-02 15:01:23,493 INFO     DONE TRAINING
2023-05-02 15:01:24,909 INFO     TRAINING SET LOSS: 239.65809117257595
2023-05-02 15:12:17,316 INFO     LM most common: [('0 1 0 1 2 2 2', 120620), ('0 0 1 0 0 1 2 2 2', 79785), ('0 1 1 0 1 1 2 2 2', 75317), ('0 1 1 1 0 1 1 1 2 2 2', 51972), ('0 0 0 1 0 0 0 1 2 2 2', 51358), ('0 0 1 1 0 0 1 1 2 2 2', 50225), ('0 0 0 0 1 0 0 0 0 1 2 2 2', 35910), ('0 1 1 1 1 0 1 1 1 1 2 2 2', 34355), ('0 0 1 1 1 0 0 1 1 1 2 2 2', 34071), ('0 0 0 1 1 0 0 0 1 1 2 2 2', 30122), ('0 0 1 1 1 1 0 0 1 1 1 1 2 2 2', 23089), ('0 0 0 0 0 1 0 0 0 0 0 1 2 2 2', 23086), ('0 1 1 1 1 1 0 1 1 1 1 1 2 2 2', 22760), ('0 0 0 0 1 1 0 0 0 0 1 1 2 2 2', 21214), ('0 0 0 1 1 1 0 0 0 1 1 1 2 2 2', 19935), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1 2 2 2', 15546), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1 2 2 2', 15141), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1 2 2 2', 14422), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1 2 2 2', 13914), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1 2 2 2', 13520), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1 2 2 2', 13518), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 2 2 2', 10170), ('0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 2 2 2', 9824), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 2 2 2', 9368), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 2 2 2', 9238)]
2023-05-02 15:12:18,108 INFO     LM most common: [('0 1 0 1 2 2 2', -3.0246129035949707), ('0 0 1 0 0 1 2 2 2', -3.242462158203125), ('0 1 1 0 1 1 2 2 2', -3.3771519660949707), ('0 0 0 1 0 0 0 1 2 2 2', -3.519606590270996), ('0 1 1 1 0 1 1 1 2 2 2', -3.5245862007141113), ('0 0 1 1 0 0 1 1 2 2 2', -3.5595855712890625), ('0 0 0 0 1 0 0 0 0 1 2 2 2', -3.660252809524536), ('0 1 1 1 1 0 1 1 1 1 2 2 2', -3.713244676589966), ('0 0 1 1 1 0 0 1 1 1 2 2 2', -3.764799118041992), ('0 0 0 0 0 1 0 0 0 0 0 1 2 2 2', -3.9000816345214844), ('0 0 1 1 1 1 0 0 1 1 1 1 2 2 2', -3.9465889930725098), ('0 1 1 1 1 1 0 1 1 1 1 1 2 2 2', -3.9486279487609863), ('0 0 0 1 1 0 0 0 1 1 2 2 2', -3.999818801879883), ('0 0 0 0 1 1 0 0 0 0 1 1 2 2 2', -4.100994110107422), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1 2 2 2', -4.13422966003418), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1 2 2 2', -4.171377182006836), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1 2 2 2', -4.211224555969238), ('0 0 0 1 1 1 0 0 0 1 1 1 2 2 2', -4.244977951049805), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1 2 2 2', -4.3190717697143555), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 2 2 2', -4.373361587524414), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1 2 2 2', -4.387767314910889), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1 2 2 2', -4.410636901855469), ('0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 2 2 2', -4.421748638153076), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 2 2 2', -4.48866081237793), ('0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 2 2 2', -4.531722545623779)]
2023-05-02 15:12:18,108 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:12:18,108 INFO     []
2023-05-02 15:12:18,108 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:12:18,108 INFO     []
2023-05-02 15:12:18,108 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:12:18,108 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:12:18,108 INFO     
2023-05-02 15:12:18,553 INFO     Language: AnBnCn
2023-05-02 15:12:18,553 INFO     Description: A^n B^n C^n
2023-05-02 15:12:57,196 INFO     DONE TRAINING
2023-05-02 15:12:58,459 INFO     TRAINING SET LOSS: 194.00285908579826
2023-05-02 15:23:42,987 INFO     LM most common: [('0 1 2', 362613), ('0 0 1 1 2 2', 228986), ('0 0 0 1 1 1 2 2 2', 147571), ('0 0 0 0 1 1 1 1 2 2 2 2', 94495), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', 60541), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', 38351), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 24524), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', 15639), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 9983), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 6252), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', 4055), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 2583), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', 1580), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1032), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 636), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 425), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 244), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 188), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 107), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 76), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 41), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 35), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 14), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 11), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 7)]
2023-05-02 15:23:43,045 INFO     LM most common: [('0 1 2', -1.4124170541763306), ('0 0 1 1 2 2', -1.7074785232543945), ('0 0 0 1 1 1 2 2 2', -1.9709787368774414), ('0 0 0 0 1 1 1 1 2 2 2 2', -2.241764545440674), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', -2.5160017013549805), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', -2.7927494049072266), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -3.071511745452881), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', -3.352036952972412), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -3.634139060974121), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -3.9176440238952637), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', -4.202378273010254), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.488199234008789), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.774974822998047), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.062569618225098), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.350863456726074), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.639735221862793), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.929073333740234), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.218770980834961), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.508729457855225), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.798852443695068), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.089038848876953), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.379208564758301), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.669267177581787), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.9591498374938965), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.248773574829102)]
2023-05-02 15:23:43,045 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:23:43,046 INFO     []
2023-05-02 15:23:43,046 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:23:43,046 INFO     []
2023-05-02 15:23:43,046 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:23:43,046 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 15:23:43,046 INFO     
2023-05-02 15:23:43,533 INFO     Language: AnBnCnDn
2023-05-02 15:23:43,533 INFO     Description: A^n B^n C^n D^n
2023-05-02 15:24:29,709 INFO     DONE TRAINING
2023-05-02 15:24:31,226 INFO     TRAINING SET LOSS: 149.5234678685665
2023-05-02 15:42:23,461 INFO     LM most common: [('0 1 2 3', 372544), ('0 0 1 1 2 2 3 3', 230738), ('0 0 0 1 1 1 2 2 2 3 3 3', 146815), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', 90931), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', 57633), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', 36493), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', 23508), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', 15082), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', 9693), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', 6062), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', 3830), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', 2438), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', 1554), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 974), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 627), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 388), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 260), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 173), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 100), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 68), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 32), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 22), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 17), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 11), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 6)]
2023-05-02 15:42:23,514 INFO     LM most common: [('0 1 2 3', -1.3464007377624512), ('0 0 1 1 2 2 3 3', -1.6756211519241333), ('0 0 0 1 1 1 2 2 2 3 3 3', -1.9577553272247314), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', -2.2869949340820312), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', -2.582939624786377), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', -2.864983558654785), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', -3.140533208847046), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', -3.4140961170196533), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', -3.6877570152282715), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', -3.962768077850342), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', -4.240001201629639), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', -4.520012378692627), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', -4.803208351135254), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.089899063110352), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.38028621673584), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.6745452880859375), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.972817420959473), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.275203704833984), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.58181095123291), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.892758846282959), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -7.20811653137207), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -7.527981281280518), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -7.852461814880371), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -8.181674003601074), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -8.515768051147461)]
2023-05-02 15:42:23,514 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:42:23,514 INFO     []
2023-05-02 15:42:23,514 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:42:23,514 INFO     []
2023-05-02 15:42:23,515 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:42:23,515 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 15:42:23,515 INFO     
2023-05-02 15:42:24,047 INFO     Language: AnBnCnDnEn
2023-05-02 15:42:24,047 INFO     Description: A^n B^n C^n D^n E^n
2023-05-02 15:43:17,723 INFO     DONE TRAINING
2023-05-02 15:43:19,481 INFO     TRAINING SET LOSS: 121.50967472046614
2023-05-02 16:13:33,031 INFO     LM most common: [('0 1 2 3 4', 344580), ('0 0 1 1 2 2 3 3 4 4', 225558), ('0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', 147615), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', 97100), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 63972), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', 41652), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', 27454), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', 18010), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', 11779), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', 7647), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', 4967), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', 3260), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', 2224), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 1426), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 946), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 626), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 411), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 279), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 179), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 107), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 78), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', 37), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 33), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', 17), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4', 12)]
2023-05-02 16:13:33,116 INFO     LM most common: [('0 1 2 3 4', -1.5261149406433105), ('0 0 1 1 2 2 3 3 4 4', -1.7809737920761108), ('0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', -2.021115779876709), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', -2.2580018043518066), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -2.504894256591797), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', -2.7487683296203613), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', -2.993317127227783), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', -3.2373547554016113), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', -3.481339454650879), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', -3.725241184234619), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', -3.969151258468628), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', -4.2131123542785645), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', -4.457130432128906), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -4.701241493225098), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -4.945460319519043), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.189809322357178), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.434274673461914), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.678869247436523), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.923616886138916), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.168520927429199), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.413561820983887), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -52.43640899658203), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', -54.090084075927734), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', -57.005088806152344), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4', -59.83689498901367)]
2023-05-02 16:13:33,117 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 16:13:33,117 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4']
2023-05-02 16:13:33,117 INFO     Grammatical sequences that the model is missing:
2023-05-02 16:13:33,117 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4']
2023-05-02 16:13:33,119 INFO     LM precision, recall, fscore: 0.84 0.84 0.8399999999999999
2023-05-02 16:13:33,119 INFO     Memorization precision, recall, fscore: 1.0 0.76 0.8636363636363636
2023-05-02 16:13:33,119 INFO     
2023-05-02 16:13:33,806 INFO     Language: A2en
2023-05-02 16:13:33,806 INFO     Description: A^(2^n)
2023-05-02 16:13:52,141 INFO     DONE TRAINING
2023-05-02 16:13:52,774 INFO     TRAINING SET LOSS: 261.9278687313199
2023-05-02 16:15:06,934 INFO     LM most common: [('0', 814561), ('0 0', 151260), ('0 0 0 0', 28211), ('0 0 0 0 0 0 0 0', 4835), ('0 0 0 0 0 0 0 0 0 0 0 0', 858), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 190), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 60), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 14), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 7), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 3), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1)]
2023-05-02 16:15:06,946 INFO     LM most common: [('0', -0.05060385912656784), ('0 0', -3.059605836868286), ('0 0 0 0', -6.059097766876221), ('0 0 0 0 0 0 0 0', -9.245280265808105), ('0 0 0 0 0 0 0 0 0 0 0 0', -12.209855079650879), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -14.617998123168945), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -16.524110794067383), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -18.013484954833984), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -19.180767059326172), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -20.11406135559082), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -21.541366577148438)]
2023-05-02 16:15:06,946 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 16:15:06,946 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 16:15:06,946 INFO     Grammatical sequences that the model is missing:
2023-05-02 16:15:06,946 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 16:15:06,947 INFO     LM precision, recall, fscore: 0.5454545454545454 0.6 0.5714285714285713
2023-05-02 16:15:06,947 INFO     Memorization precision, recall, fscore: 0.875 0.7 0.7777777777777777
2023-05-02 16:15:06,947 INFO     
2023-05-02 16:15:07,438 INFO     Language: ABnen
2023-05-02 16:15:07,438 INFO     Description: (AB)^(n^2)
2023-05-02 16:15:46,184 INFO     DONE TRAINING
2023-05-02 16:15:47,462 INFO     TRAINING SET LOSS: 142.90951471030712
2023-05-02 16:38:44,380 INFO     LM most common: [('0 1', 696937), ('0 1 0 1 0 1 0 1', 207274), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 75569), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 12330), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 894), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 882), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 417), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 407), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 382), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 378), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 377), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 374), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 362), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 320), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 318), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 300), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 295), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 245), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 220), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 185), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 168), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 162), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 156), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 124), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 108)]
2023-05-02 16:38:44,476 INFO     LM most common: [('0 1', -0.17365007102489471), ('0 1 0 1 0 1 0 1', -2.0316338539123535), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.6353116035461426), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.592367172241211), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.473454475402832), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.591564178466797), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.608417510986328), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.61038589477539), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.611891746520996), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.618014335632324), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.62033748626709), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.630342483520508), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.633210182189941), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.646114349365234), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.65001392364502), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.664227485656738), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.669783592224121), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.682317733764648), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.691682815551758), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.698805809020996), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.712845802307129), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.723944664001465), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.731426239013672), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.73460578918457), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.735551834106445)]
2023-05-02 16:38:44,477 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 16:38:44,477 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1']
2023-05-02 16:38:44,477 INFO     Grammatical sequences that the model is missing:
2023-05-02 16:38:44,477 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1']
2023-05-02 16:38:44,478 INFO     LM precision, recall, fscore: 0.24 0.5384615384615384 0.33201581027667987
2023-05-02 16:38:44,478 INFO     Memorization precision, recall, fscore: 1.0 0.6153846153846154 0.761904761904762
2023-05-02 16:38:44,478 INFO     
2023-05-02 16:38:45,165 INFO     Language: Count
2023-05-02 16:38:45,165 INFO     Description: Any prefix of [b, bb, bbb, bbbb, ...], with a's separating the elements of the prefix
2023-05-02 16:39:32,790 INFO     DONE TRAINING
2023-05-02 16:39:34,346 INFO     TRAINING SET LOSS: 184.5604953095317
2023-05-02 17:14:09,825 INFO     LM most common: [('0 1', 440169), ('0 1 0 1 1', 248787), ('0 1 0 1 1 0 1 1 1', 140653), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1', 76126), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1', 42375), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1', 22985), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1', 12566), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 7100), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1', 3956), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1', 2255), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1', 1310), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', 739), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0', 561), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', 418)]
2023-05-02 17:14:09,852 INFO     LM most common: [('0 1', -0.9648011922836304), ('0 1 0 1 1', -1.427819848060608), ('0 1 0 1 1 0 1 1 1', -1.878810167312622), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1', -2.4146454334259033), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1', -2.908750057220459), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1', -3.4343841075897217), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1', -3.959341287612915), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -4.447998523712158), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1', -4.943048000335693), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1', -5.402690410614014), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1', -5.8695783615112305), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', -6.327952861785889), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.780202388763428), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0', -37.91516876220703)]
2023-05-02 17:14:09,852 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 17:14:09,852 INFO     ['0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0']
2023-05-02 17:14:09,853 INFO     Grammatical sequences that the model is missing:
2023-05-02 17:14:09,853 INFO     ['0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1']
2023-05-02 17:14:09,853 INFO     LM precision, recall, fscore: 0.9285714285714286 0.52 0.6666666666666666
2023-05-02 17:14:09,853 INFO     Memorization precision, recall, fscore: 1.0 0.72 0.8372093023255813
2023-05-02 17:14:09,853 INFO     
2023-05-02 17:14:11,874 INFO     Language: ChineseNumeral
2023-05-02 17:14:11,874 INFO     Description: Several groups of b's joined with a single a separating each; each group of b's must be shorter than the previous one
2023-05-02 17:16:19,869 INFO     DONE TRAINING
2023-05-02 17:16:24,096 INFO     TRAINING SET LOSS: 284.1914556771517
2023-05-02 17:56:36,082 INFO     LM most common: [('0 1', 131930), ('0 1 1', 82252), ('0 1 1 1', 53685), ('0 1 1 0 1', 37286), ('0 1 1 1 1', 32570), ('0 1 1 1 0 1 1', 25590), ('0 1 1 1 0 1', 18903), ('0 1 1 1 1 1', 18519), ('0 1 1 1 1 0 1 1 1', 13104), ('0 1 1 1 1 1 1', 12455), ('0 1 1 1 1 0 1 1', 11160), ('0 1 1 1 1 0 1', 11159), ('0 1 1 1 0 1 1 0 1', 9193), ('0 1 1 1 1 1 1 1', 9048), ('0 1 1 1 1 1 0 1 1 1', 8322), ('0 1 1 1 1 1 0 1 1 1 1', 7602), ('0 1 1 1 1 1 0 1', 7122), ('0 1 1 1 1 1 1 1 1', 6706), ('0 1 1 1 1 1 0 1 1', 6485), ('0 1 1 1 1 0 1 1 1 0 1 1', 6075), ('0 1 1 1 1 1 1 0 1 1 1 1', 5390), ('0 1 1 1 1 1 1 0 1 1 1', 4707), ('0 1 1 1 1 1 1 0 1 1', 4579), ('0 1 1 1 1 1 1 0 1 1 1 1 1', 4539), ('0 1 1 1 1 0 1 1 1 0 1', 4499)]
2023-05-02 17:59:53,163 INFO     LM most common: [('0 1', -3.790647506713867), ('0 1 1', -4.443431854248047), ('0 1 1 1', -5.01123046875), ('0 1 1 1 0 1 1', -5.397812366485596), ('0 1 1 1 1 0 1 1 1', -5.679315567016602), ('0 1 1 1 1', -5.750582218170166), ('0 1 1 0 1', -6.023676872253418), ('0 1 1 1 1 1 0 1 1 1 1', -6.084406852722168), ('0 1 1 1 1 0 1 1 1 0 1 1', -6.168116092681885), ('0 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.327323913574219), ('0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1', -6.491153717041016), ('0 1 1 1 0 1', -6.506546497344971), ('0 1 1 1 1 1 0 1 1 1', -6.60932731628418), ('0 1 1 1 1 1', -6.610555171966553), ('0 1 1 1 1 0 1 1', -6.732122898101807), ('0 1 1 1 1 1 1 0 1 1 1 1 1', -6.740772247314453), ('0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.75906229019165), ('0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1', -6.904485702514648), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1', -6.908637523651123), ('0 1 1 1 1 1 1 0 1 1 1 1', -6.925615310668945), ('0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1', -6.931836128234863), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -7.0117387771606445), ('0 1 1 1 1 1 0 1 1 1 1 0 1 1', -7.0686492919921875), ('0 1 1 1 1 1 0 1 1 1 0 1 1', -7.089030742645264), ('0 1 1 1 1 1 1', -7.178837299346924)]
2023-05-02 17:59:53,164 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 17:59:53,164 INFO     []
2023-05-02 17:59:53,164 INFO     Grammatical sequences that the model is missing:
2023-05-02 17:59:53,164 INFO     []
2023-05-02 17:59:53,171 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 17:59:53,171 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 17:59:53,171 INFO     
2023-05-02 17:59:53,783 INFO     Language: ABAnBn
2023-05-02 17:59:53,784 INFO     Description: Sigma+ A^ B^n (except it seems to be missing some short ones, like aab)
2023-05-02 18:00:37,086 INFO     DONE TRAINING
2023-05-02 18:00:38,492 INFO     TRAINING SET LOSS: 513.3179121911526
2023-05-02 18:13:05,239 INFO     LM most common: [('0 0 1 1 0 1', 18780), ('0 1 0 0 1 1', 18337), ('0 0 0 1 1 1 0 1', 12893), ('0 1 0 0 0 1 1 1', 12335), ('0 0 0 1 1 1 0 0 1 1', 9362), ('0 0 0 0 1 1 1 1 0 1', 9079), ('0 0 1 1 0 0 0 1 1 1', 8760), ('0 1 0 0 0 0 1 1 1 1', 7560), ('0 0 1 0 1', 7526), ('0 1 1 0 1', 6880), ('0 0 0 0 1 1 1 1 0 0 1 1', 6657), ('0 1 0 0 1', 6238), ('0 0 0 0 0 1 1 1 1 1 0 1', 6235), ('0 0 0 1 1 1 0 0 0 1 1 1', 5959), ('0 0 1 1 0 0 0 0 1 1 1 1', 5886), ('1 0 1 0 1', 5552), ('0 0 1 0 0 1 1', 5538), ('0 0 1 1 1 0 1', 5381), ('0 1 0 0 0 0 0 1 1 1 1 1', 5225), ('0 0 0 1 1 0 1', 5070), ('0 0 1 1 0 0 1', 4945), ('0 1 1 0 0 1 1', 4864), ('1 0 0 1 1 0 1', 4841), ('1 0 1 0 0 1 1', 4699), ('0 0 0 0 0 1 1 1 1 1 0 0 1 1', 4679)]
2023-05-02 18:14:16,199 INFO     LM most common: [('0 0 1 1 0 1', -4.143017768859863), ('0 1 0 0 1 1', -4.226620197296143), ('0 0 0 1 1 1 0 1', -4.35438346862793), ('0 0 0 1 1 1 0 0 1 1', -4.402317047119141), ('0 0 0 0 1 1 1 1 0 1', -4.453649044036865), ('0 1 0 0 0 1 1 1', -4.501675128936768), ('0 0 0 0 1 1 1 1 0 0 1 1', -4.506587982177734), ('0 0 1 1 0 0 0 1 1 1', -4.512868881225586), ('0 0 0 0 0 1 1 1 1 1 0 1', -4.662578582763672), ('0 0 0 0 0 1 1 1 1 1 0 0 1 1', -4.665308952331543), ('0 0 0 1 1 1 0 0 0 1 1 1', -4.711284160614014), ('0 0 1 1 0 0 0 0 1 1 1 1', -4.712867259979248), ('0 1 0 0 0 0 1 1 1 1', -4.768071174621582), ('0 0 0 0 1 1 1 1 0 0 0 1 1 1', -4.826426982879639), ('0 0 0 1 1 1 0 0 0 0 1 1 1 1', -4.830885887145996), ('0 0 0 0 0 0 1 1 1 1 1 1 0 1', -4.89070987701416), ('0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1', -4.924571990966797), ('0 0 1 1 0 0 0 0 0 1 1 1 1 1', -4.931765079498291), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', -4.932354927062988), ('0 1 0 0 0 0 0 1 1 1 1 1', -4.969671249389648), ('0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1', -5.031172752380371), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1', -5.0492377281188965), ('0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1', -5.068881988525391), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1', -5.083078861236572), ('0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1', -5.095507621765137)]
2023-05-02 18:14:16,200 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:14:16,200 INFO     []
2023-05-02 18:14:16,200 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:14:16,200 INFO     []
2023-05-02 18:14:16,204 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:14:16,204 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:14:16,204 INFO     
2023-05-02 18:14:16,714 INFO     Language: ABaaaAB
2023-05-02 18:14:16,714 INFO     Description: Sigma+ AAA Sigma+
2023-05-02 18:14:48,379 INFO     DONE TRAINING
2023-05-02 18:14:49,383 INFO     TRAINING SET LOSS: 738.8170753717422
2023-05-02 18:18:40,120 INFO     LM most common: [('1 0 0 0 1', 31310), ('0 0 0 0 1', 28785), ('1 0 0 0 0', 28078), ('0 0 0 0 0', 25569), ('1 0 0 0 0 1', 19066), ('0 0 0 0 0 1', 17813), ('1 0 0 0 0 0', 17454), ('0 0 0 0 0 0', 17131), ('1 0 0 0 1 1', 10875), ('1 1 0 0 0 1', 10611), ('1 0 0 0 1 0', 10209), ('0 0 0 0 1 1', 9980), ('0 1 0 0 0 1', 9808), ('0 0 0 0 1 0', 9459), ('1 1 0 0 0 0', 9359), ('1 0 0 0 0 0 1', 8909), ('0 0 0 0 0 0 1', 8677), ('0 1 0 0 0 0', 8617), ('1 0 0 0 0 0 0', 8510), ('0 0 0 0 0 0 0', 8262), ('1 0 0 0 0 1 1', 6339), ('1 1 0 0 0 0 1', 6206), ('0 0 0 0 0 1 1', 5920), ('0 1 0 0 0 0 1', 5718), ('1 0 0 0 0 1 0', 5559)]
2023-05-02 18:19:57,087 INFO     LM most common: [('1 0 0 0 1', -3.4436421394348145), ('1 0 0 0 0 1', -3.480103015899658), ('0 0 0 0 1', -3.6456499099731445), ('0 0 0 0 0 1', -3.650052309036255), ('1 0 0 0 0 0', -3.708117961883545), ('1 0 0 0 0', -3.804823398590088), ('0 0 0 0 0 0', -3.8062620162963867), ('1 0 0 0 0 0 1', -3.942178726196289), ('0 0 0 0 0', -4.037040710449219), ('0 0 0 0 0 0 1', -4.08466911315918), ('1 0 0 0 0 0 0', -4.108879089355469), ('0 0 0 0 0 0 0', -4.186886787414551), ('1 0 0 0 1 1', -4.477085113525391), ('1 0 0 0 0 0 0 1', -4.560778617858887), ('1 0 0 0 0 1 1', -4.568115234375), ('1 0 0 0 1 0', -4.587639808654785), ('0 0 0 0 1 1', -4.6686110496521), ('1 0 0 0 0 0 0 0', -4.672295093536377), ('0 0 0 0 0 0 0 1', -4.681777000427246), ('0 0 0 0 0 0 0 0', -4.741436004638672), ('0 0 0 0 0 1 1', -4.7421183586120605), ('0 0 0 0 1 0', -4.762330055236816), ('1 0 0 0 0 1 0', -4.814118385314941), ('1 1 0 0 0 1', -4.9298200607299805), ('1 0 0 0 0 0 1 1', -4.965426921844482)]
2023-05-02 18:19:57,087 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:19:57,087 INFO     []
2023-05-02 18:19:57,087 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:19:57,087 INFO     []
2023-05-02 18:19:57,092 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:19:57,092 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:19:57,092 INFO     
2023-05-02 18:19:57,404 INFO     Language: Unequal
2023-05-02 18:19:57,404 INFO     Description: Strings over {A, B} with an unequal number of A's and B's
2023-05-02 18:20:21,697 INFO     DONE TRAINING
2023-05-02 18:20:22,450 INFO     TRAINING SET LOSS: 943.9097924828529
2023-05-02 18:22:36,298 INFO     LM most common: [('0', 217667), ('1', 201017), ('0 0', 72324), ('1 1', 63128), ('0 1 0', 24806), ('0 0 1', 23492), ('0 0 0', 23392), ('1 0 0', 22693), ('0 1 1', 22456), ('1 0 1', 22195), ('1 1 1', 21805), ('1 1 0', 20258), ('1 1 1 1', 7832), ('0 0 0 0', 7815), ('0 0 1 0', 7223), ('0 1 0 0', 7182), ('1 0 0 0', 6882), ('1 0 1 1', 6674), ('0 1 1 1', 6491), ('0 0 0 1', 6453), ('1 1 0 1', 6305), ('1 1 1 0', 5796), ('0 0 1 1 0', 3071), ('1 0 0 1 0', 3066), ('0 1 0 1 0', 3056)]
2023-05-02 18:22:49,070 INFO     LM most common: [('0', -1.3277665376663208), ('1', -1.478776216506958), ('0 0', -2.4424490928649902), ('1 1', -2.7046802043914795), ('0 0 0', -3.588545083999634), ('0 0 1', -3.657885789871216), ('1 1 1', -3.7361512184143066), ('1 1 0', -3.9201974868774414), ('0 1 0', -3.9328017234802246), ('1 0 0', -4.076844215393066), ('0 1 1', -4.1355485916137695), ('1 0 1', -4.150572776794434), ('0 0 0 0', -4.700415134429932), ('1 1 1 1', -4.714421272277832), ('0 0 1 0', -4.922576427459717), ('0 0 0 1', -5.071898460388184), ('1 1 0 1', -5.140098571777344), ('1 1 1 0', -5.294402122497559), ('1 0 0 0', -5.334985733032227), ('0 1 0 0', -5.342474937438965), ('1 0 1 1', -5.417630195617676), ('0 1 1 1', -5.483863830566406), ('0 0 0 0 0', -5.966683387756348), ('1 1 0 0 0', -6.056151390075684), ('0 0 1 1 0', -6.067363739013672)]
2023-05-02 18:22:49,071 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:22:49,071 INFO     []
2023-05-02 18:22:49,071 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:22:49,071 INFO     []
2023-05-02 18:22:49,071 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:22:49,071 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:22:49,071 INFO     
2023-05-02 18:22:49,512 INFO     Language: Bach2
2023-05-02 18:22:49,512 INFO     Description: Strings over {A, B} with an equal number of A's and B's
2023-05-02 18:23:21,337 INFO     DONE TRAINING
2023-05-02 18:23:22,347 INFO     TRAINING SET LOSS: 712.3849893808365
2023-05-02 18:28:56,133 INFO     LM most common: [('1 0', 179008), ('0 1', 178581), ('0 0 1 1', 40175), ('1 0 0 1', 36567), ('0 1 1 0', 36410), ('1 1 0 0', 35974), ('1 0 1 0', 35472), ('0 1 0 1', 35347), ('1 0 0 0 1 1', 8219), ('0 0 1 0 1 1', 8110), ('0 0 0 1 1 1', 8076), ('1 1 0 1 0 0', 7977), ('0 1 0 0 1 1', 7970), ('0 1 1 1 0 0', 7735), ('1 1 1 0 0 0', 7555), ('0 0 1 1 1 0', 7301), ('0 0 1 1 0 1', 7255), ('1 0 1 0 0 1', 7037), ('1 1 0 0 0 1', 7000), ('1 0 1 1 0 0', 6934), ('0 1 1 0 1 0', 6870), ('0 1 1 0 0 1', 6790), ('1 1 0 0 1 0', 6750), ('1 0 0 1 0 1', 6587), ('0 1 0 1 0 1', 6546)]
2023-05-02 18:29:45,790 INFO     LM most common: [('0 1', -1.2454456090927124), ('1 0', -1.2699506282806396), ('1 0 0 1', -2.9758141040802), ('0 1 1 0', -2.976438522338867), ('0 1 0 1', -3.0376667976379395), ('1 0 1 0', -3.0875704288482666), ('0 0 1 1', -3.327475070953369), ('1 1 0 0', -3.510101318359375), ('0 1 1 0 0 1', -4.879459381103516), ('1 0 1 0 0 1', -4.9359588623046875), ('0 1 1 0 1 0', -4.959092140197754), ('1 0 0 1 0 1', -4.971037864685059), ('0 1 0 1 0 1', -5.065971851348877), ('1 0 0 0 1 1', -5.080572605133057), ('1 0 0 1 1 0', -5.092673301696777), ('0 1 0 1 1 0', -5.093033790588379), ('0 1 0 0 1 1', -5.148869514465332), ('0 1 1 1 0 0', -5.161854267120361), ('1 0 1 0 1 0', -5.192550182342529), ('0 0 1 1 1 0', -5.290350437164307), ('0 0 1 1 0 1', -5.344501972198486), ('1 1 0 0 0 1', -5.383255481719971), ('1 0 1 1 0 0', -5.475050926208496), ('1 1 0 0 1 0', -5.494365692138672), ('0 0 0 1 1 1', -5.5620832443237305)]
2023-05-02 18:29:45,790 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:29:45,790 INFO     []
2023-05-02 18:29:45,790 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:29:45,790 INFO     []
2023-05-02 18:29:45,792 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:29:45,793 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:29:45,793 INFO     
2023-05-02 18:29:46,631 INFO     Language: Bach3
2023-05-02 18:29:46,631 INFO     Description: Strings over {A, B, C} with an equal number of A's, B's, and C's
2023-05-02 18:30:25,374 INFO     DONE TRAINING
2023-05-02 18:30:26,633 INFO     TRAINING SET LOSS: 950.7094302773476
2023-05-02 18:41:12,774 INFO     LM most common: [('1 0 2', 60603), ('1 2 0', 59698), ('0 2 1', 58369), ('2 1 0', 56672), ('0 1 2', 55904), ('2 0 1', 54002), ('0 1 2 2 1 0', 3277), ('0 2 0 1 2 1', 3274), ('2 0 0 1 2 1', 3268), ('1 2 0 0 2 1', 3212), ('1 2 2 1 0 0', 3189), ('0 1 0 2 2 1', 3122), ('2 1 0 0 1 2', 3100), ('0 1 2 2 0 1', 3080), ('0 2 2 0 1 1', 2990), ('0 1 1 2 0 2', 2982), ('0 1 2 0 2 1', 2979), ('0 0 2 1 2 1', 2972), ('1 2 0 0 1 2', 2967), ('0 2 1 2 1 0', 2940), ('2 0 1 0 2 1', 2939), ('1 0 2 2 1 0', 2915), ('1 2 1 0 0 2', 2908), ('1 1 2 0 0 2', 2870), ('0 1 2 1 2 0', 2865)]
2023-05-02 18:44:41,019 INFO     LM most common: [('1 2 0', -2.021482467651367), ('1 0 2', -2.072082281112671), ('0 1 2', -2.084372043609619), ('0 2 1', -2.1171646118164062), ('2 1 0', -2.1483349800109863), ('2 0 1', -2.1767852306365967), ('0 1 0 2 2 1', -5.5456624031066895), ('1 1 2 0 0 2', -5.565217018127441), ('2 0 1 0 2 1', -5.568345069885254), ('1 1 0 0 2 2', -5.658910751342773), ('0 1 2 2 0 1', -5.66137170791626), ('0 1 2 2 1 0', -5.669545650482178), ('1 2 0 0 2 1', -5.684032440185547), ('2 0 0 1 2 1', -5.694151878356934), ('1 1 0 2 0 2', -5.715437412261963), ('0 0 2 1 2 1', -5.718580722808838), ('1 1 0 2 2 0', -5.735224723815918), ('0 2 0 1 2 1', -5.742481708526611), ('0 0 1 2 2 1', -5.76857328414917), ('1 2 2 0 0 1', -5.816500186920166), ('0 1 1 2 0 2', -5.825630187988281), ('0 1 2 0 2 1', -5.830383777618408), ('2 1 0 0 2 1', -5.831809043884277), ('0 1 2 1 2 0', -5.833526134490967), ('0 0 2 1 1 2', -5.840394496917725)]
2023-05-02 18:44:41,020 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:44:41,020 INFO     []
2023-05-02 18:44:41,020 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:44:41,020 INFO     []
2023-05-02 18:44:41,033 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:44:41,033 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:44:41,033 INFO     
2023-05-02 18:44:41,975 INFO     Language: WeW
2023-05-02 18:44:41,975 INFO     Description: X^|X| (that is, a string X repeated |X| times, where |X| is the length of X)
2023-05-02 18:46:02,022 INFO     DONE TRAINING
2023-05-02 18:46:04,636 INFO     TRAINING SET LOSS: 344.1729976385832
2023-05-02 19:26:14,953 INFO     LM most common: [('1', 167901), ('0', 166559), ('0 1 0 1', 67311), ('0 0 0 0', 60414), ('1 0 1 0', 60163), ('1 1 1 1', 58244), ('0 0 1 0 0 1 0 0 1', 24706), ('1 1 0 1 1 0 1 1 0', 24213), ('1 0 1 1 0 1 1 0 1', 22804), ('0 1 1 0 1 1 0 1 1', 22504), ('0 1 0 0 1 0 0 1 0', 20669), ('0 0 0 0 0 0 0 0 0', 20538), ('1 0 0 1 0 0 1 0 0', 19342), ('1 1 1 1 1 1 1 1 1', 17421), ('0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1', 9158), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 7996), ('1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0', 7130), ('1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1', 6986), ('0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1', 6794), ('0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0', 6741), ('1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0', 6580), ('1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1', 6228), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 6061), ('0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0', 5887), ('0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1', 5379)]
2023-05-02 19:27:17,404 INFO     LM most common: [('1', -1.7868680953979492), ('0', -1.7941806316375732), ('0 1 0 1', -2.058098793029785), ('0 0 0 0', -2.271299123764038), ('1 1 1 1', -2.3217759132385254), ('1 0 1 0', -2.3375463485717773), ('0 0 0 0 0 0 0 0 0', -3.687826633453369), ('0 0 1 0 0 1 0 0 1', -3.724179744720459), ('1 0 1 1 0 1 1 0 1', -3.732440948486328), ('0 1 1 0 1 1 0 1 1', -3.7589690685272217), ('1 1 0 1 1 0 1 1 0', -3.825953483581543), ('0 1 0 0 1 0 0 1 0', -4.054180145263672), ('1 1 1 1 1 1 1 1 1', -4.058753967285156), ('1 0 0 1 0 0 1 0 0', -4.118740558624268), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.980185031890869), ('0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1', -5.024632930755615), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.517702579498291), ('1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1', -5.696053981781006), ('1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1', -5.714998722076416), ('0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1', -5.725502967834473), ('0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0', -5.799683570861816), ('1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0', -5.84833288192749), ('1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0', -5.867650032043457), ('0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0', -5.87080192565918), ('1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.9096574783325195)]
2023-05-02 19:27:17,404 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 19:27:17,405 INFO     []
2023-05-02 19:27:17,405 INFO     Grammatical sequences that the model is missing:
2023-05-02 19:27:17,405 INFO     []
2023-05-02 19:27:17,406 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 19:27:17,406 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 19:27:17,406 INFO     
2023-05-02 19:27:17,406 INFO     Average LM Y&P precision: 0.9548933209647495
2023-05-02 19:27:17,407 INFO     Average LM Y&P recall: 0.9549725274725277
2023-05-02 19:27:17,407 INFO     Average LM Y&P F-score: 0.9527526308848403
2023-05-02 19:27:17,407 INFO     
2023-05-02 19:27:17,407 INFO     Average memorization Y&P precision: 0.9977678571428571
2023-05-02 19:27:17,407 INFO     Average memorization Y&P recall: 0.9386675824175823
2023-05-02 19:27:17,407 INFO     Average memorization Y&P F-score: 0.9643377891575774
2023-05-02 19:27:17,407 INFO     
