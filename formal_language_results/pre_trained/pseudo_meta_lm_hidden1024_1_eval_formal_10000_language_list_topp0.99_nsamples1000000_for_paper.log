2023-05-02 07:57:59,549 INFO     Namespace(n_meta_train=25000, n_meta_valid=500, n_meta_test=1000, meta_train_batch_size=10, meta_eval_batch_size=1000, max_batches_per_language=20, meta_train_size=10, meta_test_size=1000, dataset='scfg', yandp_param_file=None, formal_train_size=10000, formal_test_size=10, language_list='language_list', withheld_languages='language_list', architecture='LSTM', n_embd=1024, n_positions=256, n_head=12, n_layer=2, dropout=0.1, n_epochs=1, eval_every=100, weight_decay=0.1, learning_rate=0.005, inner_lr=1.0, lr_scheduler_type='cosine', warmup_proportion=0.05, patience=None, lr_decay_patience=None, multi_step_loss=True, model_name='pseudo_meta_lm_hidden1024_1', weight_dir='/scratch/gpfs/tm4633/inductive_bias_distillation/weights/', log_dir='/scratch/gpfs/tm4633/inductive_bias_distillation/logs/', eval=True, eval_formal=True, eval_valid=False, top_p=0.99, hot_temperature=1.0, cold_temperature=0.5, prec_rec_n_samples=1000000, sgd_epochs=5, adam_lr=0.0005, adam_epochs=5, eval_suffix='_for_paper', random_normalized=False, return_last=True, force_precision_denominator=False)
2023-05-02 07:58:03,747 INFO     Model size: 16.8M parameters
2023-05-02 07:58:03,747 INFO     Loading model checkpoint from /scratch/gpfs/tm4633/inductive_bias_distillation/weights/pseudo_meta_lm_hidden1024_1
2023-05-02 07:58:04,264 INFO     Language: An
2023-05-02 07:58:04,264 INFO     Description: Any number of As
2023-05-02 07:58:28,644 INFO     DONE TRAINING
2023-05-02 07:58:29,407 INFO     TRAINING SET LOSS: 479.64293214678764
2023-05-02 08:00:23,945 INFO     LM most common: [('0', 373957), ('0 0', 215734), ('0 0 0', 143117), ('0 0 0 0', 93463), ('0 0 0 0 0', 60711), ('0 0 0 0 0 0', 39296), ('0 0 0 0 0 0 0', 25886), ('0 0 0 0 0 0 0 0', 16844), ('0 0 0 0 0 0 0 0 0', 10813), ('0 0 0 0 0 0 0 0 0 0', 7021), ('0 0 0 0 0 0 0 0 0 0 0', 4474), ('0 0 0 0 0 0 0 0 0 0 0 0', 2995), ('0 0 0 0 0 0 0 0 0 0 0 0 0', 1975), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1257), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 879), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 541), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 356), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 248), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 155), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 103), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 58), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 39), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 22), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 22), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 10)]
2023-05-02 08:00:23,981 INFO     LM most common: [('0', -1.336416482925415), ('0 0', -1.838538408279419), ('0 0 0', -2.04022216796875), ('0 0 0 0', -2.294410467147827), ('0 0 0 0 0', -2.551332712173462), ('0 0 0 0 0 0', -2.8071627616882324), ('0 0 0 0 0 0 0', -3.062384843826294), ('0 0 0 0 0 0 0 0', -3.316927909851074), ('0 0 0 0 0 0 0 0 0', -3.5709052085876465), ('0 0 0 0 0 0 0 0 0 0', -3.824460744857788), ('0 0 0 0 0 0 0 0 0 0 0', -4.077664375305176), ('0 0 0 0 0 0 0 0 0 0 0 0', -4.3305816650390625), ('0 0 0 0 0 0 0 0 0 0 0 0 0', -4.5832648277282715), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.835751533508301), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.088067531585693), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.340236186981201), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.592259407043457), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -5.8441548347473145), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.095940589904785), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.347620010375977), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.599183082580566), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.8506388664245605), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.101996421813965), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.3532395362854), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.604398250579834)]
2023-05-02 08:00:23,981 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:00:23,981 INFO     []
2023-05-02 08:00:23,982 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:00:23,982 INFO     []
2023-05-02 08:00:23,982 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:00:23,982 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 08:00:23,982 INFO     
2023-05-02 08:00:24,315 INFO     Language: AB
2023-05-02 08:00:24,315 INFO     Description: Sigma* over {A, B}
2023-05-02 08:00:48,371 INFO     DONE TRAINING
2023-05-02 08:00:49,129 INFO     TRAINING SET LOSS: 991.2817375063896
2023-05-02 08:02:48,475 INFO     LM most common: [('1', 181195), ('0', 173689), ('0 1', 59297), ('1 1', 57908), ('1 0', 56530), ('0 0', 54511), ('0 0 1', 18637), ('0 1 0', 18485), ('1 0 1', 18437), ('1 1 0', 17962), ('0 1 1', 17701), ('1 1 1', 17321), ('1 0 0', 17280), ('0 0 0', 17131), ('1 0 1 1', 6400), ('1 0 1 0', 6334), ('0 0 1 0', 6254), ('0 0 1 1', 6138), ('1 0 0 1', 6133), ('1 1 0 1', 6104), ('0 1 0 1', 6095), ('0 0 0 1', 5993), ('1 1 1 0', 5933), ('0 1 0 0', 5592), ('1 1 1 1', 5570)]
2023-05-02 08:02:59,658 INFO     LM most common: [('1', -1.623636245727539), ('0', -1.7105399370193481), ('0 1', -2.7700936794281006), ('1 1', -2.815464496612549), ('1 0', -2.84917950630188), ('0 0', -2.9335074424743652), ('0 0 1', -3.9925589561462402), ('1 0 1', -3.9960777759552), ('0 1 0', -4.011075019836426), ('1 1 0', -4.060037612915039), ('0 1 1', -4.085358619689941), ('1 1 1', -4.124191761016846), ('1 0 0', -4.133904457092285), ('0 0 0', -4.149204254150391), ('1 0 1 1', -5.036134719848633), ('0 0 1 0', -5.0581793785095215), ('1 0 1 0', -5.074951648712158), ('0 0 1 1', -5.080569267272949), ('1 1 0 1', -5.108920097351074), ('1 0 0 1', -5.13362455368042), ('0 0 0 1', -5.152471542358398), ('0 1 0 1', -5.153593063354492), ('1 1 1 0', -5.19718074798584), ('0 1 0 0', -5.282495021820068), ('1 1 0 0', -5.308239936828613)]
2023-05-02 08:02:59,658 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:02:59,658 INFO     []
2023-05-02 08:02:59,658 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:02:59,658 INFO     []
2023-05-02 08:02:59,659 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:02:59,659 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:02:59,659 INFO     
2023-05-02 08:03:00,041 INFO     Language: ABn
2023-05-02 08:03:00,042 INFO     Description: (AB)^n
2023-05-02 08:03:31,791 INFO     DONE TRAINING
2023-05-02 08:03:32,804 INFO     TRAINING SET LOSS: 275.2959712445736
2023-05-02 08:09:06,708 INFO     LM most common: [('0 1', 355999), ('0 1 0 1', 229455), ('0 1 0 1 0 1', 148108), ('0 1 0 1 0 1 0 1', 94823), ('0 1 0 1 0 1 0 1 0 1', 61160), ('0 1 0 1 0 1 0 1 0 1 0 1', 39415), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', 25133), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 16328), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 10628), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 6799), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 4308), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 2817), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1758), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1169), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 757), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 478), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 293), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 197), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 141), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 81), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 53), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 31), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 27), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 11), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 8)]
2023-05-02 08:09:06,760 INFO     LM most common: [('0 1', -1.4500693082809448), ('0 1 0 1', -1.717942714691162), ('0 1 0 1 0 1', -1.988969326019287), ('0 1 0 1 0 1 0 1', -2.2554373741149902), ('0 1 0 1 0 1 0 1 0 1', -2.5210766792297363), ('0 1 0 1 0 1 0 1 0 1 0 1', -2.7866101264953613), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.0521774291992188), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.3178138732910156), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.583535671234131), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.8493492603302), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.115262985229492), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.381284236907959), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.647416591644287), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.913662910461426), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.180031776428223), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.446521282196045), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.713141918182373), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.979890823364258), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.2467756271362305), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.513793468475342), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.780951023101807), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.048248291015625), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.315686225891113), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.583262920379639), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.850985050201416)]
2023-05-02 08:09:06,760 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:09:06,760 INFO     []
2023-05-02 08:09:06,760 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:09:06,760 INFO     []
2023-05-02 08:09:06,760 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:09:06,760 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 08:09:06,760 INFO     
2023-05-02 08:09:06,964 INFO     Language: AAA
2023-05-02 08:09:06,964 INFO     Description: A, AA, or AAA
2023-05-02 08:09:24,827 INFO     DONE TRAINING
2023-05-02 08:09:25,453 INFO     TRAINING SET LOSS: 369.48287212848663
2023-05-02 08:10:00,016 INFO     LM most common: [('0', 566641), ('0 0', 277059), ('0 0 0', 156300)]
2023-05-02 08:10:00,019 INFO     LM most common: [('0', -0.45768219232559204), ('0 0', -1.2759029865264893), ('0 0 0', -2.4295923709869385)]
2023-05-02 08:10:00,019 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:10:00,019 INFO     []
2023-05-02 08:10:00,019 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:10:00,019 INFO     []
2023-05-02 08:10:00,019 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:10:00,019 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:10:00,019 INFO     
2023-05-02 08:10:00,229 INFO     Language: AAAA
2023-05-02 08:10:00,230 INFO     Description: A, AA, AAA, or AAAA
2023-05-02 08:10:18,970 INFO     DONE TRAINING
2023-05-02 08:10:19,618 INFO     TRAINING SET LOSS: 412.62483528256416
2023-05-02 08:10:56,713 INFO     LM most common: [('0', 567758), ('0 0', 257614), ('0 0 0', 123403), ('0 0 0 0', 51225)]
2023-05-02 08:10:56,717 INFO     LM most common: [('0', -0.4554976224899292), ('0 0', -1.3847359418869019), ('0 0 0', -2.318924903869629), ('0 0 0 0', -4.068764686584473)]
2023-05-02 08:10:56,717 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:10:56,717 INFO     []
2023-05-02 08:10:56,717 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:10:56,717 INFO     []
2023-05-02 08:10:56,717 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:10:56,717 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:10:56,717 INFO     
2023-05-02 08:10:57,090 INFO     Language: AnBm
2023-05-02 08:10:57,091 INFO     Description: A^n B^m (n and m can be equal)
2023-05-02 08:11:25,647 INFO     DONE TRAINING
2023-05-02 08:11:26,546 INFO     TRAINING SET LOSS: 549.5043660104275
2023-05-02 08:14:29,275 INFO     LM most common: [('0 1', 116109), ('0 0 1', 77528), ('0 1 1', 76211), ('0 0 1 1', 50678), ('0 0 0 1', 50251), ('0 1 1 1', 49997), ('0 0 1 1 1', 33423), ('0 0 0 0 1', 33341), ('0 1 1 1 1', 33073), ('0 0 0 1 1', 32861), ('0 0 0 0 0 1', 22119), ('0 0 1 1 1 1', 21916), ('0 1 1 1 1 1', 21908), ('0 0 0 0 1 1', 21649), ('0 0 0 1 1 1', 21588), ('0 0 0 0 0 0 1', 14768), ('0 0 0 0 0 1 1', 14632), ('0 0 1 1 1 1 1', 14489), ('0 1 1 1 1 1 1', 14385), ('0 0 0 0 1 1 1', 14319), ('0 0 0 1 1 1 1', 14106), ('0 0 0 0 0 0 0 1', 9849), ('0 0 0 0 0 0 1 1', 9789), ('0 0 1 1 1 1 1 1', 9702), ('0 0 0 0 0 1 1 1', 9656)]
2023-05-02 08:14:29,780 INFO     LM most common: [('0 1', -3.108963966369629), ('0 0 1', -3.3096585273742676), ('0 1 1', -3.358363628387451), ('0 0 1 1', -3.571554183959961), ('0 0 0 1', -3.59258770942688), ('0 1 1 1', -3.6008787155151367), ('0 0 1 1 1', -3.8186559677124023), ('0 0 0 0 1', -3.8209426403045654), ('0 1 1 1 1', -3.8318676948547363), ('0 0 0 1 1', -3.848721504211426), ('0 0 0 0 0 1', -4.045395851135254), ('0 0 1 1 1 1', -4.0517354011535645), ('0 1 1 1 1 1', -4.064219951629639), ('0 0 0 0 1 1', -4.073337078094482), ('0 0 0 1 1 1', -4.096706390380859), ('0 0 0 0 0 0 1', -4.270512580871582), ('0 0 1 1 1 1 1', -4.285797119140625), ('0 0 0 0 0 1 1', -4.296337127685547), ('0 1 1 1 1 1 1', -4.29837703704834), ('0 0 0 0 1 1 1', -4.3213372230529785), ('0 0 0 1 1 1 1', -4.330198287963867), ('0 0 0 0 0 0 0 1', -4.49702262878418), ('0 0 0 0 0 0 1 1', -4.520555019378662), ('0 0 1 1 1 1 1 1', -4.52153205871582), ('0 1 1 1 1 1 1 1', -4.534402847290039)]
2023-05-02 08:14:29,780 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:14:29,780 INFO     []
2023-05-02 08:14:29,780 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:14:29,780 INFO     []
2023-05-02 08:14:29,781 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:14:29,781 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:14:29,781 INFO     
2023-05-02 08:14:30,120 INFO     Language: GoldenMean
2023-05-02 08:14:30,121 INFO     Description: Strings over {A, B} where no 2 A's ever appear in a row
2023-05-02 08:14:54,191 INFO     DONE TRAINING
2023-05-02 08:14:54,950 INFO     TRAINING SET LOSS: 867.0817382335663
2023-05-02 08:16:53,963 INFO     LM most common: [('0', 194225), ('1', 173614), ('0 1', 111799), ('1 0', 57528), ('1 1', 50849), ('0 1 0', 40235), ('0 1 1', 35959), ('1 0 1', 34635), ('0 1 0 1', 23145), ('1 1 0', 17544), ('1 1 1', 14862), ('0 1 1 0', 13326), ('1 0 1 0', 12812), ('1 0 1 1', 11602), ('0 1 1 1', 11148), ('1 1 0 1', 10008), ('0 1 0 1 0', 8499), ('0 1 0 1 1', 8049), ('0 1 1 0 1', 7775), ('1 0 1 0 1', 7485), ('0 1 0 1 0 1', 5225), ('1 1 1 0', 5061), ('1 1 1 1', 4706), ('1 0 1 1 0', 4404), ('0 1 1 1 0', 4120)]
2023-05-02 08:16:58,111 INFO     LM most common: [('1', -1.7233593463897705), ('0', -1.9516379833221436), ('0 1', -1.9598329067230225), ('1 1', -3.0661392211914062), ('0 1 1', -3.1245973110198975), ('1 0 1', -3.255871295928955), ('1 0', -3.3308167457580566), ('0 1 0 1', -3.3917031288146973), ('0 1 0', -3.398196220397949), ('1 0 1 1', -4.315479755401611), ('0 1 1 1', -4.39514684677124), ('1 1 1', -4.441805839538574), ('0 1 0 1 1', -4.46062707901001), ('0 1 1 0', -4.469472885131836), ('0 1 1 0 1', -4.481819152832031), ('1 0 1 0 1', -4.571569442749023), ('1 1 0 1', -4.587424278259277), ('1 0 1 0', -4.6104865074157715), ('1 1 0', -4.6143317222595215), ('0 1 0 1 0 1', -4.670202255249023), ('0 1 0 1 0', -4.7902445793151855), ('1 0 1 1 1', -5.535616397857666), ('0 1 1 1 1', -5.590620994567871), ('1 0 1 1 0', -5.618138790130615), ('1 0 1 0 1 1', -5.6346540451049805)]
2023-05-02 08:16:58,112 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:16:58,112 INFO     []
2023-05-02 08:16:58,112 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:16:58,112 INFO     []
2023-05-02 08:16:58,112 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:16:58,112 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:16:58,112 INFO     
2023-05-02 08:16:58,471 INFO     Language: Even
2023-05-02 08:16:58,471 INFO     Description: Strings over {A, B} where A's only appear in even-length groups
2023-05-02 08:17:25,704 INFO     DONE TRAINING
2023-05-02 08:17:26,557 INFO     TRAINING SET LOSS: 755.9359067678452
2023-05-02 08:20:28,386 INFO     LM most common: [('1', 218970), ('0 0', 143827), ('1 1', 83621), ('1 0 0', 61300), ('0 0 1', 52866), ('0 0 0 0', 34843), ('1 1 1', 32399), ('1 1 0 0', 22435), ('1 0 0 1', 21563), ('0 0 1 1', 21027), ('1 0 0 0 0', 14330), ('0 0 1 0 0', 13542), ('0 0 0 0 1', 13084), ('1 1 1 1', 12103), ('1 1 1 0 0', 8699), ('0 0 0 0 0 0', 8528), ('0 0 1 1 1', 8307), ('1 1 0 0 1', 8237), ('1 0 0 1 1', 8218), ('1 0 0 1 0 0', 5691), ('1 1 0 0 0 0', 5331), ('1 0 0 0 0 1', 5312), ('0 0 0 0 1 1', 5286), ('0 0 1 1 0 0', 5229), ('0 0 1 0 0 1', 5183)]
2023-05-02 08:20:37,582 INFO     LM most common: [('1', -1.3253591060638428), ('1 1', -2.165955066680908), ('0 0', -2.1728978157043457), ('1 0 0', -2.8100523948669434), ('1 1 1', -2.9962172508239746), ('0 0 1', -3.1134018898010254), ('1 1 0 0', -3.748297929763794), ('1 0 0 1', -3.8201541900634766), ('0 0 1 1', -3.8769350051879883), ('1 1 1 1', -3.8863935470581055), ('0 0 0 0', -3.9154462814331055), ('1 1 1 0 0', -4.54935884475708), ('1 0 0 0 0', -4.630528926849365), ('1 0 0 1 1', -4.637617588043213), ('1 1 0 0 1', -4.678457260131836), ('1 1 1 1 1', -4.697840213775635), ('0 0 1 1 1', -4.706837177276611), ('0 0 1 0 0', -4.768437385559082), ('0 0 0 0 1', -4.804809093475342), ('1 0 0 1 0 0', -5.461858749389648), ('1 1 1 0 0 1', -5.465237617492676), ('1 1 1 1 0 0', -5.483166217803955), ('1 1 0 0 1 1', -5.48540735244751), ('1 1 1 1 1 1', -5.486635208129883), ('1 0 0 1 1 1', -5.505825042724609)]
2023-05-02 08:20:37,582 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:20:37,582 INFO     []
2023-05-02 08:20:37,582 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:20:37,582 INFO     []
2023-05-02 08:20:37,583 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:20:37,583 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:20:37,583 INFO     
2023-05-02 08:20:37,931 INFO     Language: ApBAp
2023-05-02 08:20:37,931 INFO     Description: A+ B A+
2023-05-02 08:21:03,168 INFO     DONE TRAINING
2023-05-02 08:21:03,946 INFO     TRAINING SET LOSS: 458.91986933350563
2023-05-02 08:22:39,874 INFO     LM most common: [('0 1 0', 267467), ('0 1 0 0', 128624), ('0 0 1 0', 127541), ('0 1 0 0 0', 63743), ('0 0 1 0 0', 61693), ('0 0 0 1 0', 60308), ('0 1 0 0 0 0', 31690), ('0 0 1 0 0 0', 30462), ('0 0 0 1 0 0', 29131), ('0 0 0 0 1 0', 29011), ('0 1 0 0 0 0 0', 15969), ('0 0 1 0 0 0 0', 15292), ('0 0 0 1 0 0 0', 14543), ('0 0 0 0 1 0 0', 13927), ('0 0 0 0 0 1 0', 13856), ('0 1 0 0 0 0 0 0', 7824), ('0 0 1 0 0 0 0 0', 7467), ('0 0 0 1 0 0 0 0', 7235), ('0 0 0 0 1 0 0 0', 6879), ('0 0 0 0 0 0 1 0', 6637), ('0 0 0 0 0 1 0 0', 6602), ('0 1 0 0 0 0 0 0 0', 3893), ('0 0 1 0 0 0 0 0 0', 3663), ('0 0 0 1 0 0 0 0 0', 3623), ('0 0 0 0 1 0 0 0 0', 3491)]
2023-05-02 08:22:40,053 INFO     LM most common: [('0 1 0', -1.25580632686615), ('0 1 0 0', -2.016523838043213), ('0 0 1 0', -2.044816255569458), ('0 1 0 0 0', -2.726473569869995), ('0 0 1 0 0', -2.809070348739624), ('0 0 0 1 0', -2.849428176879883), ('0 1 0 0 0 0', -3.4346795082092285), ('0 0 1 0 0 0', -3.5143117904663086), ('0 0 0 1 0 0', -3.610293388366699), ('0 0 0 0 1 0', -3.641965389251709), ('0 1 0 0 0 0 0', -4.145782470703125), ('0 0 1 0 0 0 0', -4.218194961547852), ('0 0 0 1 0 0 0', -4.3141560554504395), ('0 0 0 0 1 0 0', -4.3975629806518555), ('0 0 0 0 0 1 0', -4.425504684448242), ('0 1 0 0 0 0 0 0', -4.859309673309326), ('0 0 1 0 0 0 0 0', -4.925044059753418), ('0 0 0 1 0 0 0 0', -5.016681671142578), ('0 0 0 0 1 0 0 0', -5.100072860717773), ('0 0 0 0 0 1 0 0', -5.175468921661377), ('0 0 0 0 0 0 1 0', -5.204627990722656), ('0 1 0 0 0 0 0 0 0', -5.574376106262207), ('0 0 1 0 0 0 0 0 0', -5.634319305419922), ('0 0 0 1 0 0 0 0 0', -5.722265243530273), ('0 0 0 0 1 0 0 0 0', -5.801222801208496)]
2023-05-02 08:22:40,053 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:22:40,053 INFO     []
2023-05-02 08:22:40,053 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:22:40,053 INFO     []
2023-05-02 08:22:40,053 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:22:40,053 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:22:40,053 INFO     
2023-05-02 08:22:40,608 INFO     Language: ApBApp
2023-05-02 08:22:40,609 INFO     Description: A+ (B A+)+
2023-05-02 08:23:16,053 INFO     DONE TRAINING
2023-05-02 08:23:17,194 INFO     TRAINING SET LOSS: 467.4550406932831
2023-05-02 08:36:42,103 INFO     LM most common: [('0 1 0', 142333), ('0 0 1 0', 68732), ('0 1 0 0', 64570), ('0 1 0 1 0', 64266), ('0 1 0 0 0', 34148), ('0 0 0 1 0', 33052), ('0 1 0 1 0 1 0', 32317), ('0 0 1 0 0', 31250), ('0 0 1 0 1 0', 31239), ('0 1 0 0 1 0 0', 29018), ('0 0 0 0 1 0', 16789), ('0 1 0 0 0 0', 16631), ('0 0 1 0 0 0', 16415), ('0 1 0 1 0 1 0 1 0', 15957), ('0 0 0 1 0 0', 15688), ('0 0 1 0 1 0 1 0', 15324), ('0 1 0 0 0 1 0 0 0', 14750), ('0 0 0 1 0 1 0', 14596), ('0 0 1 0 0 1 0 0', 14076), ('0 1 0 0 1 0 0 1 0 0', 13654), ('0 0 0 0 0 1 0', 8410), ('0 0 0 1 0 0 0', 8013), ('0 0 1 0 0 0 0', 7992), ('0 0 0 0 1 0 0', 7896), ('0 1 0 0 0 0 0', 7651)]
2023-05-02 08:36:44,862 INFO     LM most common: [('0 1 0', -2.1975371837615967), ('0 1 0 0', -2.8171792030334473), ('0 0 1 0', -2.957094192504883), ('0 1 0 1 0', -3.090534210205078), ('0 1 0 0 0', -3.1046926975250244), ('0 0 1 0 0', -3.557058334350586), ('0 1 0 0 0 0', -3.5776498317718506), ('0 0 0 1 0', -3.7340948581695557), ('0 1 0 0 1 0 0', -3.7346487045288086), ('0 1 0 1 0 1 0', -3.7751448154449463), ('0 0 1 0 1 0', -3.8590235710144043), ('0 0 1 0 0 0', -3.8602490425109863), ('0 1 0 0 0 1 0 0 0', -4.085210800170898), ('0 1 0 0 0 0 0', -4.129483699798584), ('0 0 0 1 0 0', -4.301431655883789), ('0 0 1 0 0 0 0', -4.340627670288086), ('0 0 0 0 1 0', -4.409737586975098), ('0 0 1 0 0 1 0 0', -4.474265098571777), ('0 1 0 0 0 0 1 0 0 0 0', -4.496103286743164), ('0 1 0 1 0 1 0 1 0', -4.504090785980225), ('0 1 0 0 1 0 0 1 0 0', -4.515292644500732), ('0 0 1 0 1 0 1 0', -4.561224460601807), ('0 1 0 0 0 0 0 0', -4.586790561676025), ('0 0 0 1 0 0 0', -4.62602424621582), ('0 0 0 1 0 1 0', -4.661350727081299)]
2023-05-02 08:36:44,862 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:36:44,862 INFO     []
2023-05-02 08:36:44,862 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:36:44,862 INFO     []
2023-05-02 08:36:44,862 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:36:44,862 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:36:44,862 INFO     
2023-05-02 08:36:45,256 INFO     Language: AsBAsp
2023-05-02 08:36:45,256 INFO     Description: A* (B A*)+
2023-05-02 08:37:15,187 INFO     DONE TRAINING
2023-05-02 08:37:16,138 INFO     TRAINING SET LOSS: 714.0196431279182
2023-05-02 08:44:46,219 INFO     LM most common: [('1', 128094), ('1 1', 66183), ('1 0', 65871), ('0 1', 62037), ('1 0 0', 32996), ('1 1 1', 32777), ('0 1 1', 32065), ('0 1 0', 31663), ('0 0 1', 29949), ('1 0 1 0', 28872), ('1 1 1 1', 16068), ('0 1 1 1', 15644), ('0 0 1 0', 15466), ('1 0 0 0', 15455), ('0 0 1 1', 15303), ('1 0 0 1 0 0', 15112), ('0 0 0 1', 14966), ('0 1 0 0', 14823), ('1 0 1 0 1 0', 14413), ('0 1 0 1 0', 13918), ('1 0 0 0 0', 9032), ('1 1 1 1 1', 8001), ('0 0 0 1 1', 7878), ('0 0 1 1 1', 7797), ('1 0 1 0 1 0 1 0', 7760)]
2023-05-02 08:44:47,953 INFO     LM most common: [('1', -2.423299789428711), ('1 0', -2.7767269611358643), ('1 1', -3.0469698905944824), ('1 0 0', -3.1644012928009033), ('0 1', -3.1730265617370605), ('0 1 0', -3.5485763549804688), ('1 0 0 0', -3.7218050956726074), ('1 0 1 0', -3.75038743019104), ('1 1 1', -3.7816662788391113), ('1 0 0 0 0', -3.7931675910949707), ('0 1 1', -3.8121986389160156), ('0 0 1', -3.9555749893188477), ('1 0 0 1 0 0', -4.04072904586792), ('0 1 0 0', -4.069544792175293), ('1 0 0 0 0 0', -4.162703990936279), ('0 0 1 0', -4.284912109375), ('1 0 1 0 1 0', -4.418544769287109), ('1 1 1 1', -4.51075553894043), ('0 1 0 1 0', -4.515378475189209), ('0 1 1 1', -4.527416706085205), ('1 0 0 0 0 1 0 0 0 0', -4.5293288230896), ('0 1 0 0 0', -4.550682067871094), ('1 0 0 0 1 0 0 0', -4.555850028991699), ('0 0 1 1', -4.570030212402344), ('0 0 0 1', -4.637874603271484)]
2023-05-02 08:44:47,953 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:44:47,953 INFO     []
2023-05-02 08:44:47,953 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:44:47,953 INFO     []
2023-05-02 08:44:47,954 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:44:47,954 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:44:47,954 INFO     
2023-05-02 08:44:48,327 INFO     Language: CountA2
2023-05-02 08:44:48,327 INFO     Description: Strings over {A, B} where the number of A's is at least 2
2023-05-02 08:45:14,863 INFO     DONE TRAINING
2023-05-02 08:45:15,688 INFO     TRAINING SET LOSS: 862.0886458158493
2023-05-02 08:47:37,671 INFO     LM most common: [('0 0', 154663), ('0 1 0', 52843), ('1 0 0', 52197), ('0 0 0', 51688), ('0 0 1', 49053), ('1 0 1 0', 17993), ('0 1 0 0', 17720), ('0 1 1 0', 17554), ('1 1 0 0', 17529), ('0 0 0 0', 17342), ('0 0 1 0', 16813), ('1 0 0 1', 16650), ('1 0 0 0', 16445), ('0 1 0 1', 16366), ('0 0 0 1', 15760), ('0 0 1 1', 14819), ('1 0 1 0 0', 6109), ('0 1 1 1 0', 5960), ('1 1 0 1 0', 5897), ('0 1 1 0 0', 5817), ('1 0 0 1 0', 5745), ('0 0 0 0 0', 5717), ('1 0 1 1 0', 5694), ('0 1 0 1 0', 5672), ('1 0 1 0 1', 5661)]
2023-05-02 08:47:58,678 INFO     LM most common: [('0 0', -1.4486366510391235), ('0 0 0', -2.558745861053467), ('0 0 1', -2.6548962593078613), ('0 1 0', -3.0099916458129883), ('1 0 0', -3.03271484375), ('0 0 0 0', -3.642481803894043), ('0 0 1 0', -3.700355052947998), ('0 0 0 1', -3.8081936836242676), ('0 0 1 1', -3.947831153869629), ('0 1 0 0', -4.112745761871338), ('0 1 0 1', -4.238925457000732), ('1 0 0 1', -4.24063777923584), ('1 0 0 0', -4.24166202545166), ('1 0 1 0', -4.613516330718994), ('0 1 1 0', -4.617563247680664), ('1 1 0 0', -4.645224571228027), ('0 0 0 0 0', -4.764797210693359), ('0 0 1 0 0', -4.821419715881348), ('0 0 1 0 1', -4.882274627685547), ('0 0 0 0 1', -4.882347106933594), ('0 0 0 1 0', -4.892204761505127), ('0 0 1 1 0', -4.900583744049072), ('0 0 0 1 1', -5.0870041847229), ('0 0 1 1 1', -5.102065563201904), ('1 0 0 1 0', -5.28887939453125)]
2023-05-02 08:47:58,678 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:47:58,678 INFO     []
2023-05-02 08:47:58,678 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:47:58,678 INFO     []
2023-05-02 08:47:58,679 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:47:58,679 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:47:58,679 INFO     
2023-05-02 08:47:58,989 INFO     Language: CountAEven
2023-05-02 08:47:58,990 INFO     Description: Strings over {A, B} where the number of A's is even
2023-05-02 08:48:23,160 INFO     DONE TRAINING
2023-05-02 08:48:23,916 INFO     TRAINING SET LOSS: 816.403739631176
2023-05-02 08:50:10,996 INFO     LM most common: [('1', 355106), ('0 0', 114638), ('1 1', 108053), ('0 0 1', 40204), ('0 1 0', 36308), ('1 0 0', 35740), ('1 1 1', 34927), ('0 0 0 0', 13352), ('1 0 0 1', 12719), ('0 0 1 1', 12709), ('0 1 0 1', 12183), ('1 1 0 0', 11973), ('0 1 1 0', 11217), ('1 1 1 1', 10989), ('1 0 1 0', 10460), ('0 0 1 0 0', 4685), ('1 0 0 0 0', 4207), ('1 1 0 0 1', 4185), ('1 0 0 1 1', 4133), ('0 0 1 1 1', 4064), ('0 1 0 1 1', 4015), ('0 1 1 0 1', 3985), ('1 1 1 0 0', 3880), ('0 0 0 0 1', 3839), ('0 1 0 0 0', 3831)]
2023-05-02 08:50:18,566 INFO     LM most common: [('1', -0.5765250325202942), ('1 1', -2.0364363193511963), ('0 0', -2.254523992538452), ('1 1 1', -3.4061925411224365), ('0 0 1', -3.421914577484131), ('1 0 0', -3.662045478820801), ('0 1 0', -3.9783802032470703), ('1 0 0 1', -4.743692874908447), ('1 1 1 1', -4.804076194763184), ('0 0 1 1', -4.814767837524414), ('1 1 0 0', -5.014877796173096), ('0 0 0 0', -5.105471134185791), ('0 1 0 1', -5.196508407592773), ('1 0 1 0', -5.540719985961914), ('0 1 1 0', -5.675796985626221), ('1 0 0 1 1', -6.029764175415039), ('1 1 0 0 1', -6.170569896697998), ('1 1 1 1 1', -6.199400901794434), ('0 0 1 1 1', -6.221589088439941), ('0 0 1 0 0', -6.310125350952148), ('1 0 0 0 0', -6.405187606811523), ('1 1 1 0 0', -6.422677993774414), ('0 1 0 1 1', -6.500946998596191), ('0 0 0 0 1', -6.6682586669921875), ('1 0 1 0 1', -6.805765151977539)]
2023-05-02 08:50:18,566 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:50:18,566 INFO     []
2023-05-02 08:50:18,566 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:50:18,566 INFO     []
2023-05-02 08:50:18,567 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:50:18,567 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:50:18,567 INFO     
2023-05-02 08:50:18,901 INFO     Language: aABb
2023-05-02 08:50:18,901 INFO     Description: a Sigma+ b
2023-05-02 08:50:45,239 INFO     DONE TRAINING
2023-05-02 08:50:46,055 INFO     TRAINING SET LOSS: 659.370285242796
2023-05-02 08:53:11,836 INFO     LM most common: [('0 0 1', 175686), ('0 1 1', 161308), ('0 0 1 1', 57836), ('0 0 0 1', 56513), ('0 1 1 1', 54240), ('0 1 0 1', 52727), ('0 0 1 1 1', 19772), ('0 0 0 1 1', 19287), ('0 0 0 0 1', 18933), ('0 1 0 0 1', 18270), ('0 1 1 1 1', 18212), ('0 0 1 0 1', 17936), ('0 1 0 1 1', 17526), ('0 1 1 0 1', 16992), ('0 0 1 1 1 1', 6616), ('0 0 0 1 1 1', 6555), ('0 0 0 0 1 1', 6398), ('0 0 1 0 0 1', 6262), ('0 0 1 1 0 1', 6221), ('0 1 1 1 1 1', 6213), ('0 0 0 0 0 1', 6199), ('0 1 0 1 1 1', 6110), ('0 1 0 0 1 1', 6062), ('0 1 0 0 0 1', 5973), ('0 0 0 1 0 1', 5961)]
2023-05-02 08:53:24,845 INFO     LM most common: [('0 0 1', -1.2711880207061768), ('0 1 1', -1.4301152229309082), ('0 0 1 1', -2.5521597862243652), ('0 1 1 1', -2.6621687412261963), ('0 0 0 1', -2.9415745735168457), ('0 1 0 1', -3.071965217590332), ('0 0 1 1 1', -3.7694945335388184), ('0 1 1 1 1', -3.8895459175109863), ('0 0 0 1 1', -4.177437782287598), ('0 0 1 0 1', -4.279670238494873), ('0 1 0 1 1', -4.315164089202881), ('0 1 1 0 1', -4.368154525756836), ('0 0 0 0 1', -4.546448707580566), ('0 1 0 0 1', -4.619737148284912), ('0 0 1 1 1 1', -5.017787456512451), ('0 1 1 1 1 1', -5.148207664489746), ('0 0 0 1 1 1', -5.367656230926514), ('0 0 1 1 0 1', -5.44609260559082), ('0 1 0 1 1 1', -5.476895332336426), ('0 0 1 0 1 1', -5.503429412841797), ('0 1 1 1 0 1', -5.574358940124512), ('0 1 1 0 1 1', -5.606101989746094), ('0 0 1 0 0 1', -5.768487930297852), ('0 0 0 0 1 1', -5.776015281677246), ('0 1 0 0 1 1', -5.840108394622803)]
2023-05-02 08:53:24,845 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:53:24,845 INFO     []
2023-05-02 08:53:24,845 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:53:24,845 INFO     []
2023-05-02 08:53:24,846 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:53:24,846 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:53:24,846 INFO     
2023-05-02 08:53:25,241 INFO     Language: AnBn
2023-05-02 08:53:25,241 INFO     Description: A^n B^n
2023-05-02 08:53:56,978 INFO     DONE TRAINING
2023-05-02 08:53:57,987 INFO     TRAINING SET LOSS: 275.44054672122
2023-05-02 08:59:37,871 INFO     LM most common: [('0 1', 355690), ('0 0 1 1', 234809), ('0 0 0 1 1 1', 143485), ('0 0 0 0 1 1 1 1', 93072), ('0 0 0 0 0 1 1 1 1 1', 60525), ('0 0 0 0 0 0 1 1 1 1 1 1', 39262), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', 25667), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', 16559), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', 10978), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', 6970), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', 4543), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', 2973), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1', 1908), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 1261), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 826), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 484), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 353), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 236), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 139), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 89), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 63), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 41), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 17), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 15), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 14)]
2023-05-02 08:59:37,917 INFO     LM most common: [('0 1', -1.457149863243103), ('0 0 1 1', -1.659571647644043), ('0 0 0 1 1 1', -2.0332932472229004), ('0 0 0 0 1 1 1 1', -2.3049275875091553), ('0 0 0 0 0 1 1 1 1 1', -2.557661533355713), ('0 0 0 0 0 0 1 1 1 1 1 1', -2.809093713760376), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', -3.0611674785614014), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', -3.313932418823242), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', -3.5673255920410156), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', -3.8212623596191406), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', -4.075697898864746), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', -4.330587863922119), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.585910320281982), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.841643333435059), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.097764492034912), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.3542680740356445), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.611128807067871), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.868345260620117), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.125917434692383), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.383821487426758), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.6420578956604), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.900627613067627), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.159512519836426), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.418715953826904), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.678231239318848)]
2023-05-02 08:59:37,917 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 08:59:37,917 INFO     []
2023-05-02 08:59:37,917 INFO     Grammatical sequences that the model is missing:
2023-05-02 08:59:37,917 INFO     []
2023-05-02 08:59:37,917 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 08:59:37,917 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 08:59:37,917 INFO     
2023-05-02 08:59:38,320 INFO     Language: Dyck
2023-05-02 08:59:38,321 INFO     Description: Balanced sequences of parentheses
2023-05-02 09:00:09,827 INFO     DONE TRAINING
2023-05-02 09:00:10,824 INFO     TRAINING SET LOSS: 466.34410524368286
2023-05-02 09:05:40,207 INFO     LM most common: [('0 1', 341831), ('0 0 1 1', 126237), ('0 1 0 1', 109784), ('0 0 0 1 1 1', 39601), ('0 1 0 0 1 1', 38833), ('0 0 1 0 1 1', 36994), ('0 1 0 1 0 1', 36287), ('0 1 0 1 0 0 1 1', 13132), ('0 0 0 0 1 1 1 1', 12905), ('0 1 0 0 0 1 1 1', 12393), ('0 1 0 0 1 0 1 1', 12176), ('0 1 0 1 0 1 0 1', 11954), ('0 0 0 1 0 1 1 1', 11908), ('0 0 1 0 0 1 1 1', 11470), ('0 0 1 0 1 0 1 1', 10854), ('0 1 0 1 0 1 0 0 1 1', 4334), ('0 0 0 0 0 1 1 1 1 1', 4203), ('0 1 0 1 0 0 0 1 1 1', 4187), ('0 1 0 0 0 0 1 1 1 1', 4051), ('0 1 0 1 0 0 1 0 1 1', 4037), ('0 1 0 1 0 1 0 1 0 1', 4021), ('0 1 0 0 0 1 0 1 1 1', 3899), ('0 0 0 0 1 0 1 1 1 1', 3825), ('0 0 1 0 0 0 1 1 1 1', 3824), ('0 1 0 0 1 0 0 1 1 1', 3814)]
2023-05-02 09:05:50,134 INFO     LM most common: [('0 1', -0.8697390556335449), ('0 1 0 1', -1.866544246673584), ('0 0 1 1', -2.2944693565368652), ('0 1 0 1 0 1', -2.7957231998443604), ('0 1 0 0 1 1', -3.3444228172302246), ('0 0 1 0 1 1', -3.4777169227600098), ('0 1 0 1 0 1 0 1', -3.720454692840576), ('0 0 0 1 1 1', -4.0296311378479), ('0 1 0 1 0 0 1 1', -4.26438570022583), ('0 1 0 0 1 0 1 1', -4.445779800415039), ('0 0 1 0 1 0 1 1', -4.651973724365234), ('0 1 0 1 0 1 0 1 0 1', -4.659255504608154), ('0 1 0 0 0 1 1 1', -5.058481693267822), ('0 0 0 1 0 1 1 1', -5.1493330001831055), ('0 1 0 1 0 1 0 0 1 1', -5.198437213897705), ('0 0 1 0 0 1 1 1', -5.208810806274414), ('0 1 0 1 0 0 1 0 1 1', -5.354045391082764), ('0 1 0 0 1 0 1 0 1 1', -5.565195083618164), ('0 1 0 1 0 1 0 1 0 1 0 1', -5.6109161376953125), ('0 0 0 0 1 1 1 1', -5.681220054626465), ('0 0 1 0 1 0 1 0 1 1', -5.791265964508057), ('0 1 0 1 0 0 0 1 1 1', -5.980921268463135), ('0 1 0 0 0 1 0 1 1 1', -6.047346115112305), ('0 1 0 1 0 1 0 1 0 0 1 1', -6.142491340637207), ('0 1 0 0 1 0 0 1 1 1', -6.150484085083008)]
2023-05-02 09:05:50,134 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:05:50,135 INFO     []
2023-05-02 09:05:50,135 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:05:50,135 INFO     []
2023-05-02 09:05:50,135 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:05:50,135 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:05:50,135 INFO     
2023-05-02 09:05:50,575 INFO     Language: AnB2n
2023-05-02 09:05:50,575 INFO     Description: A^n B^(2n)
2023-05-02 09:06:29,763 INFO     DONE TRAINING
2023-05-02 09:06:31,032 INFO     TRAINING SET LOSS: 193.69097773730755
2023-05-02 09:16:02,698 INFO     LM most common: [('0 1 1', 374737), ('0 0 1 1 1 1', 233139), ('0 0 0 1 1 1 1 1 1', 149914), ('0 0 0 0 1 1 1 1 1 1 1 1', 90469), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', 56099), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', 35015), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 22348), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 14204), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 9086), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 5736), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 3586), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 2238), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 1404), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 812), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 504), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 277), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 158), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 112), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 56), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 47), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 33), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 8), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 5), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 3), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 3)]
2023-05-02 09:16:02,753 INFO     LM most common: [('0 1 1', -1.3317408561706543), ('0 0 1 1 1 1', -1.6547874212265015), ('0 0 0 1 1 1 1 1 1', -1.8948733806610107), ('0 0 0 0 1 1 1 1 1 1 1 1', -2.2623820304870605), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', -2.5995774269104004), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', -2.9129652976989746), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.196052312850952), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.467832565307617), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -3.7410006523132324), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.020026206970215), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.307063102722168), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.603982925415039), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.912604808807373), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.234762191772461), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.57211446762085), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.926194190979004), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.298216819763184), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.688858509063721), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.098211288452148), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.525691032409668), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.970011234283447), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -8.429723739624023), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -8.903078079223633), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -9.388351440429688), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -9.883913040161133)]
2023-05-02 09:16:02,753 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:16:02,753 INFO     []
2023-05-02 09:16:02,753 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:16:02,753 INFO     []
2023-05-02 09:16:02,753 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:16:02,753 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 09:16:02,753 INFO     
2023-05-02 09:16:03,153 INFO     Language: AnCBn
2023-05-02 09:16:03,154 INFO     Description: A^n C B^n
2023-05-02 09:16:35,636 INFO     DONE TRAINING
2023-05-02 09:16:36,675 INFO     TRAINING SET LOSS: 239.78280083835125
2023-05-02 09:22:42,233 INFO     LM most common: [('0 2 1', 341598), ('0 0 2 1 1', 229298), ('0 0 0 2 1 1 1', 150035), ('0 0 0 0 2 1 1 1 1', 97473), ('0 0 0 0 0 2 1 1 1 1 1', 63693), ('0 0 0 0 0 0 2 1 1 1 1 1 1', 41044), ('0 0 0 0 0 0 0 2 1 1 1 1 1 1 1', 26708), ('0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1', 17307), ('0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1', 11375), ('0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1', 7405), ('0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1', 4869), ('0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1', 3188), ('0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1', 2138), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 1282), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 866), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 595), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 414), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 249), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 153), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 119), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 57), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 48), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 29), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 20), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 11)]
2023-05-02 09:22:42,283 INFO     LM most common: [('0 2 1', -1.5497655868530273), ('0 0 2 1 1', -1.7427129745483398), ('0 0 0 2 1 1 1', -1.9876682758331299), ('0 0 0 0 2 1 1 1 1', -2.2418055534362793), ('0 0 0 0 0 2 1 1 1 1 1', -2.495171070098877), ('0 0 0 0 0 0 2 1 1 1 1 1 1', -2.7480478286743164), ('0 0 0 0 0 0 0 2 1 1 1 1 1 1 1', -3.0009117126464844), ('0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1', -3.253809690475464), ('0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1', -3.5067014694213867), ('0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1', -3.759544610977173), ('0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1', -4.012303829193115), ('0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1', -4.2649641036987305), ('0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.517499923706055), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -4.769904613494873), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.022161483764648), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.2742719650268555), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.52621603012085), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -5.777994155883789), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.029600143432617), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.281024932861328), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.532262802124023), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.7833123207092285), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.034160614013672), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.284807205200195), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -7.535255432128906)]
2023-05-02 09:22:42,283 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:22:42,283 INFO     []
2023-05-02 09:22:42,283 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:22:42,283 INFO     []
2023-05-02 09:22:42,283 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:22:42,283 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 09:22:42,283 INFO     
2023-05-02 09:22:42,793 INFO     Language: AnABn
2023-05-02 09:22:42,793 INFO     Description: A^n (AB)^n
2023-05-02 09:23:22,363 INFO     DONE TRAINING
2023-05-02 09:23:23,644 INFO     TRAINING SET LOSS: 193.70980289578438
2023-05-02 09:35:41,695 INFO     LM most common: [('0 0 1', 354321), ('0 0 0 1 0 1', 228017), ('0 0 0 0 1 0 1 0 1', 147454), ('0 0 0 0 0 1 0 1 0 1 0 1', 95168), ('0 0 0 0 0 0 1 0 1 0 1 0 1 0 1', 61536), ('0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1', 39601), ('0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 25658), ('0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 16836), ('0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 10850), ('0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 7155), ('0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 4524), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 3006), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1967), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1324), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 854), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 584), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 374), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 287), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 167), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 107), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 56), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 48), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 35), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 20), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 18)]
2023-05-02 09:35:41,758 INFO     LM most common: [('0 0 1', -1.4647932052612305), ('0 0 0 1 0 1', -1.737041711807251), ('0 0 0 0 1 0 1 0 1', -1.993994951248169), ('0 0 0 0 0 1 0 1 0 1 0 1', -2.2635159492492676), ('0 0 0 0 0 0 1 0 1 0 1 0 1 0 1', -2.5320465564727783), ('0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1', -2.7974700927734375), ('0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.0599679946899414), ('0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.3196001052856445), ('0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.576345920562744), ('0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.8302693367004395), ('0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.08140754699707), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.329809188842773), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.575526237487793), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.818624496459961), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.0591278076171875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.297110080718994), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.5326128005981445), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.765707969665527), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.996424198150635), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.2248077392578125), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.450920581817627), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.674809455871582), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.89650821685791), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.116070747375488), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -7.333542823791504)]
2023-05-02 09:35:41,758 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 09:35:41,758 INFO     []
2023-05-02 09:35:41,758 INFO     Grammatical sequences that the model is missing:
2023-05-02 09:35:41,758 INFO     []
2023-05-02 09:35:41,758 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 09:35:41,758 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 09:35:41,758 INFO     
2023-05-02 09:35:42,340 INFO     Language: ABnABAn
2023-05-02 09:35:42,340 INFO     Description: (AB)^n (ABA)^n
2023-05-02 09:36:36,292 INFO     DONE TRAINING
2023-05-02 09:36:38,037 INFO     TRAINING SET LOSS: 121.35896158963442
2023-05-02 10:07:03,236 INFO     LM most common: [('0 1 0 1 0', 345391), ('0 1 0 1 0 1 0 0 1 0', 223602), ('0 1 0 1 0 1 0 1 0 0 1 0 0 1 0', 146132), ('0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0', 97145), ('0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 64624), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 42651), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 27755), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 18269), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 11946), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 7720), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 5066), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 3356), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 2151), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 1455), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 936), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 605), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 417), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 267), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 165), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 121), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 73), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', 54), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1', 27), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', 21), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', 16)]
2023-05-02 10:07:03,308 INFO     LM most common: [('0 1 0 1 0', -1.5175390243530273), ('0 1 0 1 0 1 0 0 1 0', -1.799084186553955), ('0 1 0 1 0 1 0 1 0 0 1 0 0 1 0', -2.0431876182556152), ('0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0', -2.2684712409973145), ('0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -2.4976084232330322), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -2.7344608306884766), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -2.9761617183685303), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.2203192710876465), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.4655473232269287), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.711118459701538), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -3.956645965576172), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.201937675476074), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.446899890899658), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.691475868225098), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -4.935642242431641), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.179392337799072), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.42272424697876), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.665647029876709), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -5.9081645011901855), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -6.15029764175415), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -6.392050266265869), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -47.46549987792969), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', -48.54701614379883), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', -51.163543701171875), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', -60.063880920410156)]
2023-05-02 10:07:03,308 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:07:03,308 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0']
2023-05-02 10:07:03,308 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:07:03,308 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0']
2023-05-02 10:07:03,308 INFO     LM precision, recall, fscore: 0.84 0.84 0.8399999999999999
2023-05-02 10:07:03,308 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 10:07:03,308 INFO     
2023-05-02 10:07:03,737 INFO     Language: AnBmCn
2023-05-02 10:07:03,737 INFO     Description: A^n B^m C^n
2023-05-02 10:07:38,911 INFO     DONE TRAINING
2023-05-02 10:07:40,043 INFO     TRAINING SET LOSS: 385.0158860385418
2023-05-02 10:14:21,987 INFO     LM most common: [('0 1 2', 121413), ('0 0 1 2 2', 78598), ('0 1 1 2', 78144), ('0 0 0 1 2 2 2', 51601), ('0 0 1 1 2 2', 51178), ('0 1 1 1 2', 50740), ('0 1 1 1 1 2', 33639), ('0 0 0 1 1 2 2 2', 33606), ('0 0 1 1 1 2 2', 33289), ('0 0 0 0 1 2 2 2 2', 33127), ('0 0 0 1 1 1 2 2 2', 22326), ('0 1 1 1 1 1 2', 22038), ('0 0 1 1 1 1 2 2', 21736), ('0 0 0 0 1 1 2 2 2 2', 21650), ('0 0 0 0 0 1 2 2 2 2 2', 21323), ('0 0 0 0 1 1 1 2 2 2 2', 14570), ('0 1 1 1 1 1 1 2', 14530), ('0 0 1 1 1 1 1 2 2', 14490), ('0 0 0 1 1 1 1 2 2 2', 14466), ('0 0 0 0 0 1 1 2 2 2 2 2', 14141), ('0 0 0 0 0 0 1 2 2 2 2 2 2', 13687), ('0 0 0 0 1 1 1 1 2 2 2 2', 9714), ('0 0 0 1 1 1 1 1 2 2 2', 9601), ('0 0 1 1 1 1 1 1 2 2', 9552), ('0 1 1 1 1 1 1 1 2', 9534)]
2023-05-02 10:14:22,584 INFO     LM most common: [('0 1 2', -3.0003695487976074), ('0 0 1 2 2', -3.267331600189209), ('0 1 1 2', -3.286297082901001), ('0 0 0 1 2 2 2', -3.507068157196045), ('0 0 1 1 2 2', -3.5458550453186035), ('0 1 1 1 2', -3.547516345977783), ('0 0 0 1 1 2 2 2', -3.7599222660064697), ('0 0 0 0 1 2 2 2 2', -3.77595853805542), ('0 0 1 1 1 2 2', -3.7904014587402344), ('0 1 1 1 1 2', -3.792896032333374), ('0 0 0 1 1 1 2 2 2', -3.996387004852295), ('0 0 0 0 1 1 2 2 2 2', -4.016365051269531), ('0 1 1 1 1 1 2', -4.033139228820801), ('0 0 1 1 1 1 2 2', -4.033624649047852), ('0 0 0 0 0 1 2 2 2 2 2', -4.043786525726318), ('0 0 0 1 1 1 1 2 2 2', -4.236651420593262), ('0 0 0 0 1 1 1 2 2 2 2', -4.25150203704834), ('0 1 1 1 1 1 1 2', -4.271109104156494), ('0 0 1 1 1 1 1 2 2', -4.276093482971191), ('0 0 0 0 0 1 1 2 2 2 2 2', -4.278469085693359), ('0 0 0 0 0 0 1 2 2 2 2 2 2', -4.310286045074463), ('0 0 0 1 1 1 1 1 2 2 2', -4.477307319641113), ('0 0 0 0 1 1 1 1 2 2 2 2', -4.490349769592285), ('0 1 1 1 1 1 1 1 2', -4.507610321044922), ('0 0 0 0 0 1 1 1 2 2 2 2 2', -4.515901565551758)]
2023-05-02 10:14:22,584 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:14:22,584 INFO     []
2023-05-02 10:14:22,584 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:14:22,584 INFO     []
2023-05-02 10:14:22,584 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:14:22,584 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:14:22,584 INFO     
2023-05-02 10:14:23,076 INFO     Language: AnBmA2n
2023-05-02 10:14:23,077 INFO     Description: A^n B^m A^(2n)
2023-05-02 10:15:05,324 INFO     DONE TRAINING
2023-05-02 10:15:06,701 INFO     TRAINING SET LOSS: 303.21694070100784
2023-05-02 10:27:28,932 INFO     LM most common: [('0 1 0 0', 115907), ('0 0 1 0 0 0 0', 80370), ('0 1 1 0 0', 75038), ('0 0 0 1 0 0 0 0 0 0', 54453), ('0 0 1 1 0 0 0 0', 52820), ('0 1 1 1 0 0', 47249), ('0 0 0 1 1 0 0 0 0 0 0', 34799), ('0 0 1 1 1 0 0 0 0', 34140), ('0 0 0 0 1 0 0 0 0 0 0 0 0', 33479), ('0 1 1 1 1 0 0', 31515), ('0 0 1 1 1 1 0 0 0 0', 22944), ('0 0 0 1 1 1 0 0 0 0 0 0', 22882), ('0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0', 22395), ('0 1 1 1 1 1 0 0', 21194), ('0 0 0 0 1 1 0 0 0 0 0 0 0 0', 20950), ('0 0 0 1 1 1 1 0 0 0 0 0 0', 15267), ('0 0 1 1 1 1 1 0 0 0 0', 15201), ('0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0', 14245), ('0 1 1 1 1 1 1 0 0', 14113), ('0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0', 13852), ('0 0 0 0 1 1 1 0 0 0 0 0 0 0 0', 13681), ('0 0 0 1 1 1 1 1 0 0 0 0 0 0', 10301), ('0 0 1 1 1 1 1 1 0 0 0 0', 10130), ('0 1 1 1 1 1 1 1 0 0', 9378), ('0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0', 9307)]
2023-05-02 10:27:29,862 INFO     LM most common: [('0 1 0 0', -3.1249239444732666), ('0 0 1 0 0 0 0', -3.2495033740997314), ('0 1 1 0 0', -3.379146099090576), ('0 0 0 1 0 0 0 0 0 0', -3.3929286003112793), ('0 0 1 1 0 0 0 0', -3.4988317489624023), ('0 0 0 1 1 0 0 0 0 0 0', -3.695310592651367), ('0 1 1 1 0 0', -3.7141315937042236), ('0 0 0 0 1 0 0 0 0 0 0 0 0', -3.7366955280303955), ('0 0 1 1 1 0 0 0 0', -3.79769229888916), ('0 1 1 1 1 0 0', -3.9362449645996094), ('0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0', -3.956803321838379), ('0 0 0 1 1 1 0 0 0 0 0 0', -3.99324369430542), ('0 0 1 1 1 1 0 0 0 0', -4.008312225341797), ('0 0 0 0 1 1 0 0 0 0 0 0 0 0', -4.077069282531738), ('0 1 1 1 1 1 0 0', -4.158758640289307), ('0 0 0 1 1 1 1 0 0 0 0 0 0', -4.193296432495117), ('0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0', -4.200253486633301), ('0 0 1 1 1 1 1 0 0 0 0', -4.221602439880371), ('0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0', -4.312118053436279), ('0 0 0 0 1 1 1 0 0 0 0 0 0 0 0', -4.380804061889648), ('0 1 1 1 1 1 1 0 0', -4.382941246032715), ('0 0 0 1 1 1 1 1 0 0 0 0 0 0', -4.395186901092529), ('0 0 1 1 1 1 1 1 0 0 0 0', -4.435801029205322), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.471622467041016), ('0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0', -4.554172039031982)]
2023-05-02 10:27:29,862 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:27:29,862 INFO     []
2023-05-02 10:27:29,862 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:27:29,862 INFO     []
2023-05-02 10:27:29,862 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:27:29,862 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:27:29,862 INFO     
2023-05-02 10:27:30,363 INFO     Language: AnBnC2n
2023-05-02 10:27:30,364 INFO     Description: A^n B^n C^(2n)
2023-05-02 10:28:16,515 INFO     DONE TRAINING
2023-05-02 10:28:18,016 INFO     TRAINING SET LOSS: 149.97147338092327
2023-05-02 10:45:20,856 INFO     LM most common: [('0 1 2 2', 367326), ('0 0 1 1 2 2 2 2', 238845), ('0 0 0 1 1 1 2 2 2 2 2 2', 145614), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2', 91834), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 57477), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 36636), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 22987), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 14356), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 9183), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 5876), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 3742), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 2329), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1410), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 936), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 586), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 314), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 217), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 124), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 79), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 56), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 28), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 13), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 12), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 7)]
2023-05-02 10:45:20,911 INFO     LM most common: [('0 1 2 2', -1.379875898361206), ('0 0 1 1 2 2 2 2', -1.5959984064102173), ('0 0 0 1 1 1 2 2 2 2 2 2', -1.9643726348876953), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2', -2.260469913482666), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -2.5649449825286865), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -2.866251230239868), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.1600847244262695), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.4475042819976807), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.732293128967285), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.017727851867676), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.305876731872559), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.597955703735352), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.894710540771484), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.196649074554443), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.504086494445801), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.817281723022461), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.136429786682129), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.461695671081543), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.793220520019531), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.131103038787842), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.475433349609375), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.8262858390808105), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.18372917175293), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.54779052734375), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.91853141784668)]
2023-05-02 10:45:20,911 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:45:20,911 INFO     []
2023-05-02 10:45:20,911 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:45:20,911 INFO     []
2023-05-02 10:45:20,911 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:45:20,911 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 10:45:20,911 INFO     
2023-05-02 10:45:21,321 INFO     Language: AnBmCm
2023-05-02 10:45:21,321 INFO     Description: A^n B^m C^m
2023-05-02 10:45:56,799 INFO     DONE TRAINING
2023-05-02 10:45:57,939 INFO     TRAINING SET LOSS: 385.4598258137703
2023-05-02 10:53:42,429 INFO     LM most common: [('0 1 2', 115376), ('0 0 1 2', 77610), ('0 1 1 2 2', 74308), ('0 0 0 1 2', 49406), ('0 1 1 1 2 2 2', 49140), ('0 0 1 1 2 2', 48608), ('0 1 1 1 1 2 2 2 2', 33179), ('0 0 0 0 1 2', 33019), ('0 0 1 1 1 2 2 2', 32146), ('0 0 0 1 1 2 2', 31649), ('0 0 1 1 1 1 2 2 2 2', 22089), ('0 1 1 1 1 1 2 2 2 2 2', 22074), ('0 0 0 0 0 1 2', 21696), ('0 0 0 1 1 1 2 2 2', 20861), ('0 0 0 0 1 1 2 2', 20614), ('0 1 1 1 1 1 1 2 2 2 2 2 2', 14751), ('0 0 0 0 0 0 1 2', 14650), ('0 0 1 1 1 1 1 2 2 2 2 2', 14572), ('0 0 0 1 1 1 1 2 2 2 2', 14335), ('0 0 0 0 1 1 1 2 2 2', 14167), ('0 0 0 0 0 1 1 2 2', 13659), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 9947), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2', 9823), ('0 0 0 0 0 0 0 1 2', 9685), ('0 0 0 0 1 1 1 1 2 2 2 2', 9499)]
2023-05-02 10:53:43,125 INFO     LM most common: [('0 1 2', -3.129556179046631), ('0 0 1 2', -3.325377941131592), ('0 1 1 2 2', -3.4168472290039062), ('0 0 0 1 2', -3.617994785308838), ('0 1 1 1 2 2 2', -3.6598057746887207), ('0 0 1 1 2 2', -3.6755642890930176), ('0 0 0 0 1 2', -3.8623790740966797), ('0 1 1 1 1 2 2 2 2', -3.876779556274414), ('0 0 1 1 1 2 2 2', -3.899911880493164), ('0 0 0 1 1 2 2', -3.9714698791503906), ('0 1 1 1 1 1 2 2 2 2 2', -4.097748756408691), ('0 0 0 0 0 1 2', -4.099240779876709), ('0 0 1 1 1 1 2 2 2 2', -4.111185073852539), ('0 0 0 1 1 1 2 2 2', -4.17534065246582), ('0 0 0 0 1 1 2 2', -4.215794563293457), ('0 1 1 1 1 1 1 2 2 2 2 2 2', -4.318974018096924), ('0 0 0 0 0 0 1 2', -4.329312324523926), ('0 0 1 1 1 1 1 2 2 2 2 2', -4.329679012298584), ('0 0 0 1 1 1 1 2 2 2 2', -4.382420063018799), ('0 0 0 0 1 1 1 2 2 2', -4.414858818054199), ('0 0 0 0 0 1 1 2 2', -4.452264785766602), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -4.538909435272217), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2', -4.548664093017578), ('0 0 0 0 0 0 0 1 2', -4.555478096008301), ('0 0 0 1 1 1 1 1 2 2 2 2 2', -4.600296974182129)]
2023-05-02 10:53:43,125 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 10:53:43,125 INFO     []
2023-05-02 10:53:43,125 INFO     Grammatical sequences that the model is missing:
2023-05-02 10:53:43,125 INFO     []
2023-05-02 10:53:43,125 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:53:43,125 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 10:53:43,125 INFO     
2023-05-02 10:53:43,575 INFO     Language: AnBmCnpm
2023-05-02 10:53:43,575 INFO     Description: A^n B^m C^(n+m)
2023-05-02 10:54:24,495 INFO     DONE TRAINING
2023-05-02 10:54:25,823 INFO     TRAINING SET LOSS: 296.4484151303768
2023-05-02 11:04:36,372 INFO     LM most common: [('0 1 2 2', 120296), ('0 0 1 2 2 2', 80846), ('0 1 1 2 2 2', 75552), ('0 0 0 1 2 2 2 2', 53108), ('0 0 1 1 2 2 2 2', 51573), ('0 1 1 1 2 2 2 2', 47738), ('0 0 0 0 1 2 2 2 2 2', 35875), ('0 0 0 1 1 2 2 2 2 2', 33723), ('0 0 1 1 1 2 2 2 2 2', 32563), ('0 1 1 1 1 2 2 2 2 2', 29985), ('0 0 0 0 0 1 2 2 2 2 2 2', 24894), ('0 0 0 0 1 1 2 2 2 2 2 2', 22638), ('0 0 0 1 1 1 2 2 2 2 2 2', 21350), ('0 0 1 1 1 1 2 2 2 2 2 2', 20441), ('0 1 1 1 1 1 2 2 2 2 2 2', 18660), ('0 0 0 0 0 0 1 2 2 2 2 2 2 2', 17049), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2', 15160), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2', 14417), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2', 13525), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2', 12583), ('0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2', 11935), ('0 1 1 1 1 1 1 2 2 2 2 2 2 2', 11652), ('0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2', 10372), ('0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2', 9866), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2', 9020)]
2023-05-02 11:04:37,110 INFO     LM most common: [('0 1 2 2', -3.0333285331726074), ('0 0 1 2 2 2', -3.252678394317627), ('0 1 1 2 2 2', -3.337770938873291), ('0 0 1 1 2 2 2 2', -3.5047826766967773), ('0 0 0 1 2 2 2 2', -3.5296032428741455), ('0 1 1 1 2 2 2 2', -3.618985176086426), ('0 0 0 0 1 2 2 2 2 2', -3.7377500534057617), ('0 0 1 1 1 2 2 2 2 2', -3.8025383949279785), ('0 0 0 1 1 2 2 2 2 2', -3.8117570877075195), ('0 0 0 0 0 1 2 2 2 2 2 2', -3.926821231842041), ('0 1 1 1 1 2 2 2 2 2', -3.9300551414489746), ('0 0 0 0 1 1 2 2 2 2 2 2', -4.045244216918945), ('0 0 0 1 1 1 2 2 2 2 2 2', -4.103280067443848), ('0 0 0 0 0 0 1 2 2 2 2 2 2 2', -4.109685897827148), ('0 0 1 1 1 1 2 2 2 2 2 2', -4.116541862487793), ('0 1 1 1 1 1 2 2 2 2 2 2', -4.237936496734619), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2', -4.249966144561768), ('0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2', -4.288810729980469), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2', -4.329125881195068), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2', -4.4064531326293945), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2', -4.424953937530518), ('0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2', -4.442527770996094), ('0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 2', -4.46553897857666), ('0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2', -4.533127784729004), ('0 1 1 1 1 1 1 2 2 2 2 2 2 2', -4.540098667144775)]
2023-05-02 11:04:37,110 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 11:04:37,110 INFO     []
2023-05-02 11:04:37,110 INFO     Grammatical sequences that the model is missing:
2023-05-02 11:04:37,110 INFO     []
2023-05-02 11:04:37,110 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:04:37,110 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:04:37,110 INFO     
2023-05-02 11:04:37,863 INFO     Language: AnBmCnm
2023-05-02 11:04:37,863 INFO     Description: A^n B^m C^(n*m)
2023-05-02 11:05:35,679 INFO     DONE TRAINING
2023-05-02 11:05:37,560 INFO     TRAINING SET LOSS: 268.6324245482683
2023-05-02 11:44:13,923 INFO     LM most common: [('0 1 2', 132391), ('0 1 1 2 2', 82731), ('0 0 1 2 2', 80307), ('0 0 0 1 2 2 2', 53813), ('0 1 1 1 2 2 2', 53202), ('0 0 1 1 2 2 2 2', 53026), ('0 1 1 1 1 2 2 2 2', 34228), ('0 0 0 1 1 2 2 2 2 2 2', 34146), ('0 0 1 1 1 2 2 2 2 2 2', 33778), ('0 0 0 0 1 2 2 2 2', 33377), ('0 0 0 1 1 1 2 2 2 2 2 2 2 2 2', 22681), ('0 0 1 1 1 1 2 2 2 2 2 2 2 2', 22532), ('0 1 1 1 1 1 2 2 2 2 2', 22409), ('0 0 0 0 1 1 2 2 2 2 2 2 2 2', 21542), ('0 0 0 0 0 1 2 2 2 2 2', 20704), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 15245), ('0 1 1 1 1 1 1 2 2 2 2 2 2', 14713), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 14256), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 14011), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2', 13240), ('0 0 0 0 0 0 1 2 2 2 2 2 2', 12707), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 9851), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 9475), ('0 0 0 0 0 0 0 1 2 2 2 2 2 2 2', 8094), ('0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 7047)]
2023-05-02 11:44:18,276 INFO     LM most common: [('0 1 2', -2.8027548789978027), ('0 1 1 2 2', -3.1309471130371094), ('0 0 1 2 2', -3.194129705429077), ('0 0 0 1 2 2 2', -3.3468470573425293), ('0 1 1 1 2 2 2', -3.414155960083008), ('0 0 1 1 2 2 2 2', -3.4354705810546875), ('0 0 0 1 1 2 2 2 2 2 2', -3.639397621154785), ('0 0 0 0 1 2 2 2 2', -3.640489101409912), ('0 1 1 1 1 2 2 2 2', -3.687187671661377), ('0 0 1 1 1 2 2 2 2 2 2', -3.70741868019104), ('0 0 0 1 1 1 2 2 2 2 2 2 2 2 2', -3.86779522895813), ('0 0 0 0 1 1 2 2 2 2 2 2 2 2', -3.914433240890503), ('0 1 1 1 1 1 2 2 2 2 2', -3.937626361846924), ('0 0 1 1 1 1 2 2 2 2 2 2 2 2', -3.9459238052368164), ('0 0 0 0 0 1 2 2 2 2 2', -3.957487106323242), ('0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.105353355407715), ('0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.150758266448975), ('0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -4.158245086669922), ('0 1 1 1 1 1 1 2 2 2 2 2 2', -4.166019916534424), ('0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 2 2', -4.229176998138428), ('0 0 0 0 0 0 1 2 2 2 2 2 2', -4.27482271194458), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -4.384358882904053), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.38956356048584), ('0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.483278274536133), ('0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.57321310043335)]
2023-05-02 11:44:18,276 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 11:44:18,276 INFO     []
2023-05-02 11:44:18,276 INFO     Grammatical sequences that the model is missing:
2023-05-02 11:44:18,276 INFO     []
2023-05-02 11:44:18,276 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:44:18,276 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:44:18,276 INFO     
2023-05-02 11:44:18,685 INFO     Language: AnBk
2023-05-02 11:44:18,685 INFO     Description: A^n B^(n+m)
2023-05-02 11:44:53,615 INFO     DONE TRAINING
2023-05-02 11:44:54,738 INFO     TRAINING SET LOSS: 386.19678246974945
2023-05-02 11:51:48,624 INFO     LM most common: [('0 1 1', 118995), ('0 1 1 1', 76102), ('0 0 1 1 1', 75565), ('0 0 0 1 1 1 1', 52208), ('0 0 1 1 1 1', 50825), ('0 1 1 1 1', 49468), ('0 0 0 1 1 1 1 1', 34844), ('0 0 0 0 1 1 1 1 1', 34266), ('0 0 1 1 1 1 1', 33379), ('0 1 1 1 1 1', 32100), ('0 0 0 0 1 1 1 1 1 1', 23095), ('0 0 0 1 1 1 1 1 1', 22683), ('0 0 0 0 0 1 1 1 1 1 1', 22324), ('0 0 1 1 1 1 1 1', 21715), ('0 1 1 1 1 1 1', 21053), ('0 0 0 0 1 1 1 1 1 1 1', 14817), ('0 0 0 1 1 1 1 1 1 1', 14761), ('0 0 0 0 0 0 1 1 1 1 1 1 1', 14638), ('0 0 0 0 0 1 1 1 1 1 1 1', 14620), ('0 0 1 1 1 1 1 1 1', 14218), ('0 1 1 1 1 1 1 1', 13504), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1', 9782), ('0 0 0 0 0 1 1 1 1 1 1 1 1', 9678), ('0 0 0 1 1 1 1 1 1 1 1', 9528), ('0 0 1 1 1 1 1 1 1 1', 9493)]
2023-05-02 11:51:49,227 INFO     LM most common: [('0 1 1', -3.0367064476013184), ('0 1 1 1', -3.3456315994262695), ('0 0 1 1 1', -3.3825292587280273), ('0 0 0 1 1 1 1', -3.5151174068450928), ('0 0 1 1 1 1', -3.5680155754089355), ('0 1 1 1 1', -3.6077280044555664), ('0 0 0 1 1 1 1 1', -3.7290456295013428), ('0 0 0 0 1 1 1 1 1', -3.7566328048706055), ('0 0 1 1 1 1 1', -3.826805591583252), ('0 1 1 1 1 1', -3.8608314990997314), ('0 0 0 0 1 1 1 1 1 1', -3.9698023796081543), ('0 0 0 1 1 1 1 1 1', -3.9889817237854004), ('0 0 0 0 0 1 1 1 1 1 1', -4.004995346069336), ('0 0 1 1 1 1 1 1', -4.0787858963012695), ('0 1 1 1 1 1 1', -4.111814498901367), ('0 0 0 0 0 1 1 1 1 1 1 1', -4.217071056365967), ('0 0 0 0 1 1 1 1 1 1 1', -4.22993278503418), ('0 0 0 1 1 1 1 1 1 1', -4.243136405944824), ('0 0 0 0 0 0 1 1 1 1 1 1 1', -4.255625247955322), ('0 0 1 1 1 1 1 1 1', -4.328689098358154), ('0 1 1 1 1 1 1 1', -4.360831260681152), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1', -4.466039180755615), ('0 0 0 0 0 1 1 1 1 1 1 1 1', -4.476566791534424), ('0 0 0 0 1 1 1 1 1 1 1 1', -4.484976291656494), ('0 0 0 1 1 1 1 1 1 1 1', -4.495707035064697)]
2023-05-02 11:51:49,228 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 11:51:49,228 INFO     []
2023-05-02 11:51:49,228 INFO     Grammatical sequences that the model is missing:
2023-05-02 11:51:49,228 INFO     []
2023-05-02 11:51:49,228 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:51:49,228 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 11:51:49,228 INFO     
2023-05-02 11:51:49,685 INFO     Language: AnBmCmAn
2023-05-02 11:51:49,685 INFO     Description: A^n B^m C^m A^n
2023-05-02 11:52:30,061 INFO     DONE TRAINING
2023-05-02 11:52:31,366 INFO     TRAINING SET LOSS: 297.37518334388733
2023-05-02 12:02:34,995 INFO     LM most common: [('0 1 2 0', 114993), ('0 0 1 2 0 0', 76569), ('0 1 1 2 2 0', 75758), ('0 1 1 1 2 2 2 0', 50715), ('0 0 1 1 2 2 0 0', 49772), ('0 0 0 1 2 0 0 0', 49406), ('0 1 1 1 1 2 2 2 2 0', 33796), ('0 0 1 1 1 2 2 2 0 0', 33724), ('0 0 0 1 1 2 2 0 0 0', 32470), ('0 0 0 0 1 2 0 0 0 0', 32149), ('0 0 1 1 1 1 2 2 2 2 0 0', 22624), ('0 1 1 1 1 1 2 2 2 2 2 0', 22401), ('0 0 0 1 1 1 2 2 2 0 0 0', 22044), ('0 0 0 0 1 1 2 2 0 0 0 0', 21559), ('0 0 0 0 0 1 2 0 0 0 0 0', 20802), ('0 0 1 1 1 1 1 2 2 2 2 2 0 0', 15141), ('0 0 0 1 1 1 1 2 2 2 2 0 0 0', 14817), ('0 1 1 1 1 1 1 2 2 2 2 2 2 0', 14703), ('0 0 0 0 1 1 1 2 2 2 0 0 0 0', 14406), ('0 0 0 0 0 1 1 2 2 0 0 0 0 0', 14296), ('0 0 0 0 0 0 1 2 0 0 0 0 0 0', 13498), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 0 0', 10135), ('0 0 0 1 1 1 1 1 2 2 2 2 2 0 0 0', 10103), ('0 0 0 0 1 1 1 1 2 2 2 2 0 0 0 0', 9822), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0', 9735)]
2023-05-02 12:02:35,766 INFO     LM most common: [('0 1 2 0', -3.1419200897216797), ('0 0 1 2 0 0', -3.3528263568878174), ('0 1 1 2 2 0', -3.378438711166382), ('0 1 1 1 2 2 2 0', -3.5923526287078857), ('0 0 1 1 2 2 0 0', -3.610743522644043), ('0 0 0 1 2 0 0 0', -3.624917507171631), ('0 1 1 1 1 2 2 2 2 0', -3.813284397125244), ('0 0 1 1 1 2 2 2 0 0', -3.8159000873565674), ('0 0 0 1 1 2 2 0 0 0', -3.8749821186065674), ('0 0 0 0 1 2 0 0 0 0', -3.881638288497925), ('0 0 1 1 1 1 2 2 2 2 0 0', -4.025308609008789), ('0 1 1 1 1 1 2 2 2 2 2 0', -4.039705753326416), ('0 0 0 1 1 1 2 2 2 0 0 0', -4.076566219329834), ('0 0 0 0 1 1 2 2 0 0 0 0', -4.1195878982543945), ('0 0 0 0 0 1 2 0 0 0 0 0', -4.132838726043701), ('0 0 1 1 1 1 1 2 2 2 2 2 0 0', -4.2401227951049805), ('0 1 1 1 1 1 1 2 2 2 2 2 2 0', -4.27085542678833), ('0 0 0 1 1 1 1 2 2 2 2 0 0 0', -4.282839298248291), ('0 0 0 0 1 1 1 2 2 2 0 0 0 0', -4.319875717163086), ('0 0 0 0 0 1 1 2 2 0 0 0 0 0', -4.3573431968688965), ('0 0 0 0 0 0 1 2 0 0 0 0 0 0', -4.384736061096191), ('0 0 1 1 1 1 1 1 2 2 2 2 2 2 0 0', -4.458862781524658), ('0 0 0 1 1 1 1 1 2 2 2 2 2 0 0 0', -4.494748592376709), ('0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0', -4.505287170410156), ('0 0 0 0 1 1 1 1 2 2 2 2 0 0 0 0', -4.5251593589782715)]
2023-05-02 12:02:35,766 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:02:35,766 INFO     []
2023-05-02 12:02:35,766 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:02:35,766 INFO     []
2023-05-02 12:02:35,767 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:02:35,767 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:02:35,767 INFO     
2023-05-02 12:02:36,454 INFO     Language: AnB2nC3n
2023-05-02 12:02:36,454 INFO     Description: A^n B^2n C^3n
2023-05-02 12:03:37,195 INFO     DONE TRAINING
2023-05-02 12:03:39,160 INFO     TRAINING SET LOSS: 102.6898478269577
2023-05-02 12:33:54,743 INFO     LM most common: [('0 1 1 2 2 2', 365405), ('0 0 1 1 1 1 2 2 2 2 2 2', 242415), ('0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 146781), ('0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 92747), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 59988), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 37241), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 22440), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 13204), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8118), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 4817), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 2822), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1698), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 994), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 548), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 303), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 201), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 130), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 63), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 37), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 24), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 11), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 7), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 3), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 2), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1)]
2023-05-02 12:33:54,803 INFO     LM most common: [('0 1 1 2 2 2', -1.3931031227111816), ('0 0 1 1 1 1 2 2 2 2 2 2', -1.5734028816223145), ('0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -1.94476318359375), ('0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -2.208137273788452), ('0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -2.4694886207580566), ('0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -2.765799045562744), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.0980000495910645), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.455319404602051), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -3.827017307281494), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.207829475402832), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.595489501953125), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.9887285232543945), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.38684606552124), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.789430618286133), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.196300983428955), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.607250690460205), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.0221405029296875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -59.65156936645508), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -63.754676818847656), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -64.94786834716797), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -66.20046997070312), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -68.8369369506836), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -70.4130630493164), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -71.85130310058594), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -75.70792388916016)]
2023-05-02 12:33:54,803 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:33:54,803 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2023-05-02 12:33:54,803 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:33:54,804 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2']
2023-05-02 12:33:54,804 INFO     LM precision, recall, fscore: 0.68 0.68 0.68
2023-05-02 12:33:54,804 INFO     Memorization precision, recall, fscore: 1.0 0.84 0.9130434782608696
2023-05-02 12:33:54,804 INFO     
2023-05-02 12:33:55,274 INFO     Language: AnBnp1Cnp2
2023-05-02 12:33:55,274 INFO     Description: A^n B^(n+1) C^(n+2)
2023-05-02 12:34:36,911 INFO     DONE TRAINING
2023-05-02 12:34:38,265 INFO     TRAINING SET LOSS: 147.3415537327528
2023-05-02 12:45:51,293 INFO     LM most common: [('0 1 1 2 2 2', 357645), ('0 0 1 1 1 2 2 2 2', 239118), ('0 0 0 1 1 1 1 2 2 2 2 2', 151031), ('0 0 0 0 1 1 1 1 1 2 2 2 2 2 2', 94543), ('0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2', 59403), ('0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', 37216), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 23090), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 14244), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', 8895), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 5598), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', 3423), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 2254), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1305), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 830), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 514), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 355), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 198), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 137), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 67), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 48), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 30), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 25), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 14), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 9), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 4)]
2023-05-02 12:45:51,343 INFO     LM most common: [('0 1 1 2 2 2', -1.4400074481964111), ('0 0 1 1 1 2 2 2 2', -1.6254756450653076), ('0 0 0 1 1 1 1 2 2 2 2 2', -1.8996191024780273), ('0 0 0 0 1 1 1 1 1 2 2 2 2 2 2', -2.1984739303588867), ('0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 2', -2.506793975830078), ('0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', -2.8177876472473145), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -3.129054307937622), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -3.4399890899658203), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', -3.750401735305786), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.060257911682129), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.369546413421631), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.678283214569092), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.986489295959473), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.294189929962158), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.601414680480957), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.90818977355957), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.214531421661377), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.520489692687988), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.826075077056885), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.131333351135254), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.436286449432373), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.74097204208374), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.045421600341797), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.34967041015625), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.653746604919434)]
2023-05-02 12:45:51,343 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:45:51,343 INFO     []
2023-05-02 12:45:51,343 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:45:51,343 INFO     []
2023-05-02 12:45:51,343 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:45:51,343 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 12:45:51,343 INFO     
2023-05-02 12:45:51,641 INFO     Language: AnUBn
2023-05-02 12:45:51,641 INFO     Description: A^n | B^n
2023-05-02 12:46:15,845 INFO     DONE TRAINING
2023-05-02 12:46:16,601 INFO     TRAINING SET LOSS: 657.7056076526642
2023-05-02 12:48:05,228 INFO     LM most common: [('0', 188936), ('1', 178813), ('0 0', 114959), ('1 1', 109633), ('0 0 0', 73548), ('1 1 1', 70724), ('0 0 0 0', 47656), ('1 1 1 1', 45823), ('0 0 0 0 0', 30389), ('1 1 1 1 1', 30108), ('1 1 1 1 1 1', 19564), ('0 0 0 0 0 0', 19476), ('1 1 1 1 1 1 1', 12910), ('0 0 0 0 0 0 0', 12173), ('1 1 1 1 1 1 1 1', 8372), ('0 0 0 0 0 0 0 0', 7856), ('1 1 1 1 1 1 1 1 1', 5386), ('0 0 0 0 0 0 0 0 0', 4870), ('1 1 1 1 1 1 1 1 1 1', 3695), ('0 0 0 0 0 0 0 0 0 0', 3030), ('1 1 1 1 1 1 1 1 1 1 1', 2359), ('0 0 0 0 0 0 0 0 0 0 0', 1945), ('1 1 1 1 1 1 1 1 1 1 1 1', 1557), ('0 0 0 0 0 0 0 0 0 0 0 0', 1220), ('1 1 1 1 1 1 1 1 1 1 1 1 1', 1007)]
2023-05-02 12:48:05,285 INFO     LM most common: [('0', -2.0121426582336426), ('1', -2.1287474632263184), ('0 0', -2.3890199661254883), ('1 1', -2.5024490356445312), ('0 0 0', -2.6439902782440186), ('1 1 1', -2.7720346450805664), ('0 0 0 0', -2.9077532291412354), ('1 1 1 1', -3.0278162956237793), ('0 0 0 0 0', -3.1815619468688965), ('1 1 1 1 1', -3.2804670333862305), ('0 0 0 0 0 0', -3.461132049560547), ('1 1 1 1 1 1', -3.5314671993255615), ('0 0 0 0 0 0 0', -3.744251012802124), ('1 1 1 1 1 1 1', -3.781341314315796), ('1 1 1 1 1 1 1 1', -4.030313491821289), ('0 0 0 0 0 0 0 0', -4.0303635597229), ('1 1 1 1 1 1 1 1 1', -4.278532028198242), ('0 0 0 0 0 0 0 0 0', -4.319217681884766), ('1 1 1 1 1 1 1 1 1 1', -4.526069164276123), ('0 0 0 0 0 0 0 0 0 0', -4.61067008972168), ('1 1 1 1 1 1 1 1 1 1 1', -4.773001670837402), ('0 0 0 0 0 0 0 0 0 0 0', -4.904573440551758), ('1 1 1 1 1 1 1 1 1 1 1 1', -5.019387245178223), ('0 0 0 0 0 0 0 0 0 0 0 0', -5.200798988342285), ('1 1 1 1 1 1 1 1 1 1 1 1 1', -5.26529598236084)]
2023-05-02 12:48:05,286 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:48:05,286 INFO     []
2023-05-02 12:48:05,286 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:48:05,286 INFO     []
2023-05-02 12:48:05,286 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:48:05,286 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:48:05,286 INFO     
2023-05-02 12:48:05,680 INFO     Language: AnUAnBn
2023-05-02 12:48:05,680 INFO     Description: A^n | (A^n B^n)
2023-05-02 12:48:34,604 INFO     DONE TRAINING
2023-05-02 12:48:35,503 INFO     TRAINING SET LOSS: 486.8931775689125
2023-05-02 12:53:04,935 INFO     LM most common: [('0', 179238), ('0 1', 174048), ('0 0', 115572), ('0 0 1 1', 111563), ('0 0 0', 76087), ('0 0 0 1 1 1', 71456), ('0 0 0 0', 50338), ('0 0 0 0 1 1 1 1', 46710), ('0 0 0 0 0', 32755), ('0 0 0 0 0 1 1 1 1 1', 30462), ('0 0 0 0 0 0', 21070), ('0 0 0 0 0 0 1 1 1 1 1 1', 19430), ('0 0 0 0 0 0 0', 13539), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', 12199), ('0 0 0 0 0 0 0 0', 8535), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', 7940), ('0 0 0 0 0 0 0 0 0', 5459), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', 5197), ('0 0 0 0 0 0 0 0 0 0', 3528), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', 3246), ('0 0 0 0 0 0 0 0 0 0 0', 2229), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', 2051), ('0 0 0 0 0 0 0 0 0 0 0 0', 1416), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', 1220), ('0 0 0 0 0 0 0 0 0 0 0 0 0', 912)]
2023-05-02 12:53:04,998 INFO     LM most common: [('0', -2.700847864151001), ('0 1', -2.7637875080108643), ('0 0', -2.8582630157470703), ('0 0 1 1', -2.920681953430176), ('0 0 0', -2.9544966220855713), ('0 0 0 0', -3.045062780380249), ('0 0 0 1 1 1', -3.0874757766723633), ('0 0 0 0 0', -3.1674036979675293), ('0 0 0 0 1 1 1 1', -3.196122646331787), ('0 0 0 0 0 0', -3.3024799823760986), ('0 0 0 0 0 1 1 1 1 1', -3.326033115386963), ('0 0 0 0 0 0 0', -3.4416282176971436), ('0 0 0 0 0 0 1 1 1 1 1 1', -3.466571807861328), ('0 0 0 0 0 0 0 0', -3.5828194618225098), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1', -3.610997438430786), ('0 0 0 0 0 0 0 0 0', -3.7255406379699707), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1', -3.757343292236328), ('0 0 0 0 0 0 0 0 0 0', -3.8695626258850098), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1', -3.9050469398498535), ('0 0 0 0 0 0 0 0 0 0 0', -4.014764785766602), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1', -4.053854942321777), ('0 0 0 0 0 0 0 0 0 0 0 0', -4.161059856414795), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1', -4.203639030456543), ('0 0 0 0 0 0 0 0 0 0 0 0 0', -4.308377265930176), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1', -4.354318618774414)]
2023-05-02 12:53:04,998 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:53:04,998 INFO     []
2023-05-02 12:53:04,999 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:53:04,999 INFO     []
2023-05-02 12:53:04,999 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:53:04,999 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:53:04,999 INFO     
2023-05-02 12:53:05,375 INFO     Language: ABnUBAn
2023-05-02 12:53:05,375 INFO     Description: (AB)^n | (BA)^n
2023-05-02 12:53:37,093 INFO     DONE TRAINING
2023-05-02 12:53:38,099 INFO     TRAINING SET LOSS: 378.7480701506138
2023-05-02 12:59:34,717 INFO     LM most common: [('0 1', 182252), ('1 0', 167441), ('1 0 1 0', 119340), ('0 1 0 1', 115428), ('0 1 0 1 0 1', 75470), ('1 0 1 0 1 0', 70114), ('0 1 0 1 0 1 0 1', 49698), ('1 0 1 0 1 0 1 0', 44480), ('0 1 0 1 0 1 0 1 0 1', 32592), ('1 0 1 0 1 0 1 0 1 0', 28290), ('0 1 0 1 0 1 0 1 0 1 0 1', 21305), ('1 0 1 0 1 0 1 0 1 0 1 0', 18527), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', 14297), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0', 11860), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 9064), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 7767), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 6069), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 5154), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 3818), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 3213), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 2528), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 2182), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1687), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 1483), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 1029)]
2023-05-02 12:59:34,806 INFO     LM most common: [('0 1', -2.1122868061065674), ('1 0', -2.276951551437378), ('1 0 1 0', -2.3243465423583984), ('0 1 0 1', -2.413282632827759), ('0 1 0 1 0 1', -2.6452741622924805), ('1 0 1 0 1 0', -2.7652430534362793), ('0 1 0 1 0 1 0 1', -2.889909267425537), ('1 0 1 0 1 0 1 0', -3.084641456604004), ('0 1 0 1 0 1 0 1 0 1', -3.1361398696899414), ('1 0 1 0 1 0 1 0 1 0', -3.3719871044158936), ('0 1 0 1 0 1 0 1 0 1 0 1', -3.3828125), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.629744529724121), ('1 0 1 0 1 0 1 0 1 0 1 0', -3.6384410858154297), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.876891613006592), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0', -3.8948659896850586), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.124324321746826), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.146389484405518), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.372036457061768), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.394392013549805), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.620112419128418), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.639305591583252), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -4.868570327758789), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -4.8813042640686035), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -5.117428779602051), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -5.120511054992676)]
2023-05-02 12:59:34,806 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 12:59:34,806 INFO     []
2023-05-02 12:59:34,806 INFO     Grammatical sequences that the model is missing:
2023-05-02 12:59:34,806 INFO     []
2023-05-02 12:59:34,806 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:59:34,806 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 12:59:34,807 INFO     
2023-05-02 12:59:35,239 INFO     Language: XX
2023-05-02 12:59:35,239 INFO     Description: XX (two copies of the same string)
2023-05-02 13:00:06,776 INFO     DONE TRAINING
2023-05-02 13:00:07,768 INFO     TRAINING SET LOSS: 599.9156387448311
2023-05-02 13:05:16,284 INFO     LM most common: [('0 0', 194094), ('1 1', 173733), ('0 0 0 0', 61997), ('0 1 0 1', 61809), ('1 0 1 0', 56258), ('1 1 1 1', 55940), ('1 0 1 1 0 1', 23089), ('1 0 0 1 0 0', 21615), ('0 1 1 0 1 1', 19820), ('1 1 1 1 1 1', 19342), ('1 1 0 1 1 0', 18326), ('0 0 1 0 0 1', 18324), ('0 0 0 0 0 0', 16305), ('0 1 0 0 1 0', 13899), ('1 1 0 1 1 1 0 1', 7665), ('1 0 1 1 1 0 1 1', 7510), ('0 1 1 1 0 1 1 1', 7414), ('1 0 0 1 1 0 0 1', 6969), ('1 0 0 0 1 0 0 0', 6900), ('0 1 0 1 0 1 0 1', 6825), ('0 0 0 1 0 0 0 1', 6590), ('1 1 1 1 1 1 1 1', 6293), ('0 0 1 0 0 0 1 0', 5864), ('1 1 1 0 1 1 1 0', 5861), ('0 0 1 1 0 0 1 1', 5774)]
2023-05-02 13:05:37,268 INFO     LM most common: [('0 0', -1.165420413017273), ('1 1', -1.3160712718963623), ('1 1 1 1', -2.546128034591675), ('0 0 0 0', -2.5878186225891113), ('0 1 0 1', -2.8325767517089844), ('1 0 1 0', -2.847280979156494), ('1 1 1 1 1 1', -3.9408233165740967), ('1 0 1 1 0 1', -4.157505035400391), ('0 0 1 0 0 1', -4.36520528793335), ('1 0 0 1 0 0', -4.371613025665283), ('1 1 0 1 1 0', -4.3939361572265625), ('0 1 1 0 1 1', -4.535050392150879), ('0 0 0 0 0 0', -4.677201747894287), ('0 1 0 0 1 0', -4.970495223999023), ('1 1 1 1 1 1 1 1', -5.495307922363281), ('1 1 0 1 1 1 0 1', -5.597376346588135), ('1 0 1 1 1 0 1 1', -5.772098541259766), ('0 0 1 0 0 0 1 0', -5.920000076293945), ('1 0 0 1 1 0 0 1', -5.9258012771606445), ('0 1 1 1 0 1 1 1', -6.144600868225098), ('1 0 0 0 1 0 0 0', -6.197086334228516), ('0 0 1 1 0 0 1 1', -6.235820770263672), ('0 0 0 1 0 0 0 1', -6.263859748840332), ('1 1 1 0 1 1 1 0', -6.323220252990723), ('0 1 0 0 0 1 0 0', -6.367846488952637)]
2023-05-02 13:05:37,268 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:05:37,268 INFO     []
2023-05-02 13:05:37,268 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:05:37,268 INFO     []
2023-05-02 13:05:37,269 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:05:37,269 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:05:37,269 INFO     
2023-05-02 13:05:37,745 INFO     Language: XXX
2023-05-02 13:05:37,746 INFO     Description: XXX
2023-05-02 13:06:17,038 INFO     DONE TRAINING
2023-05-02 13:06:18,316 INFO     TRAINING SET LOSS: 431.9397184550762
2023-05-02 13:16:56,707 INFO     LM most common: [('0 0 0', 179411), ('1 1 1', 165487), ('1 1 1 1 1 1', 59496), ('0 0 0 0 0 0', 58995), ('0 1 0 1 0 1', 58930), ('1 0 1 0 1 0', 55119), ('0 1 0 0 1 0 0 1 0', 21703), ('1 1 0 1 1 0 1 1 0', 21268), ('0 0 1 0 0 1 0 0 1', 21254), ('0 1 1 0 1 1 0 1 1', 20402), ('1 0 0 1 0 0 1 0 0', 20066), ('1 1 1 1 1 1 1 1 1', 18029), ('0 0 0 0 0 0 0 0 0', 17283), ('1 0 1 1 0 1 1 0 1', 16133), ('1 0 1 0 1 0 1 0 1 0 1 0', 8162), ('0 0 0 1 0 0 0 1 0 0 0 1', 7257), ('0 0 1 1 0 0 1 1 0 0 1 1', 6575), ('0 0 1 0 0 0 1 0 0 0 1 0', 6330), ('1 1 0 1 1 1 0 1 1 1 0 1', 6210), ('1 0 0 0 1 0 0 0 1 0 0 0', 6155), ('0 1 1 1 0 1 1 1 0 1 1 1', 5956), ('0 1 0 0 0 1 0 0 0 1 0 0', 5825), ('1 1 0 0 1 1 0 0 1 1 0 0', 5742), ('1 1 1 1 1 1 1 1 1 1 1 1', 5534), ('1 1 1 0 1 1 1 0 1 1 1 0', 5522)]
2023-05-02 13:17:35,558 INFO     LM most common: [('0 0 0', -1.123492956161499), ('1 1 1', -1.2791283130645752), ('1 1 1 1 1 1', -2.631577253341675), ('0 0 0 0 0 0', -2.694305896759033), ('0 1 0 1 0 1', -2.736011505126953), ('1 0 1 0 1 0', -2.8291070461273193), ('0 1 0 0 1 0 0 1 0', -4.2475152015686035), ('0 1 1 0 1 1 0 1 1', -4.405109405517578), ('1 1 1 1 1 1 1 1 1', -4.427456378936768), ('0 0 1 0 0 1 0 0 1', -4.455840110778809), ('1 0 0 1 0 0 1 0 0', -4.501777648925781), ('1 1 0 1 1 0 1 1 0', -4.571591854095459), ('0 0 0 0 0 0 0 0 0', -4.5725998878479), ('1 0 1 1 0 1 1 0 1', -4.757070541381836), ('1 0 0 0 1 0 0 0 1 0 0 0', -6.0660810470581055), ('0 1 1 1 0 1 1 1 0 1 1 1', -6.113561630249023), ('0 0 0 1 0 0 0 1 0 0 0 1', -6.179201126098633), ('1 1 1 1 1 1 1 1 1 1 1 1', -6.18835973739624), ('0 1 1 0 0 1 1 0 0 1 1 0', -6.2268476486206055), ('0 0 1 0 0 0 1 0 0 0 1 0', -6.2668046951293945), ('0 0 1 1 0 0 1 1 0 0 1 1', -6.26820707321167), ('0 1 0 0 0 1 0 0 0 1 0 0', -6.2773356437683105), ('1 1 0 1 1 1 0 1 1 1 0 1', -6.355130195617676), ('1 1 0 0 1 1 0 0 1 1 0 0', -6.384094715118408), ('0 0 0 0 0 0 0 0 0 0 0 0', -6.389766693115234)]
2023-05-02 13:17:35,558 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:17:35,558 INFO     []
2023-05-02 13:17:35,558 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:17:35,558 INFO     []
2023-05-02 13:17:35,560 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:17:35,560 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:17:35,560 INFO     
2023-05-02 13:17:36,060 INFO     Language: XY
2023-05-02 13:17:36,060 INFO     Description: XY: X != Y (2 non-empty strings that are not identical; could include BBBB = B + BBB)
2023-05-02 13:18:05,001 INFO     DONE TRAINING
2023-05-02 13:18:05,909 INFO     TRAINING SET LOSS: 929.9963488578796
2023-05-02 13:21:19,468 INFO     LM most common: [('1 0', 36245), ('0 1', 29983), ('0 1 1', 24003), ('0 0 0', 23200), ('1 1 1', 22709), ('1 1 0', 21233), ('1 0 1', 21191), ('1 0 0', 20250), ('0 1 0', 19188), ('0 0 1', 18712), ('0 0 1 1', 11147), ('1 1 1 0', 11043), ('1 1 0 0', 10858), ('0 1 1 1', 10613), ('1 0 0 1', 10360), ('1 0 0 0', 10309), ('1 1 0 1', 10189), ('1 0 1 1', 9874), ('0 1 1 0', 9869), ('0 0 0 1', 9851), ('0 0 1 0', 9783), ('0 1 0 1', 9335), ('0 1 0 0', 9047), ('0 0 0 0', 8084), ('1 0 1 0', 8067)]
2023-05-02 13:22:07,871 INFO     LM most common: [('0 1 1', -4.178920745849609), ('1 0', -4.312348365783691), ('1 0 1', -4.380460739135742), ('0 0 0', -4.4017333984375), ('1 0 0', -4.479030609130859), ('1 1 1', -4.482781410217285), ('0 1 0', -4.602938652038574), ('1 1 0', -4.63159704208374), ('0 1 1 1', -4.753176212310791), ('0 1', -4.754477024078369), ('1 0 0 1', -4.785569190979004), ('1 0 0 0', -4.803121566772461), ('1 0 1 1', -4.8675384521484375), ('0 0 1', -4.88908576965332), ('0 1 1 0', -4.893960952758789), ('0 0 1 1', -4.914651870727539), ('1 1 0 0', -4.928519248962402), ('1 1 1 0', -4.95773983001709), ('0 1 0 1', -5.048459053039551), ('0 1 0 0', -5.071938514709473), ('1 1 0 1', -5.078569412231445), ('0 0 0 1', -5.1175689697265625), ('0 0 1 0', -5.177101135253906), ('1 1 1 1 0', -5.260568141937256), ('1 0 1 0', -5.2613630294799805)]
2023-05-02 13:22:07,871 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:22:07,871 INFO     []
2023-05-02 13:22:07,872 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:22:07,872 INFO     []
2023-05-02 13:22:07,874 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:22:07,874 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:22:07,874 INFO     
2023-05-02 13:22:08,281 INFO     Language: XXR
2023-05-02 13:22:08,281 INFO     Description: X X^R (even-length palindromes)
2023-05-02 13:22:39,537 INFO     DONE TRAINING
2023-05-02 13:22:40,516 INFO     TRAINING SET LOSS: 590.967975974083
2023-05-02 13:26:46,356 INFO     LM most common: [('1 1', 179631), ('0 0', 178454), ('1 0 0 1', 64048), ('0 0 0 0', 55904), ('1 1 1 1', 54279), ('0 1 1 0', 53559), ('0 1 0 0 1 0', 25485), ('1 0 0 0 0 1', 23926), ('1 1 0 0 1 1', 21454), ('0 0 1 1 0 0', 20429), ('1 0 1 1 0 1', 19946), ('0 1 1 1 1 0', 17552), ('0 0 0 0 0 0', 16117), ('1 1 1 1 1 1', 13765), ('1 0 0 1 1 0 0 1', 8275), ('0 1 0 0 0 0 1 0', 8174), ('0 0 1 1 1 1 0 0', 8152), ('0 0 1 0 0 1 0 0', 7791), ('1 0 0 0 0 0 0 1', 7608), ('1 1 0 0 0 0 1 1', 7568), ('0 1 0 1 1 0 1 0', 7265), ('1 1 1 0 0 1 1 1', 7212), ('1 0 1 1 1 1 0 1', 6535), ('1 0 1 0 0 1 0 1', 6305), ('0 1 1 1 1 1 1 0', 6262)]
2023-05-02 13:26:57,771 INFO     LM most common: [('1 1', -1.2412502765655518), ('0 0', -1.2615768909454346), ('1 0 0 1', -2.62595534324646), ('0 0 0 0', -2.669231414794922), ('1 1 1 1', -2.6884422302246094), ('0 1 1 0', -2.972418785095215), ('0 0 1 1 0 0', -4.023698806762695), ('1 1 0 0 1 1', -4.040599346160889), ('1 0 0 0 0 1', -4.073012351989746), ('0 1 0 0 1 0', -4.090795040130615), ('0 0 0 0 0 0', -4.4049973487854), ('1 0 1 1 0 1', -4.438259124755859), ('0 1 1 1 1 0', -4.646972179412842), ('1 1 1 1 1 1', -4.771993160247803), ('0 0 1 1 1 1 0 0', -5.4585280418396), ('1 1 0 0 0 0 1 1', -5.513477325439453), ('0 0 1 0 0 1 0 0', -5.5286383628845215), ('0 1 0 0 0 0 1 0', -5.665945053100586), ('1 0 0 0 0 0 0 1', -5.852013111114502), ('1 1 1 0 0 1 1 1', -6.060641765594482), ('1 0 1 1 1 1 0 1', -6.105471134185791), ('1 0 0 1 1 0 0 1', -6.11182165145874), ('0 1 0 1 1 0 1 0', -6.155704498291016), ('0 1 1 1 1 1 1 0', -6.163279056549072), ('1 0 1 0 0 1 0 1', -6.1687846183776855)]
2023-05-02 13:26:57,771 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:26:57,771 INFO     []
2023-05-02 13:26:57,771 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:26:57,771 INFO     []
2023-05-02 13:26:57,772 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:26:57,772 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:26:57,772 INFO     
2023-05-02 13:26:58,172 INFO     Language: XXI
2023-05-02 13:26:58,172 INFO     Description: X X^I (where X^I is the inverse of X - replace every A with B and vice-versa)
2023-05-02 13:27:29,779 INFO     DONE TRAINING
2023-05-02 13:27:30,789 INFO     TRAINING SET LOSS: 591.7603742480278
2023-05-02 13:35:59,047 INFO     LM most common: [('1 0', 185662), ('0 1', 169224), ('0 1 1 0', 59466), ('1 1 0 0', 55485), ('1 0 0 1', 53059), ('0 0 1 1', 51545), ('1 0 1 0 1 0', 23383), ('0 0 1 1 1 0', 20908), ('0 1 0 1 0 1', 19931), ('1 1 1 0 0 0', 17036), ('1 1 0 0 0 1', 16653), ('0 0 0 1 1 1', 15985), ('0 1 1 1 0 0', 15516), ('1 0 0 0 1 1', 14549), ('0 0 1 1 1 1 0 0', 7480), ('1 0 0 1 0 1 1 0', 6730), ('1 0 1 1 0 1 0 0', 6454), ('1 1 0 1 0 0 1 0', 6054), ('1 1 1 1 0 0 0 0', 5881), ('0 0 0 1 1 1 1 0', 5820), ('0 0 1 0 1 1 0 1', 5803), ('1 1 0 0 0 0 1 1', 5719), ('1 1 1 0 0 0 0 1', 5629), ('0 0 0 0 1 1 1 1', 5556), ('1 0 0 0 0 1 1 1', 5466)]
2023-05-02 13:36:39,302 INFO     LM most common: [('1 0', -1.1861820220947266), ('0 1', -1.3628427982330322), ('0 1 1 0', -2.543788433074951), ('1 0 0 1', -2.5731725692749023), ('1 1 0 0', -2.8765416145324707), ('0 0 1 1', -2.9623916149139404), ('1 0 1 0 1 0', -3.78909969329834), ('0 0 1 1 1 0', -4.032867908477783), ('1 0 0 0 1 1', -4.162476062774658), ('0 1 0 1 0 1', -4.211021900177002), ('0 1 1 1 0 0', -4.448827266693115), ('1 1 0 0 0 1', -4.473677158355713), ('1 1 1 0 0 0', -4.633975028991699), ('0 0 0 1 1 1', -4.696643352508545), ('0 0 1 1 1 1 0 0', -5.393540859222412), ('1 0 0 0 0 1 1 1', -5.722428321838379), ('1 1 0 0 0 0 1 1', -5.752010345458984), ('1 0 0 1 0 1 1 0', -5.784451961517334), ('1 0 1 1 0 1 0 0', -5.838446617126465), ('0 0 0 1 1 1 1 0', -6.0309295654296875), ('1 1 1 0 0 0 0 1', -6.052684307098389), ('0 1 0 0 1 0 1 1', -6.0886311531066895), ('1 1 1 1 0 0 0 0', -6.141908168792725), ('0 1 1 1 1 0 0 0', -6.242874622344971), ('0 1 0 1 1 0 1 0', -6.2788920402526855)]
2023-05-02 13:36:39,302 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:36:39,302 INFO     []
2023-05-02 13:36:39,302 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:36:39,303 INFO     []
2023-05-02 13:36:39,304 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:36:39,304 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:36:39,304 INFO     
2023-05-02 13:36:39,707 INFO     Language: XXRI
2023-05-02 13:36:39,707 INFO     Description: X (X^R)^I
2023-05-02 13:37:11,331 INFO     DONE TRAINING
2023-05-02 13:37:12,334 INFO     TRAINING SET LOSS: 586.756246984005
2023-05-02 13:57:09,555 INFO     LM most common: [('1 0', 182763), ('0 1', 165373), ('1 1 0 0', 59131), ('0 0 1 1', 56771), ('0 1 0 1', 55635), ('1 0 1 0', 54792), ('0 1 1 0 0 1', 20679), ('1 1 1 0 0 0', 20442), ('1 1 0 1 0 0', 19185), ('0 1 0 1 0 1', 18283), ('0 0 1 0 1 1', 18188), ('0 0 0 1 1 1', 18104), ('1 0 1 0 1 0', 17557), ('1 0 0 1 1 0', 16852), ('1 0 1 1 0 0 1 0', 7948), ('1 1 1 1 0 0 0 0', 6831), ('0 1 1 1 0 0 0 1', 6815), ('0 1 1 0 1 0 0 1', 6768), ('1 1 0 0 1 1 0 0', 6703), ('1 1 1 0 1 0 0 0', 6402), ('0 1 0 0 1 1 0 1', 6312), ('1 1 0 1 0 1 0 0', 6141), ('0 0 0 0 1 1 1 1', 5838), ('1 0 0 1 0 1 1 0', 5761), ('0 0 0 1 0 1 1 1', 5728)]
2023-05-02 13:57:38,989 INFO     LM most common: [('1 0', -1.230796456336975), ('0 1', -1.3835161924362183), ('0 1 0 1', -2.5342459678649902), ('1 0 1 0', -2.5518486499786377), ('1 1 0 0', -2.725555419921875), ('0 0 1 1', -2.859156608581543), ('0 1 0 1 0 1', -4.008608818054199), ('0 1 1 0 0 1', -4.037267684936523), ('1 0 1 0 1 0', -4.053864479064941), ('1 1 0 1 0 0', -4.235687255859375), ('1 1 1 0 0 0', -4.295724868774414), ('0 0 1 0 1 1', -4.4508209228515625), ('0 0 0 1 1 1', -4.467584133148193), ('1 0 0 1 1 0', -4.520738124847412), ('0 1 1 0 1 0 0 1', -5.682011604309082), ('1 0 1 1 0 0 1 0', -5.770923614501953), ('0 1 1 1 0 0 0 1', -5.797628402709961), ('1 1 0 1 0 1 0 0', -5.825847148895264), ('1 0 0 1 0 1 1 0', -5.854681015014648), ('0 1 0 0 1 1 0 1', -5.95577335357666), ('1 1 1 0 1 0 0 0', -5.974886894226074), ('1 0 1 0 1 0 1 0', -5.9945526123046875), ('1 1 1 1 0 0 0 0', -6.007791042327881), ('0 1 0 1 0 1 0 1', -6.013486862182617), ('1 1 0 0 1 1 0 0', -6.053420543670654)]
2023-05-02 13:57:38,989 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 13:57:38,989 INFO     []
2023-05-02 13:57:38,989 INFO     Grammatical sequences that the model is missing:
2023-05-02 13:57:38,989 INFO     []
2023-05-02 13:57:38,991 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:57:38,991 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 13:57:38,991 INFO     
2023-05-02 13:57:39,599 INFO     Language: An2
2023-05-02 13:57:39,600 INFO     Description: A^(n^2)
2023-05-02 13:58:21,633 INFO     DONE TRAINING
2023-05-02 13:58:22,993 INFO     TRAINING SET LOSS: 218.31485054641962
2023-05-02 14:19:54,438 INFO     LM most common: [('0', 544437), ('0 0 0 0', 249436), ('0 0 0 0 0 0 0 0 0', 124376), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 51465), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 19050), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 6311), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1420), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1246), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 745), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 289), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 218), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 196), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 109), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 104), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 98), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 76), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 63), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 49), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 41), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 33), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 33), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 29), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 28), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 28), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 22)]
2023-05-02 14:19:54,522 INFO     LM most common: [('0', -0.5313546657562256), ('0 0 0 0', -1.4046401977539062), ('0 0 0 0 0 0 0 0 0', -2.1475133895874023), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -3.293633222579956), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -4.655490875244141), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -6.175707817077637), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -7.966165065765381), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -8.733293533325195), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -8.921629905700684), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -9.846909523010254), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -10.037817001342773), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.268610954284668), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.31772232055664), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.401690483093262), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.891836166381836), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -11.965961456298828), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.156704902648926), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.460554122924805), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.552695274353027), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.576122283935547), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.800106048583984), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -12.997031211853027), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -13.582618713378906), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -13.595430374145508), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -13.732464790344238)]
2023-05-02 14:19:54,523 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:19:54,523 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 14:19:54,523 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:19:54,523 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 14:19:54,523 INFO     LM precision, recall, fscore: 0.36 0.45 0.39999999999999997
2023-05-02 14:19:54,523 INFO     Memorization precision, recall, fscore: 1.0 0.65 0.787878787878788
2023-05-02 14:19:54,523 INFO     
2023-05-02 14:19:54,962 INFO     Language: AnBmCnDm
2023-05-02 14:19:54,962 INFO     Description: A^n B^m C^n D^m
2023-05-02 14:20:35,593 INFO     DONE TRAINING
2023-05-02 14:20:36,917 INFO     TRAINING SET LOSS: 296.24839052557945
2023-05-02 14:31:15,491 INFO     LM most common: [('0 1 2 3', 106882), ('0 1 1 2 3 3', 75784), ('0 0 1 2 2 3', 74166), ('0 1 1 1 2 3 3 3', 50228), ('0 0 1 1 2 2 3 3', 49166), ('0 0 0 1 2 2 2 3', 49150), ('0 1 1 1 1 2 3 3 3 3', 34350), ('0 0 1 1 1 2 2 3 3 3', 33075), ('0 0 0 0 1 2 2 2 2 3', 32511), ('0 0 0 1 1 2 2 2 3 3', 31822), ('0 1 1 1 1 1 2 3 3 3 3 3', 23331), ('0 0 1 1 1 1 2 2 3 3 3 3', 22433), ('0 0 0 1 1 1 2 2 2 3 3 3', 21707), ('0 0 0 0 1 1 2 2 2 2 3 3', 21250), ('0 0 0 0 0 1 2 2 2 2 2 3', 21017), ('0 1 1 1 1 1 1 2 3 3 3 3 3 3', 16016), ('0 0 1 1 1 1 1 2 2 3 3 3 3 3', 15361), ('0 0 0 1 1 1 1 2 2 2 3 3 3 3', 14532), ('0 0 0 0 1 1 1 2 2 2 2 3 3 3', 14293), ('0 0 0 0 0 0 1 2 2 2 2 2 2 3', 13955), ('0 0 0 0 0 1 1 2 2 2 2 2 3 3', 13746), ('0 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3', 11009), ('0 0 1 1 1 1 1 1 2 2 3 3 3 3 3 3', 10536), ('0 0 0 1 1 1 1 1 2 2 2 3 3 3 3 3', 9928), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', 9805)]
2023-05-02 14:31:16,308 INFO     LM most common: [('0 1 2 3', -3.310389995574951), ('0 1 1 2 3 3', -3.4290175437927246), ('0 0 1 2 2 3', -3.4349617958068848), ('0 0 0 1 2 2 2 3', -3.6417665481567383), ('0 1 1 1 2 3 3 3', -3.6641387939453125), ('0 0 1 1 2 2 3 3', -3.6645917892456055), ('0 1 1 1 1 2 3 3 3 3', -3.868482828140259), ('0 0 1 1 1 2 2 3 3 3', -3.885338306427002), ('0 0 0 0 1 2 2 2 2 3', -3.889251232147217), ('0 0 0 1 1 2 2 2 3 3', -3.911285877227783), ('0 1 1 1 1 1 2 3 3 3 3 3', -4.0615925788879395), ('0 0 1 1 1 1 2 2 3 3 3 3', -4.079414367675781), ('0 0 0 1 1 1 2 2 2 3 3 3', -4.126465797424316), ('0 0 0 0 0 1 2 2 2 2 2 3', -4.146169185638428), ('0 0 0 0 1 1 2 2 2 2 3 3', -4.1637678146362305), ('0 1 1 1 1 1 1 2 3 3 3 3 3 3', -4.254443645477295), ('0 0 1 1 1 1 1 2 2 3 3 3 3 3', -4.272781848907471), ('0 0 0 1 1 1 1 2 2 2 3 3 3 3', -4.3210129737854), ('0 0 0 0 1 1 1 2 2 2 2 3 3 3', -4.375624656677246), ('0 0 0 0 0 0 1 2 2 2 2 2 2 3', -4.4000959396362305), ('0 0 0 0 0 1 1 2 2 2 2 2 3 3', -4.417737007141113), ('0 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3', -4.4488959312438965), ('0 0 1 1 1 1 1 1 2 2 3 3 3 3 3 3', -4.468886852264404), ('0 0 0 1 1 1 1 1 2 2 2 3 3 3 3 3', -4.51868200302124), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', -4.568540096282959)]
2023-05-02 14:31:16,308 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:31:16,308 INFO     []
2023-05-02 14:31:16,308 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:31:16,308 INFO     []
2023-05-02 14:31:16,308 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:31:16,308 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:31:16,308 INFO     
2023-05-02 14:31:16,759 INFO     Language: AnBmAnBm
2023-05-02 14:31:16,759 INFO     Description: A^n B^m A^n B^m
2023-05-02 14:31:57,010 INFO     DONE TRAINING
2023-05-02 14:31:58,329 INFO     TRAINING SET LOSS: 296.97835966944695
2023-05-02 14:41:16,489 INFO     LM most common: [('0 1 0 1', 118487), ('0 0 1 0 0 1', 83057), ('0 1 1 0 1 1', 73773), ('0 0 0 1 0 0 0 1', 56468), ('0 0 1 1 0 0 1 1', 54808), ('0 1 1 1 0 1 1 1', 46508), ('0 0 0 1 1 0 0 0 1 1', 36889), ('0 0 0 0 1 0 0 0 0 1', 36694), ('0 0 1 1 1 0 0 1 1 1', 34616), ('0 1 1 1 1 0 1 1 1 1', 29873), ('0 0 0 0 1 1 0 0 0 0 1 1', 24027), ('0 0 0 1 1 1 0 0 0 1 1 1', 23734), ('0 0 0 0 0 1 0 0 0 0 0 1', 23471), ('0 0 1 1 1 1 0 0 1 1 1 1', 21995), ('0 1 1 1 1 1 0 1 1 1 1 1', 19295), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1', 15531), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1', 15341), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1', 15122), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1', 14838), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1', 13949), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1', 12581), ('0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1', 9930), ('0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1', 9777), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', 9653), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1', 9444)]
2023-05-02 14:41:17,253 INFO     LM most common: [('0 1 0 1', -3.0646519660949707), ('0 0 1 0 0 1', -3.2014737129211426), ('0 0 0 1 0 0 0 1', -3.3570003509521484), ('0 1 1 0 1 1', -3.3967349529266357), ('0 0 1 1 0 0 1 1', -3.401904582977295), ('0 0 0 1 1 0 0 0 1 1', -3.5811407566070557), ('0 0 0 0 1 0 0 0 0 1', -3.584592819213867), ('0 0 1 1 1 0 0 1 1 1', -3.694127082824707), ('0 1 1 1 0 1 1 1', -3.725597858428955), ('0 0 0 0 1 1 0 0 0 0 1 1', -3.818472385406494), ('0 0 0 0 0 1 0 0 0 0 0 1', -3.854111671447754), ('0 0 0 1 1 1 0 0 0 1 1 1', -3.8575797080993652), ('0 0 1 1 1 1 0 0 1 1 1 1', -3.971096992492676), ('0 1 1 1 1 0 1 1 1 1', -3.985788345336914), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1', -4.076979637145996), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1', -4.0964274406433105), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1', -4.136122226715088), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1', -4.141552925109863), ('0 1 1 1 1 1 0 1 1 1 1 1', -4.262197494506836), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1', -4.267308235168457), ('0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1', -4.335232734680176), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', -4.354214191436768), ('0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1', -4.393329620361328), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1', -4.432006359100342), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1', -4.439556121826172)]
2023-05-02 14:41:17,253 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:41:17,253 INFO     []
2023-05-02 14:41:17,253 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:41:17,253 INFO     []
2023-05-02 14:41:17,253 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:41:17,253 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:41:17,253 INFO     
2023-05-02 14:41:17,749 INFO     Language: AnBmAnBmCCC
2023-05-02 14:41:17,749 INFO     Description: A^n B^m A^n B^m CCC
2023-05-02 14:42:01,262 INFO     DONE TRAINING
2023-05-02 14:42:02,682 INFO     TRAINING SET LOSS: 239.5780343413353
2023-05-02 14:53:20,430 INFO     LM most common: [('0 1 0 1 2 2 2', 121916), ('0 0 1 0 0 1 2 2 2', 81548), ('0 1 1 0 1 1 2 2 2', 75540), ('0 0 0 1 0 0 0 1 2 2 2', 51907), ('0 1 1 1 0 1 1 1 2 2 2', 51544), ('0 0 1 1 0 0 1 1 2 2 2', 50471), ('0 0 0 0 1 0 0 0 0 1 2 2 2', 35483), ('0 1 1 1 1 0 1 1 1 1 2 2 2', 35211), ('0 0 1 1 1 0 0 1 1 1 2 2 2', 34008), ('0 0 0 1 1 0 0 0 1 1 2 2 2', 30284), ('0 0 0 0 0 1 0 0 0 0 0 1 2 2 2', 23307), ('0 1 1 1 1 1 0 1 1 1 1 1 2 2 2', 23115), ('0 0 1 1 1 1 0 0 1 1 1 1 2 2 2', 22896), ('0 0 0 0 1 1 0 0 0 0 1 1 2 2 2', 20812), ('0 0 0 1 1 1 0 0 0 1 1 1 2 2 2', 19897), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1 2 2 2', 15794), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1 2 2 2', 15261), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1 2 2 2', 14908), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1 2 2 2', 13696), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1 2 2 2', 13454), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1 2 2 2', 12916), ('0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 2 2 2', 10180), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 2 2 2', 10085), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 2 2 2', 9659), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 2 2 2', 9112)]
2023-05-02 14:53:21,254 INFO     LM most common: [('0 1 0 1 2 2 2', -2.99617075920105), ('0 0 1 0 0 1 2 2 2', -3.1712121963500977), ('0 1 1 0 1 1 2 2 2', -3.3674983978271484), ('0 0 0 1 0 0 0 1 2 2 2', -3.461636781692505), ('0 1 1 1 0 1 1 1 2 2 2', -3.529507637023926), ('0 0 1 1 0 0 1 1 2 2 2', -3.5633559226989746), ('0 0 0 0 1 0 0 0 0 1 2 2 2', -3.6545257568359375), ('0 1 1 1 1 0 1 1 1 1 2 2 2', -3.6926136016845703), ('0 0 1 1 1 0 0 1 1 1 2 2 2', -3.768859624862671), ('0 0 0 0 0 1 0 0 0 0 0 1 2 2 2', -3.883699893951416), ('0 1 1 1 1 1 0 1 1 1 1 1 2 2 2', -3.8894872665405273), ('0 0 1 1 1 1 0 0 1 1 1 1 2 2 2', -3.9282493591308594), ('0 0 0 1 1 0 0 0 1 1 2 2 2', -3.956606864929199), ('0 0 1 1 1 1 1 0 0 1 1 1 1 1 2 2 2', -4.111440181732178), ('0 0 0 0 0 0 1 0 0 0 0 0 0 1 2 2 2', -4.1160173416137695), ('0 0 0 0 1 1 0 0 0 0 1 1 2 2 2', -4.127350807189941), ('0 1 1 1 1 1 1 0 1 1 1 1 1 1 2 2 2', -4.137802600860596), ('0 0 0 1 1 1 0 0 0 1 1 1 2 2 2', -4.226463317871094), ('0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 2 2 2', -4.342239856719971), ('0 0 0 0 0 1 1 0 0 0 0 0 1 1 2 2 2', -4.34739875793457), ('0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 2 2 2', -4.351114749908447), ('0 0 0 1 1 1 1 0 0 0 1 1 1 1 2 2 2', -4.388187408447266), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 2 2 2', -4.422161102294922), ('0 0 0 0 1 1 1 0 0 0 0 1 1 1 2 2 2', -4.454267501831055), ('0 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 2 2 2', -4.563910484313965)]
2023-05-02 14:53:21,254 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 14:53:21,254 INFO     []
2023-05-02 14:53:21,254 INFO     Grammatical sequences that the model is missing:
2023-05-02 14:53:21,254 INFO     []
2023-05-02 14:53:21,254 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:53:21,254 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 14:53:21,254 INFO     
2023-05-02 14:53:21,709 INFO     Language: AnBnCn
2023-05-02 14:53:21,709 INFO     Description: A^n B^n C^n
2023-05-02 14:54:00,575 INFO     DONE TRAINING
2023-05-02 14:54:01,835 INFO     TRAINING SET LOSS: 194.0105436295271
2023-05-02 15:04:39,358 INFO     LM most common: [('0 1 2', 361256), ('0 0 1 1 2 2', 229768), ('0 0 0 1 1 1 2 2 2', 147923), ('0 0 0 0 1 1 1 1 2 2 2 2', 94797), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', 60611), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', 38658), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', 24518), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', 15597), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', 9784), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', 6136), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', 4029), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', 2583), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', 1567), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 1031), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 643), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 387), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 269), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 163), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 107), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 72), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 26), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 25), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 23), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', 8)]
2023-05-02 15:04:39,410 INFO     LM most common: [('0 1 2', -1.4133384227752686), ('0 0 1 1 2 2', -1.703522801399231), ('0 0 0 1 1 1 2 2 2', -1.958791971206665), ('0 0 0 0 1 1 1 1 2 2 2 2', -2.238823890686035), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2', -2.5174078941345215), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2', -2.799609422683716), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2', -3.083944797515869), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2', -3.3691837787628174), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2', -3.654527187347412), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2', -3.9394571781158447), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2', -4.223684310913086), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2', -4.5070061683654785), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2', -4.789294242858887), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.070462226867676), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.350521087646484), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.62943172454834), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -5.907196044921875), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.18380880355835), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.459283828735352), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -6.733659744262695), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.006932258605957), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.279148101806641), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.550293922424316), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -7.820412635803223), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2', -8.089512825012207)]
2023-05-02 15:04:39,410 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:04:39,410 INFO     []
2023-05-02 15:04:39,410 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:04:39,410 INFO     []
2023-05-02 15:04:39,410 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:04:39,410 INFO     Memorization precision, recall, fscore: 1.0 0.88 0.9361702127659575
2023-05-02 15:04:39,410 INFO     
2023-05-02 15:04:39,920 INFO     Language: AnBnCnDn
2023-05-02 15:04:39,920 INFO     Description: A^n B^n C^n D^n
2023-05-02 15:05:26,398 INFO     DONE TRAINING
2023-05-02 15:05:27,916 INFO     TRAINING SET LOSS: 149.52829229831696
2023-05-02 15:23:25,872 INFO     LM most common: [('0 1 2 3', 374004), ('0 0 1 1 2 2 3 3', 229167), ('0 0 0 1 1 1 2 2 2 3 3 3', 146208), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', 91017), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', 57619), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', 36836), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', 23631), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', 14938), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', 9668), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', 6136), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', 3951), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', 2529), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', 1605), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 999), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 633), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 431), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 232), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 156), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 80), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 62), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 32), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 25), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 14), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 10), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', 7)]
2023-05-02 15:23:25,934 INFO     LM most common: [('0 1 2 3', -1.3412774801254272), ('0 0 1 1 2 2 3 3', -1.688218116760254), ('0 0 0 1 1 1 2 2 2 3 3 3', -1.9683983325958252), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3', -2.29123592376709), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3', -2.5795021057128906), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3', -2.856966495513916), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3', -3.1307804584503174), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3', -3.4039597511291504), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3', -3.677891731262207), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3', -3.9533655643463135), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3', -4.230823040008545), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3', -4.510591506958008), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3', -4.792832374572754), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.077702045440674), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.365267753601074), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.655605792999268), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -5.948790550231934), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.244861602783203), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.543858051300049), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -6.845847129821777), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -7.1508355140686035), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -7.458898544311523), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -7.770059585571289), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -8.084362983703613), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3', -8.40185260772705)]
2023-05-02 15:23:25,934 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:23:25,934 INFO     []
2023-05-02 15:23:25,934 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:23:25,934 INFO     []
2023-05-02 15:23:25,934 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 15:23:25,934 INFO     Memorization precision, recall, fscore: 1.0 0.8 0.888888888888889
2023-05-02 15:23:25,934 INFO     
2023-05-02 15:23:26,485 INFO     Language: AnBnCnDnEn
2023-05-02 15:23:26,485 INFO     Description: A^n B^n C^n D^n E^n
2023-05-02 15:24:20,597 INFO     DONE TRAINING
2023-05-02 15:24:22,351 INFO     TRAINING SET LOSS: 121.55970948189497
2023-05-02 15:54:56,453 INFO     LM most common: [('0 1 2 3 4', 345830), ('0 0 1 1 2 2 3 3 4 4', 225168), ('0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', 146556), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', 96663), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', 64067), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', 41821), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', 27757), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', 18024), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', 11683), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', 7677), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', 5093), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', 3326), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', 2171), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 1445), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 907), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 625), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 420), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 263), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 159), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 125), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 78), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', 49), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', 37), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', 19), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4', 16)]
2023-05-02 15:54:56,531 INFO     LM most common: [('0 1 2 3 4', -1.5178329944610596), ('0 0 1 1 2 2 3 3 4 4', -1.7824136018753052), ('0 0 0 1 1 1 2 2 2 3 3 3 4 4 4', -2.031742811203003), ('0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4', -2.26914644241333), ('0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4', -2.5091135501861572), ('0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4', -2.7499520778656006), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4', -2.991347074508667), ('0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4', -3.233213186264038), ('0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', -3.475471019744873), ('0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4', -3.7180590629577637), ('0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4', -3.9609508514404297), ('0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4', -4.204122543334961), ('0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', -4.447565078735352), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -4.691274642944336), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -4.935242652893066), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.179469108581543), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.423953056335449), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.6686882972717285), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -5.913687705993652), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.158944129943848), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -6.404451370239258), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', -55.303253173828125), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', -56.2438850402832), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', -56.415042877197266), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4', -57.660343170166016)]
2023-05-02 15:54:56,531 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:54:56,531 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4']
2023-05-02 15:54:56,531 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:54:56,531 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4']
2023-05-02 15:54:56,531 INFO     LM precision, recall, fscore: 0.84 0.84 0.8399999999999999
2023-05-02 15:54:56,531 INFO     Memorization precision, recall, fscore: 1.0 0.76 0.8636363636363636
2023-05-02 15:54:56,531 INFO     
2023-05-02 15:54:57,216 INFO     Language: A2en
2023-05-02 15:54:57,216 INFO     Description: A^(2^n)
2023-05-02 15:55:15,572 INFO     DONE TRAINING
2023-05-02 15:55:16,199 INFO     TRAINING SET LOSS: 261.49551217257977
2023-05-02 15:56:41,393 INFO     LM most common: [('0', 810314), ('0 0', 154368), ('0 0 0 0', 28938), ('0 0 0 0 0 0 0 0', 5679), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 603), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 79), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 6), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 5), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 3), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 2), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', 1)]
2023-05-02 15:56:41,412 INFO     LM most common: [('0', -0.05329492315649986), ('0 0', -3.0093603134155273), ('0 0 0 0', -6.007837772369385), ('0 0 0 0 0 0 0 0', -9.070344924926758), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -13.179242134094238), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -16.80663299560547), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -20.112722396850586), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -20.165912628173828), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -21.042226791381836), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -22.96961784362793), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -23.034770965576172), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -26.680532455444336), ('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', -51.30996322631836)]
2023-05-02 15:56:41,412 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 15:56:41,412 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 15:56:41,412 INFO     Grammatical sequences that the model is missing:
2023-05-02 15:56:41,412 INFO     ['0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']
2023-05-02 15:56:41,413 INFO     LM precision, recall, fscore: 0.46153846153846156 0.6 0.5217391304347826
2023-05-02 15:56:41,413 INFO     Memorization precision, recall, fscore: 0.875 0.7 0.7777777777777777
2023-05-02 15:56:41,413 INFO     
2023-05-02 15:56:41,940 INFO     Language: ABnen
2023-05-02 15:56:41,940 INFO     Description: (AB)^(n^2)
2023-05-02 15:57:20,915 INFO     DONE TRAINING
2023-05-02 15:57:22,190 INFO     TRAINING SET LOSS: 142.43687073141336
2023-05-02 16:30:52,264 INFO     LM most common: [('0 1', 693647), ('0 1 0 1 0 1 0 1', 207163), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 76692), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 13783), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 795), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 705), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 650), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 627), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 599), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 509), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 490), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 490), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 437), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 357), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 313), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 276), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 259), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 255), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 228), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 196), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 180), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 146), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 126), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 122), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', 116)]
2023-05-02 16:30:52,359 INFO     LM most common: [('0 1', -0.1769421398639679), ('0 1 0 1 0 1 0 1', -2.023251533508301), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -3.5902159214019775), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.395827293395996), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.357406616210938), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.365273475646973), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.365378379821777), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.374974250793457), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.384461402893066), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.393878936767578), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.403427124023438), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.414051055908203), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.425302505493164), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.437336921691895), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.4498291015625), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.450130462646484), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.463611602783203), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.477583885192871), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.492159843444824), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -11.814607620239258), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -12.922012329101562), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -12.974522590637207), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -14.439070701599121), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -15.042035102844238), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -15.04409408569336)]
2023-05-02 16:30:52,359 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 16:30:52,359 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1']
2023-05-02 16:30:52,359 INFO     Grammatical sequences that the model is missing:
2023-05-02 16:30:52,359 INFO     ['0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', '0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1']
2023-05-02 16:30:52,359 INFO     LM precision, recall, fscore: 0.24 0.5384615384615384 0.33201581027667987
2023-05-02 16:30:52,359 INFO     Memorization precision, recall, fscore: 1.0 0.6153846153846154 0.761904761904762
2023-05-02 16:30:52,359 INFO     
2023-05-02 16:30:53,063 INFO     Language: Count
2023-05-02 16:30:53,063 INFO     Description: Any prefix of [b, bb, bbb, bbbb, ...], with a's separating the elements of the prefix
2023-05-02 16:31:41,067 INFO     DONE TRAINING
2023-05-02 16:31:42,621 INFO     TRAINING SET LOSS: 185.10958264768124
2023-05-02 17:07:01,195 INFO     LM most common: [('0 1', 441117), ('0 1 0 1 1', 247501), ('0 1 0 1 1 0 1 1 1', 138797), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1', 76080), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1', 42781), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1', 23793), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1', 13116), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', 7375), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1', 4122), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1', 2250), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1', 1248), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', 692), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0', 465), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', 383), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 75), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', 73), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', 58), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1', 28), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', 25), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', 20), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', 1)]
2023-05-02 17:07:01,242 INFO     LM most common: [('0 1', -0.955173134803772), ('0 1 0 1 1', -1.4368091821670532), ('0 1 0 1 1 0 1 1 1', -1.9105182886123657), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1', -2.428515672683716), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1', -2.8884105682373047), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1', -3.406358003616333), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1', -3.907180070877075), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1', -4.4070658683776855), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1', -4.904040336608887), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1', -5.386075496673584), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1', -5.843496799468994), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', -6.291352272033691), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', -6.734355926513672), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', -10.711092948913574), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -10.887887001037598), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', -12.573799133300781), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', -13.152804374694824), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', -42.68595886230469), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0', -51.35348129272461), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', -69.19706726074219), ('0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1', -71.00071716308594)]
2023-05-02 17:07:01,242 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 17:07:01,242 INFO     ['0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1']
2023-05-02 17:07:01,242 INFO     Grammatical sequences that the model is missing:
2023-05-02 17:07:01,242 INFO     ['0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1', '0 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1']
2023-05-02 17:07:01,243 INFO     LM precision, recall, fscore: 0.6190476190476191 0.52 0.5652173913043478
2023-05-02 17:07:01,243 INFO     Memorization precision, recall, fscore: 1.0 0.72 0.8372093023255813
2023-05-02 17:07:01,243 INFO     
2023-05-02 17:07:03,278 INFO     Language: ChineseNumeral
2023-05-02 17:07:03,278 INFO     Description: Several groups of b's joined with a single a separating each; each group of b's must be shorter than the previous one
2023-05-02 17:09:11,083 INFO     DONE TRAINING
2023-05-02 17:09:15,313 INFO     TRAINING SET LOSS: 285.3014658987522
2023-05-02 17:49:36,275 INFO     LM most common: [('0 1', 132436), ('0 1 1', 86306), ('0 1 1 1', 53440), ('0 1 1 0 1', 37380), ('0 1 1 1 1', 32170), ('0 1 1 1 0 1 1', 23265), ('0 1 1 1 1 1', 20256), ('0 1 1 1 0 1', 19085), ('0 1 1 1 1 1 1', 13606), ('0 1 1 1 1 0 1 1 1', 12242), ('0 1 1 1 1 0 1', 11219), ('0 1 1 1 1 0 1 1', 10785), ('0 1 1 1 1 1 1 1', 9201), ('0 1 1 1 0 1 1 0 1', 8776), ('0 1 1 1 1 1 0 1 1 1', 8635), ('0 1 1 1 1 1 0 1', 7314), ('0 1 1 1 1 1 0 1 1 1 1', 7150), ('0 1 1 1 1 1 1 0 1 1 1 1', 6430), ('0 1 1 1 1 1 0 1 1', 6421), ('0 1 1 1 1 1 1 1 1', 6097), ('0 1 1 1 1 1 1 0 1', 5233), ('0 1 1 1 1 0 1 1 0 1', 4933), ('0 1 1 1 1 0 1 1 1 0 1 1', 4728), ('0 1 1 1 1 1 1 0 1 1', 4701), ('0 1 1 1 1 1 1 0 1 1 1', 4640)]
2023-05-02 17:53:01,325 INFO     LM most common: [('0 1', -3.7868752479553223), ('0 1 1', -4.350057601928711), ('0 1 1 1', -5.004184246063232), ('0 1 1 1 0 1 1', -5.509214401245117), ('0 1 1 1 1 0 1 1 1', -5.716801643371582), ('0 1 1 1 1', -5.751311779022217), ('0 1 1 0 1', -6.017682075500488), ('0 1 1 1 1 1 0 1 1 1 1', -6.085606575012207), ('0 1 1 1 1 1 1 0 1 1 1 1', -6.385818958282471), ('0 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.387819766998291), ('0 1 1 1 1 1', -6.4012885093688965), ('0 1 1 1 0 1', -6.431910514831543), ('0 1 1 1 1 1 0 1 1 1', -6.436953544616699), ('0 1 1 1 1 0 1 1 1 0 1 1', -6.549459457397461), ('0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.646432876586914), ('0 1 1 1 1 0 1 1', -6.734412670135498), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1', -6.736510276794434), ('0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1', -6.765053749084473), ('0 1 1 1 1 1 1 0 1 1 1 1 1', -6.809678077697754), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1', -6.8434295654296875), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1', -6.866448402404785), ('0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.868441104888916), ('0 1 1 1 1 1 1', -6.944079399108887), ('0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.95215368270874), ('0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1', -6.955130577087402)]
2023-05-02 17:53:01,326 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 17:53:01,326 INFO     []
2023-05-02 17:53:01,326 INFO     Grammatical sequences that the model is missing:
2023-05-02 17:53:01,326 INFO     []
2023-05-02 17:53:01,334 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 17:53:01,334 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 17:53:01,334 INFO     
2023-05-02 17:53:01,999 INFO     Language: ABAnBn
2023-05-02 17:53:01,999 INFO     Description: Sigma+ A^ B^n (except it seems to be missing some short ones, like aab)
2023-05-02 17:53:45,221 INFO     DONE TRAINING
2023-05-02 17:53:46,629 INFO     TRAINING SET LOSS: 514.9973084330559
2023-05-02 18:05:59,180 INFO     LM most common: [('0 1 0 0 1 1', 18805), ('0 0 1 1 0 1', 18673), ('0 0 0 1 1 1 0 1', 13717), ('0 1 0 0 0 1 1 1', 12871), ('0 0 1 1 0 0 1 1', 10731), ('0 0 0 1 1 1 0 0 1 1', 9834), ('0 0 0 0 1 1 1 1 0 1', 9739), ('0 0 1 1 0 0 0 1 1 1', 9228), ('0 1 0 0 0 0 1 1 1 1', 8212), ('0 0 1 0 1', 7264), ('0 0 0 0 1 1 1 1 0 0 1 1', 7185), ('0 0 0 0 0 1 1 1 1 1 0 1', 6764), ('0 1 1 0 1', 6704), ('0 0 0 1 1 1 0 0 0 1 1 1', 6640), ('0 0 1 1 0 0 0 0 1 1 1 1', 6121), ('0 1 0 0 0 0 0 1 1 1 1 1', 5817), ('1 0 1 0 1', 5537), ('0 0 1 1 1 0 1', 5530), ('0 0 0 0 0 1 1 1 1 1 0 0 1 1', 5012), ('0 0 0 1 1 0 1', 4939), ('1 0 1 0 0 1 1', 4921), ('0 1 0 0 1', 4790), ('1 0 0 1 1 0 1', 4716), ('0 0 0 0 1 1 1 1 0 0 0 1 1 1', 4692), ('0 0 1 0 0 1 1', 4665)]
2023-05-02 18:07:11,582 INFO     LM most common: [('0 0 1 1 0 1', -4.20366096496582), ('0 1 0 0 1 1', -4.21642541885376), ('0 0 0 1 1 1 0 1', -4.277563571929932), ('0 0 0 1 1 1 0 0 1 1', -4.376418113708496), ('0 0 0 0 1 1 1 1 0 1', -4.384367942810059), ('0 0 0 0 1 1 1 1 0 0 1 1', -4.44603157043457), ('0 0 1 1 0 0 0 1 1 1', -4.469569206237793), ('0 1 0 0 0 1 1 1', -4.500030040740967), ('0 0 0 1 1 1 0 0 0 1 1 1', -4.548806190490723), ('0 0 0 0 0 1 1 1 1 1 0 1', -4.577932834625244), ('0 0 1 1 0 0 1 1', -4.581592559814453), ('0 0 0 0 0 1 1 1 1 1 0 0 1 1', -4.6317243576049805), ('0 0 0 0 1 1 1 1 0 0 0 1 1 1', -4.666652202606201), ('0 0 1 1 0 0 0 0 1 1 1 1', -4.693930149078369), ('0 1 0 0 0 0 1 1 1 1', -4.709218978881836), ('0 0 0 0 0 0 1 1 1 1 1 1 0 1', -4.775709629058838), ('0 0 0 1 1 1 0 0 0 0 1 1 1 1', -4.792081832885742), ('0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1', -4.830241680145264), ('0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1', -4.864526271820068), ('0 0 1 1 0 0 0 0 0 1 1 1 1 1', -4.893531799316406), ('0 1 0 0 0 0 0 1 1 1 1 1', -4.898496627807617), ('0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1', -4.917154312133789), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1', -4.973636150360107), ('0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1', -4.999109745025635), ('0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1', -5.029424667358398)]
2023-05-02 18:07:11,582 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:07:11,582 INFO     []
2023-05-02 18:07:11,582 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:07:11,582 INFO     []
2023-05-02 18:07:11,586 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:07:11,586 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:07:11,586 INFO     
2023-05-02 18:07:12,116 INFO     Language: ABaaaAB
2023-05-02 18:07:12,116 INFO     Description: Sigma+ AAA Sigma+
2023-05-02 18:07:43,741 INFO     DONE TRAINING
2023-05-02 18:07:44,743 INFO     TRAINING SET LOSS: 739.166558265686
2023-05-02 18:11:37,544 INFO     LM most common: [('1 0 0 0 1', 31589), ('0 0 0 0 1', 28670), ('1 0 0 0 0', 28533), ('0 0 0 0 0', 25291), ('1 0 0 0 0 1', 19439), ('0 0 0 0 0 1', 17876), ('1 0 0 0 0 0', 17055), ('0 0 0 0 0 0', 16425), ('1 0 0 0 1 1', 10789), ('1 1 0 0 0 1', 10319), ('1 0 0 0 1 0', 10202), ('0 0 0 0 1 1', 9858), ('0 1 0 0 0 1', 9535), ('0 0 0 0 1 0', 9530), ('0 1 0 0 0 0', 9447), ('1 1 0 0 0 0', 9423), ('1 0 0 0 0 0 1', 9118), ('0 0 0 0 0 0 1', 8546), ('1 0 0 0 0 0 0', 8085), ('0 0 0 0 0 0 0', 7755), ('1 0 0 0 0 1 1', 6547), ('1 1 0 0 0 0 1', 6212), ('0 0 0 0 0 1 1', 5991), ('0 1 0 0 0 0 1', 5809), ('1 0 0 0 0 1 0', 5744)]
2023-05-02 18:12:56,109 INFO     LM most common: [('1 0 0 0 1', -3.4226274490356445), ('1 0 0 0 0 1', -3.4435110092163086), ('0 0 0 0 0 1', -3.640155553817749), ('0 0 0 0 1', -3.6507363319396973), ('1 0 0 0 0 0', -3.722789764404297), ('1 0 0 0 0', -3.7586238384246826), ('0 0 0 0 0 0', -3.866529941558838), ('1 0 0 0 0 0 1', -3.9145522117614746), ('0 0 0 0 0', -4.0163044929504395), ('0 0 0 0 0 0 1', -4.057616233825684), ('1 0 0 0 0 0 0', -4.1772003173828125), ('0 0 0 0 0 0 0', -4.287898063659668), ('1 0 0 0 1 1', -4.471805572509766), ('1 0 0 0 0 0 0 1', -4.512104034423828), ('1 0 0 0 0 1 1', -4.543124198913574), ('1 0 0 0 1 0', -4.607619762420654), ('0 0 0 0 0 0 0 1', -4.641324043273926), ('0 0 0 0 1 1', -4.6615447998046875), ('0 0 0 0 0 1 1', -4.72771692276001), ('0 0 0 0 1 0', -4.7578277587890625), ('1 0 0 0 0 0 0 0', -4.762279510498047), ('1 0 0 0 0 1 0', -4.8047332763671875), ('0 0 0 0 0 0 0 0', -4.862909317016602), ('1 1 0 0 0 1', -4.931878566741943), ('0 0 0 0 0 1 0', -4.976032257080078)]
2023-05-02 18:12:56,110 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:12:56,110 INFO     []
2023-05-02 18:12:56,110 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:12:56,110 INFO     []
2023-05-02 18:12:56,114 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:12:56,114 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:12:56,114 INFO     
2023-05-02 18:12:56,437 INFO     Language: Unequal
2023-05-02 18:12:56,437 INFO     Description: Strings over {A, B} with an unequal number of A's and B's
2023-05-02 18:13:20,753 INFO     DONE TRAINING
2023-05-02 18:13:21,512 INFO     TRAINING SET LOSS: 942.4570492506027
2023-05-02 18:15:34,836 INFO     LM most common: [('0', 217874), ('1', 201029), ('0 0', 72093), ('1 1', 63996), ('0 1 0', 24462), ('0 0 1', 23368), ('0 0 0', 23321), ('1 0 0', 22960), ('0 1 1', 22131), ('1 0 1', 22007), ('1 1 1', 21023), ('1 1 0', 20495), ('0 0 0 0', 7768), ('0 1 0 0', 7594), ('1 0 0 0', 7524), ('0 0 1 0', 7248), ('0 0 0 1', 6977), ('1 0 1 1', 6722), ('1 1 1 1', 6704), ('0 1 1 1', 6678), ('1 1 0 1', 6278), ('1 1 1 0', 5690), ('1 1 0 0 0', 3019), ('1 0 0 1 0', 2838), ('0 1 0 1 0', 2820)]
2023-05-02 18:15:47,891 INFO     LM most common: [('0', -1.3271849155426025), ('1', -1.4740190505981445), ('0 0', -2.4440488815307617), ('1 1', -2.6882543563842773), ('0 0 0', -3.6282541751861572), ('0 0 1', -3.6611645221710205), ('1 1 1', -3.8357625007629395), ('1 1 0', -3.8834054470062256), ('0 1 0', -3.9698266983032227), ('1 0 0', -4.096892833709717), ('0 1 1', -4.1529035568237305), ('1 0 1', -4.167952537536621), ('0 0 0 0', -4.720334529876709), ('0 0 1 0', -4.88421106338501), ('0 0 0 1', -4.93857479095459), ('1 1 1 1', -4.96062707901001), ('1 1 0 1', -5.16771125793457), ('1 0 0 0', -5.212850570678711), ('0 1 0 0', -5.219779968261719), ('1 1 1 0', -5.323874473571777), ('1 0 1 1', -5.455698013305664), ('0 1 1 1', -5.503572940826416), ('0 0 0 0 0', -6.011322498321533), ('1 1 0 0 0', -6.0526580810546875), ('1 1 1 1 0', -6.054669380187988)]
2023-05-02 18:15:47,891 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:15:47,891 INFO     []
2023-05-02 18:15:47,891 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:15:47,891 INFO     []
2023-05-02 18:15:47,892 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:15:47,892 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:15:47,892 INFO     
2023-05-02 18:15:48,357 INFO     Language: Bach2
2023-05-02 18:15:48,358 INFO     Description: Strings over {A, B} with an equal number of A's and B's
2023-05-02 18:16:20,166 INFO     DONE TRAINING
2023-05-02 18:16:21,176 INFO     TRAINING SET LOSS: 713.2876887321472
2023-05-02 18:22:19,791 INFO     LM most common: [('0 1', 179347), ('1 0', 176614), ('0 0 1 1', 41749), ('1 0 0 1', 37823), ('0 1 1 0', 36645), ('1 1 0 0', 36381), ('0 1 0 1', 35621), ('1 0 1 0', 34595), ('0 0 0 1 1 1', 8711), ('1 0 0 0 1 1', 8672), ('1 1 0 1 0 0', 8552), ('0 0 1 0 1 1', 8494), ('1 1 1 0 0 0', 7980), ('0 1 0 0 1 1', 7962), ('0 1 1 1 0 0', 7952), ('0 0 1 1 1 0', 7197), ('0 0 1 1 0 1', 7093), ('0 1 1 0 0 1', 7021), ('0 1 1 0 1 0', 6984), ('1 0 1 1 0 0', 6937), ('1 1 0 0 0 1', 6937), ('1 0 1 0 0 1', 6924), ('1 0 0 1 0 1', 6403), ('1 1 0 0 1 0', 6384), ('1 0 1 0 1 0', 6203)]
2023-05-02 18:23:09,752 INFO     LM most common: [('0 1', -1.2403206825256348), ('1 0', -1.2815433740615845), ('1 0 0 1', -2.9372925758361816), ('0 1 1 0', -2.9674136638641357), ('0 1 0 1', -3.0293960571289062), ('1 0 1 0', -3.1202890872955322), ('0 0 1 1', -3.261673927307129), ('1 1 0 0', -3.5089426040649414), ('0 1 1 0 0 1', -4.883589744567871), ('0 1 1 0 1 0', -4.955362319946289), ('1 0 1 0 0 1', -4.968422889709473), ('1 0 0 0 1 1', -4.98708963394165), ('1 0 0 1 0 1', -4.99578857421875), ('0 1 0 0 1 1', -5.119536399841309), ('0 1 0 1 0 1', -5.120301246643066), ('1 0 0 1 1 0', -5.128306865692139), ('0 1 0 1 1 0', -5.135696887969971), ('0 1 1 1 0 0', -5.144169330596924), ('1 0 1 0 1 0', -5.253105163574219), ('0 0 1 1 1 0', -5.275832653045654), ('0 0 1 1 0 1', -5.40280294418335), ('1 1 0 0 0 1', -5.408443927764893), ('0 0 0 1 1 1', -5.458704948425293), ('1 0 1 1 0 0', -5.478599548339844), ('0 0 1 0 1 1', -5.540423393249512)]
2023-05-02 18:23:09,753 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:23:09,753 INFO     []
2023-05-02 18:23:09,753 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:23:09,753 INFO     []
2023-05-02 18:23:09,755 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:23:09,755 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:23:09,755 INFO     
2023-05-02 18:23:10,617 INFO     Language: Bach3
2023-05-02 18:23:10,617 INFO     Description: Strings over {A, B, C} with an equal number of A's, B's, and C's
2023-05-02 18:23:49,613 INFO     DONE TRAINING
2023-05-02 18:23:50,870 INFO     TRAINING SET LOSS: 948.6267647147179
2023-05-02 18:34:24,056 INFO     LM most common: [('1 2 0', 60297), ('1 0 2', 59002), ('0 2 1', 56895), ('0 1 2', 56806), ('2 1 0', 56598), ('2 0 1', 55100), ('0 2 2 0 1 1', 3113), ('2 0 0 1 2 1', 3063), ('2 1 0 0 2 1', 3051), ('2 1 0 0 1 2', 3048), ('0 2 1 0 2 1', 2997), ('1 2 0 0 1 2', 2968), ('0 1 1 2 0 2', 2967), ('1 1 2 0 0 2', 2949), ('0 2 0 1 2 1', 2947), ('0 1 0 2 2 1', 2931), ('1 2 2 0 0 1', 2916), ('0 1 2 2 1 0', 2888), ('1 1 0 0 2 2', 2884), ('1 2 0 0 2 1', 2843), ('2 0 1 0 2 1', 2830), ('0 1 2 2 0 1', 2820), ('2 1 2 0 0 1', 2816), ('2 0 0 1 1 2', 2789), ('1 2 2 1 0 0', 2786)]
2023-05-02 18:38:03,051 INFO     LM most common: [('1 2 0', -2.0215373039245605), ('0 1 2', -2.0559802055358887), ('1 0 2', -2.0998995304107666), ('0 2 1', -2.1318137645721436), ('2 0 1', -2.1526951789855957), ('2 1 0', -2.168224811553955), ('1 1 2 0 0 2', -5.490176200866699), ('0 1 0 2 2 1', -5.5849151611328125), ('1 1 0 0 2 2', -5.589215278625488), ('2 0 1 0 2 1', -5.668271064758301), ('1 1 0 2 0 2', -5.684251308441162), ('2 0 0 1 2 1', -5.723624229431152), ('0 1 1 2 0 2', -5.728000164031982), ('0 1 2 0 2 1', -5.760331153869629), ('2 1 0 0 2 1', -5.770483016967773), ('0 2 0 1 2 1', -5.778290271759033), ('0 0 2 1 2 1', -5.778293609619141), ('1 1 0 2 2 0', -5.795124530792236), ('2 1 0 0 1 2', -5.798911094665527), ('0 0 1 2 2 1', -5.8134331703186035), ('0 1 2 2 0 1', -5.834012508392334), ('1 2 0 0 2 1', -5.851084232330322), ('0 2 1 0 2 1', -5.8536248207092285), ('0 1 0 2 1 2', -5.861380100250244), ('0 1 2 2 1 0', -5.867791175842285)]
2023-05-02 18:38:03,051 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 18:38:03,051 INFO     []
2023-05-02 18:38:03,051 INFO     Grammatical sequences that the model is missing:
2023-05-02 18:38:03,051 INFO     []
2023-05-02 18:38:03,065 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:38:03,065 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 18:38:03,065 INFO     
2023-05-02 18:38:04,029 INFO     Language: WeW
2023-05-02 18:38:04,029 INFO     Description: X^|X| (that is, a string X repeated |X| times, where |X| is the length of X)
2023-05-02 18:39:24,613 INFO     DONE TRAINING
2023-05-02 18:39:27,225 INFO     TRAINING SET LOSS: 375.42763228714466
2023-05-02 19:19:48,659 INFO     LM most common: [('0', 170542), ('1', 163912), ('0 0 0 0', 66732), ('0 1 0 1', 65921), ('1 1 1 1', 62987), ('1 0 1 0', 57889), ('1 0 1 1 0 1 1 0 1', 24728), ('0 0 0 0 0 0 0 0 0', 24541), ('0 0 1 0 0 1 0 0 1', 24038), ('1 1 0 1 1 0 1 1 0', 24025), ('0 1 1 0 1 1 0 1 1', 21823), ('0 1 0 0 1 0 0 1 0', 21351), ('1 0 0 1 0 0 1 0 0', 15831), ('1 1 1 1 1 1 1 1 1', 13585), ('0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1', 8714), ('1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1', 8566), ('0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1', 7110), ('1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0', 6919), ('0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0', 6475), ('0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0', 6055), ('1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0', 5676), ('1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1', 4956), ('0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1', 4815), ('0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0', 4781), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', 4705)]
2023-05-02 19:21:03,559 INFO     LM most common: [('0', -1.7477492094039917), ('1', -1.8297374248504639), ('0 1 0 1', -2.1104371547698975), ('0 0 0 0', -2.154853343963623), ('1 1 1 1', -2.255481004714966), ('1 0 1 0', -2.415505886077881), ('0 0 0 0 0 0 0 0 0', -3.542448043823242), ('1 0 1 1 0 1 1 0 1', -3.6610360145568848), ('0 0 1 0 0 1 0 0 1', -3.7025270462036133), ('0 1 1 0 1 1 0 1 1', -3.711606502532959), ('1 1 0 1 1 0 1 1 0', -3.746326208114624), ('0 1 0 0 1 0 0 1 0', -4.017832279205322), ('1 1 1 1 1 1 1 1 1', -4.445669174194336), ('1 0 0 1 0 0 1 0 0', -4.595701694488525), ('0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1', -4.9486517906188965), ('1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1', -5.4738383293151855), ('0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1', -5.535513401031494), ('1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1', -5.681407928466797), ('1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0', -5.844125270843506), ('0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0', -5.860955238342285), ('1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0', -6.005997657775879), ('1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0', -6.048234939575195), ('0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0', -6.050370216369629), ('0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0', -6.227977275848389), ('0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1', -6.6180830001831055)]
2023-05-02 19:21:03,560 INFO     LM-generated common sequences that are ungrammatical:
2023-05-02 19:21:03,560 INFO     []
2023-05-02 19:21:03,560 INFO     Grammatical sequences that the model is missing:
2023-05-02 19:21:03,560 INFO     []
2023-05-02 19:21:03,562 INFO     LM precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 19:21:03,562 INFO     Memorization precision, recall, fscore: 1.0 1.0 1.0
2023-05-02 19:21:03,562 INFO     
2023-05-02 19:21:03,562 INFO     Average LM Y&P precision: 0.9471533228676086
2023-05-02 19:21:03,562 INFO     Average LM Y&P recall: 0.9547939560439562
2023-05-02 19:21:03,562 INFO     Average LM Y&P F-score: 0.9496245059288536
2023-05-02 19:21:03,562 INFO     
2023-05-02 19:21:03,562 INFO     Average memorization Y&P precision: 0.9977678571428571
2023-05-02 19:21:03,562 INFO     Average memorization Y&P recall: 0.9386675824175823
2023-05-02 19:21:03,562 INFO     Average memorization Y&P F-score: 0.9643377891575774
2023-05-02 19:21:03,562 INFO     
