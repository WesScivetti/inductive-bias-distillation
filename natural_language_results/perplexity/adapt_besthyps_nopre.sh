python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_nopre --model_index 19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_20/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 20 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_21/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 21 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_22/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 22 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_23/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 23 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_24/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 24 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_25/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 25 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_26/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 26 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_27/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 27 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_28/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 28 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_29/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 29 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_30/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 30 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_31/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 31 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_32/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 32 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_33/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 33 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_34/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 34 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_35/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 35 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_36/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 36 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_37/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 37 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_38/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 38 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_39/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_nopre --model_index 39 --weight_dir weights/ --log_dir logs/
