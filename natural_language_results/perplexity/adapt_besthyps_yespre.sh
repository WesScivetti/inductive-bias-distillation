python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_0 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_0 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_0 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_0 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_0 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_0/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_0 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre0 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_1 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_1 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_1 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_1 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_1 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_1/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_1 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre1 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_2 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_2 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_2 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_2 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_2 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_2/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_2 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre2 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_3 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_3 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_3 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_3 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_3 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_3/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_3 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre3 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_4 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_4 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_4 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_4 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_4 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_4/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_4 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre4 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_5 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_5 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_5 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_5 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_5 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_5/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_5 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre5 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_6 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_6 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_6 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_6 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_6 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_6/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_6 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre6 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_7 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_7 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_7 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_7 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_7 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_7/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_7 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre7 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_8 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_8 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_8 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_8 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_8 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_8/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_8 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre8 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_9 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_9 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_9 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_9 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_9 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_9/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_9 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre9 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_10 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_10 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_10 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_10 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_10 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_10/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_10 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre10 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_11 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_11 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_11 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_11 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_11 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_11/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_11 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre11 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_12 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_12 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_12 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_12 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_12 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_12/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_12 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre12 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_13 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_13 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_13 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_13 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_13 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_13/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_13 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre13 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_14 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_14 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_14 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_14 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_14 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_14/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_14 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre14 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_15 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_15 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_15 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_15 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_15 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_15/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_15 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre15 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_16 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_16 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_16 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_16 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_16 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_16/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_16 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre16 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_17 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_17 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_17 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_17 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_17 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_17/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_17 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre17 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_18 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_18 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_18 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_18 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_18 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_18/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_18 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre18 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_full_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_half_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 256 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_half_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_quarter_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 512 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_quarter_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_eighth_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 1024 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_eighth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixteenth_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 2048 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixteenth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_thirtysecond_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 4096 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_thirtysecond_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_19 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 512 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden512_19 --pretrained_vocab_size 15 --n_epochs 32 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden512_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 256 --n_positions 256 --n_layer 2 --dropout 0.2 --pretrained_name weights/meta_lm_hidden256_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden256_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 128 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden128_19 --pretrained_vocab_size 15 --n_epochs 128 --eval_every 100 --weight_decay 0.01 --learning_rate 0.001 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden128_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 64 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden64_19 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden64_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 32 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden32_19 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden32_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_sixtyfourth_19/ --batch_size 10 --architecture LSTM --n_embd 16 --n_positions 256 --n_layer 2 --dropout 0.1 --pretrained_name weights/meta_lm_hidden16_19 --pretrained_vocab_size 15 --n_epochs 8192 --eval_every 100 --weight_decay 0.01 --learning_rate 0.01 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden16_pretraining_sixtyfourth_yespre19 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_20/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_20 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre20 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_21/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_21 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre21 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_22/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_22 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre22 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_23/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_23 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre23 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_24/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_24 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre24 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_25/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_25 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre25 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_26/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_26 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre26 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_27/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_27 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre27 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_28/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_28 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre28 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_29/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_29 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre29 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_30/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_30 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre30 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_31/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_31 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre31 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_32/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_32 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre32 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_33/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_33 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre33 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_34/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_34 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre34 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_35/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_35 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre35 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_36/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_36 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre36 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_37/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_37 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre37 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_38/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_38 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre38 --weight_dir weights/ --log_dir logs/
python lm_train.py --directory CHILDES/pretraining_full_39/ --batch_size 10 --architecture LSTM --n_embd 1024 --n_positions 256 --n_layer 2 --dropout 0.4 --pretrained_name weights/meta_lm_hidden1024_39 --pretrained_vocab_size 15 --n_epochs 64 --eval_every 100 --weight_decay 0.01 --learning_rate 0.0005 --lr_scheduler_type cosine --warmup_proportion 0.06 --model_name bestparams_adapt_hidden1024_pretraining_full_yespre39 --weight_dir weights/ --log_dir logs/
